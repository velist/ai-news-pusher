#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆAIæ–°é—»ç´¯ç§¯æ›´æ–°ç³»ç»Ÿ - é›†æˆç¡…åŸºæµåŠ¨æ™ºèƒ½ç¿»è¯‘
"""

import os
import json
import urllib.request
import urllib.parse
import time
import hashlib
from datetime import datetime, timedelta

# å°è¯•å¯¼å…¥dotenvï¼Œå¦‚æœå¤±è´¥åˆ™ç»§ç»­ï¼ˆGitHub Actionsä¸­ç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("python-dotenvæœªå®‰è£…ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")

# å¯¼å…¥ç¿»è¯‘æœåŠ¡
try:
    from translation.services.siliconflow_translator import SiliconFlowTranslator
except ImportError:
    print("ç¿»è¯‘æœåŠ¡æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½")
    SiliconFlowTranslator = None

class EnhancedAINewsAccumulator:
    def __init__(self):
        # APIé…ç½® - ä»ç¯å¢ƒå˜é‡è·å–
        self.gnews_api_key = os.getenv('GNEWS_API_KEY')
        if not self.gnews_api_key:
            raise ValueError("GNEWS_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.gnews_base_url = "https://gnews.io/api/v4"
        self.news_data_file = 'docs/enhanced_news_data.json'
        
        # åˆå§‹åŒ–ç¡…åŸºæµåŠ¨ç¿»è¯‘å™¨
        self.siliconflow_api_key = os.getenv('SILICONFLOW_API_KEY')
        self.translator = None
        self._init_translator()
        
    def _init_translator(self):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        if SiliconFlowTranslator and self.siliconflow_api_key:
            try:
                self.translator = SiliconFlowTranslator(
                    api_key=self.siliconflow_api_key,
                    model="Qwen/Qwen2.5-7B-Instruct"  # ä½¿ç”¨æ€§ä»·æ¯”æœ€é«˜çš„æ¨¡å‹
                )
                print("âœ… ç¡…åŸºæµåŠ¨ç¿»è¯‘å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ ç¿»è¯‘å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.translator = None
        else:
            print("âš ï¸ ç¿»è¯‘æœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸå§‹æ–°é—»å†…å®¹")
    
    
    def get_latest_news(self):
        """è·å–æœ€æ–°ç§‘æŠ€ã€æ¸¸æˆã€ç»æµæ–°é—»"""
        all_articles = []
        
        # å®šä¹‰å¤šä¸ªæœç´¢ç±»åˆ«
        search_queries = [
            {
                'query': 'AI OR OpenAI OR ChatGPT OR "artificial intelligence"',
                'category': 'AIç§‘æŠ€',
                'max': '15'
            },
            {
                'query': 'gaming OR PlayStation OR Xbox OR Nintendo',
                'category': 'æ¸¸æˆç§‘æŠ€', 
                'max': '10'
            },
            {
                'query': 'stock OR bitcoin OR finance OR cryptocurrency',
                'category': 'ç»æµé‡‘è',
                'max': '10'
            },
            {
                'query': 'Apple OR Google OR Microsoft OR Meta OR technology',
                'category': 'ç§‘æŠ€åˆ›æ–°',
                'max': '10'
            }
        ]
        
        for search_config in search_queries:
            max_retries = 3 if search_config['category'] == 'AIç§‘æŠ€' else 1
            
            for attempt in range(max_retries):
                try:
                    # è®¡ç®—3å¤©å‰çš„æ—¥æœŸ
                    three_days_ago = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')
                    
                    params = {
                        'apikey': self.gnews_api_key,
                        'q': search_config['query'],
                        'lang': 'en',
                        'max': search_config['max'],
                        'sortby': 'publishedAt',
                        'from': three_days_ago
                    }
                    
                    query_string = urllib.parse.urlencode(params)
                    url = f"{self.gnews_base_url}/search?{query_string}"
                    
                    with urllib.request.urlopen(url, timeout=20) as response:
                        result = json.loads(response.read().decode('utf-8'))
                    
                    articles = result.get('articles', [])
                    # ä¸ºæ¯ç¯‡æ–‡ç« æ·»åŠ æœç´¢ç±»åˆ«æ ‡è®°
                    for article in articles:
                        article['search_category'] = search_config['category']
                    
                    all_articles.extend(articles)
                    print(f"âœ… {search_config['category']}è·å– {len(articles)} æ¡æ–°é—»")
                    break
                    
                except Exception as e:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ {search_config['category']}ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥ï¼Œé‡è¯•ä¸­...")
                        time.sleep(2)
                        continue
                    else:
                        print(f"âŒ è·å–{search_config['category']}æ–°é—»å¤±è´¥: {str(e)}")
        
        print(f"âœ… æ€»å…±è·å– {len(all_articles)} æ¡æœ€æ–°æ–°é—»")
        return all_articles
    
    def translate_article(self, article):
        """ç¿»è¯‘å•ç¯‡æ–‡ç« """
        if not self.translator:
            return article
        
        try:
            title = article.get('title', '')
            description = article.get('description', '')
            
            # ç¿»è¯‘æ ‡é¢˜
            translated_title = ""
            title_confidence = 0.0
            if title:
                title_result = self.translator.translate_text(title, "en", "zh")
                if not title_result.error_message:
                    translated_title = title_result.translated_text
                    title_confidence = title_result.confidence_score
                else:
                    print(f"âš ï¸ æ ‡é¢˜ç¿»è¯‘å¤±è´¥: {title_result.error_message}")
            
            # ç¿»è¯‘æè¿°
            translated_description = ""
            desc_confidence = 0.0
            if description:
                desc_result = self.translator.translate_text(description, "en", "zh")
                if not desc_result.error_message:
                    translated_description = desc_result.translated_text
                    desc_confidence = desc_result.confidence_score
                else:
                    print(f"âš ï¸ æè¿°ç¿»è¯‘å¤±è´¥: {desc_result.error_message}")
            
            # æ·»åŠ ç¿»è¯‘ä¿¡æ¯åˆ°æ–‡ç« 
            article['ai_translation'] = {
                'translated_title': translated_title,
                'translated_description': translated_description,
                'translation_confidence': {
                    'title': title_confidence,
                    'description': desc_confidence
                },
                'translation_service': self.translator.get_service_name(),
                'translation_time': datetime.now().isoformat(),
                'original_title': title,
                'original_description': description
            }
            
            return article
            
        except Exception as e:
            print(f"âŒ æ–‡ç« ç¿»è¯‘å¼‚å¸¸: {str(e)}")
            return article
    
    def translate_articles_batch(self, articles):
        """æ‰¹é‡ç¿»è¯‘æ–‡ç« """
        if not self.translator or not articles:
            return articles
        
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(articles)} ç¯‡æ–‡ç« ...")
        
        try:
            # æå–æ ‡é¢˜å’Œæè¿°
            titles = [article.get('title', '') for article in articles]
            descriptions = [article.get('description', '') for article in articles]
            
            # è¿‡æ»¤ç©ºå†…å®¹
            valid_titles = [t for t in titles if t.strip()]
            valid_descriptions = [d for d in descriptions if d.strip()]
            
            translated_titles = []
            translated_descriptions = []
            
            # æ‰¹é‡ç¿»è¯‘æ ‡é¢˜
            if valid_titles:
                print("ğŸ“ ç¿»è¯‘æ ‡é¢˜ä¸­...")
                title_results = self.translator.translate_batch(valid_titles, "en", "zh")
                translated_titles = title_results
            
            # æ‰¹é‡ç¿»è¯‘æè¿°
            if valid_descriptions:
                print("ğŸ“„ ç¿»è¯‘æè¿°ä¸­...")
                desc_results = self.translator.translate_batch(valid_descriptions, "en", "zh")
                translated_descriptions = desc_results
            
            # å°†ç¿»è¯‘ç»“æœæ·»åŠ åˆ°æ–‡ç« ä¸­
            title_idx = 0
            desc_idx = 0
            
            for article in articles:
                title = article.get('title', '')
                description = article.get('description', '')
                
                # å¤„ç†æ ‡é¢˜ç¿»è¯‘
                translated_title = ""
                title_confidence = 0.0
                if title.strip() and title_idx < len(translated_titles):
                    title_result = translated_titles[title_idx]
                    if not title_result.error_message:
                        translated_title = title_result.translated_text
                        title_confidence = title_result.confidence_score
                    title_idx += 1
                
                # å¤„ç†æè¿°ç¿»è¯‘
                translated_description = ""
                desc_confidence = 0.0
                if description.strip() and desc_idx < len(translated_descriptions):
                    desc_result = translated_descriptions[desc_idx]
                    if not desc_result.error_message:
                        translated_description = desc_result.translated_text
                        desc_confidence = desc_result.confidence_score
                    desc_idx += 1
                
                # æ·»åŠ ç¿»è¯‘ä¿¡æ¯
                article['ai_translation'] = {
                    'translated_title': translated_title,
                    'translated_description': translated_description,
                    'translation_confidence': {
                        'title': title_confidence,
                        'description': desc_confidence
                    },
                    'translation_service': self.translator.get_service_name(),
                    'translation_time': datetime.now().isoformat(),
                    'original_title': title,
                    'original_description': description
                }
            
            print(f"âœ… æ‰¹é‡ç¿»è¯‘å®Œæˆ")
            return articles
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡ç¿»è¯‘å¤±è´¥ï¼Œå›é€€åˆ°å•ä¸ªç¿»è¯‘: {str(e)}")
            # å›é€€åˆ°å•ä¸ªç¿»è¯‘
            return [self.translate_article(article) for article in articles]
    
    def load_existing_news(self):
        """åŠ è½½ç°æœ‰æ–°é—»æ•°æ®"""
        try:
            if os.path.exists(self.news_data_file):
                with open(self.news_data_file, 'r', encoding='utf-8') as f:
                    existing_news = json.load(f)
                print(f"ğŸ“š åŠ è½½ç°æœ‰æ–°é—»: {len(existing_news)} æ¡")
                return existing_news
            else:
                print("ğŸ“ é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ–°çš„æ–°é—»æ•°æ®")
                return []
        except Exception as e:
            print(f"âŒ åŠ è½½ç°æœ‰æ–°é—»å¤±è´¥: {str(e)}")
            return []
    
    def generate_news_id(self, article):
        """ç”Ÿæˆæ–°é—»å”¯ä¸€ID"""
        content = f"{article.get('url', '')}{article.get('title', '')}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()[:12]
    
    def is_news_recent(self, publish_date, days=3):
        """æ£€æŸ¥æ–°é—»æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…"""
        try:
            if not publish_date:
                return False
            
            if 'T' in publish_date:
                news_date = datetime.fromisoformat(publish_date.replace('Z', '+00:00'))
            else:
                news_date = datetime.fromisoformat(publish_date)
            
            now = datetime.now().replace(tzinfo=news_date.tzinfo) if news_date.tzinfo else datetime.now()
            time_diff = now - news_date
            
            return time_diff.days <= days
        except:
            return False
    
    def categorize_news(self, title, search_category=""):
        """æ–°é—»åˆ†ç±»"""
        title_lower = title.lower()
        
        if search_category == 'AIç§‘æŠ€':
            if 'openai' in title_lower or 'chatgpt' in title_lower:
                return {'name': 'OpenAI', 'color': '#34C759', 'icon': 'ğŸ¤–'}
            elif 'google' in title_lower:
                return {'name': 'è°·æ­ŒAI', 'color': '#007AFF', 'icon': 'ğŸ”'}
            elif 'microsoft' in title_lower:
                return {'name': 'å¾®è½¯AI', 'color': '#5856D6', 'icon': 'ğŸ’¼'}
            else:
                return {'name': 'AIç§‘æŠ€', 'color': '#FF6B35', 'icon': 'ğŸ¤–'}
        elif search_category == 'æ¸¸æˆç§‘æŠ€':
            return {'name': 'æ¸¸æˆç§‘æŠ€', 'color': '#9B59B6', 'icon': 'ğŸ®'}
        elif search_category == 'ç»æµé‡‘è':
            return {'name': 'ç»æµé‡‘è', 'color': '#E67E22', 'icon': 'ğŸ’°'}
        else:
            return {'name': 'ç§‘æŠ€èµ„è®¯', 'color': '#6B7280', 'icon': 'ğŸ“±'}
    
    def get_importance_score(self, title):
        """é‡è¦æ€§è¯„åˆ†"""
        title_lower = title.lower()
        score = 1
        
        if any(word in title_lower for word in ['breakthrough', 'revolutionary', 'major', 'launch']):
            score += 3
        if any(word in title_lower for word in ['openai', 'gpt-5', 'gpt-4']):
            score += 2
        if any(word in title_lower for word in ['google', 'microsoft', 'meta']):
            score += 1
        
        return min(score, 5)
    
    def merge_news_data(self, existing_news, new_articles):
        """åˆå¹¶æ–°æ—§æ–°é—»æ•°æ®"""
        existing_urls = {news.get('url', ''): news for news in existing_news}
        merged_news = []
        added_count = 0
        
        # é¦–å…ˆæ·»åŠ æ–°æ–‡ç« ï¼ˆå¸¦ç¿»è¯‘ï¼‰
        for article in new_articles:
            article_url = article.get('url', '')
            
            if article_url not in existing_urls:
                search_category = article.get('search_category', '')
                
                # ä½¿ç”¨AIç¿»è¯‘çš„æ ‡é¢˜å’Œæè¿°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                ai_translation = article.get('ai_translation', {})
                chinese_title = ai_translation.get('translated_title', '') or article.get('title', '')
                chinese_description = ai_translation.get('translated_description', '') or article.get('description', '')
                
                news_item = {
                    "id": self.generate_news_id(article),
                    "title": chinese_title,
                    "original_title": article.get('title', ''),
                    "description": chinese_description,
                    "original_description": article.get('description', ''),
                    "url": article_url,
                    "source": article.get('source', {}).get('name', 'æœªçŸ¥æ¥æº'),
                    "publishedAt": article.get('publishedAt', ''),
                    "image": article.get('image', ''),
                    "category": self.categorize_news(chinese_title, search_category),
                    "importance": self.get_importance_score(chinese_title),
                    "added_time": datetime.now().isoformat(),
                    "search_category": search_category,
                    "ai_translation": ai_translation  # ä¿å­˜å®Œæ•´çš„ç¿»è¯‘ä¿¡æ¯
                }
                merged_news.append(news_item)
                added_count += 1
        
        # ç„¶åæ·»åŠ ä¿ç•™çš„å†å²æ–°é—»ï¼ˆ3å¤©å†…ï¼‰
        retained_count = 0
        for news in existing_news:
            if self.is_news_recent(news.get('publishedAt'), days=3):
                merged_news.append(news)
                retained_count += 1
        
        # æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ—
        merged_news.sort(key=lambda x: x.get('publishedAt', ''), reverse=True)
        
        print(f"ğŸ“Š æ–°é—»åˆå¹¶å®Œæˆ:")
        print(f"   ğŸ“ˆ æ–°å¢æ–°é—»: {added_count} æ¡")
        print(f"   ğŸ“š ä¿ç•™å†å²: {retained_count} æ¡")
        print(f"   ğŸ“° æ€»è®¡æ–°é—»: {len(merged_news)} æ¡")
        
        return merged_news
    
    def save_news_data(self, news_data):
        """ä¿å­˜æ–°é—»æ•°æ®"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.news_data_file), exist_ok=True)
            
            with open(self.news_data_file, 'w', encoding='utf-8') as f:
                json.dump(news_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ–°é—»æ•°æ®å·²ä¿å­˜åˆ°: {self.news_data_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–°é—»æ•°æ®å¤±è´¥: {str(e)}")
    
    def run_update(self):
        """è¿è¡Œæ–°é—»æ›´æ–°æµç¨‹"""
        print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆAIæ–°é—»ç´¯ç§¯æ›´æ–°ç³»ç»Ÿ")
        print("=" * 60)
        
        try:
            # 1. è·å–æœ€æ–°æ–°é—»
            print("\nğŸ“¡ è·å–æœ€æ–°æ–°é—»...")
            new_articles = self.get_latest_news()
            
            if not new_articles:
                print("âš ï¸ æ²¡æœ‰è·å–åˆ°æ–°é—»ï¼Œé€€å‡ºæ›´æ–°")
                return
            
            # 2. æ‰¹é‡ç¿»è¯‘æ–°é—»
            print(f"\nğŸ”¤ å¼€å§‹ç¿»è¯‘ {len(new_articles)} æ¡æ–°é—»...")
            if self.translator:
                translated_articles = self.translate_articles_batch(new_articles)
                
                # ç»Ÿè®¡ç¿»è¯‘æˆåŠŸç‡
                success_count = sum(1 for article in translated_articles 
                                  if article.get('ai_translation', {}).get('translated_title'))
                print(f"âœ… ç¿»è¯‘æˆåŠŸ: {success_count}/{len(new_articles)} æ¡")
            else:
                print("âš ï¸ ç¿»è¯‘å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤")
                translated_articles = new_articles
            
            # 3. åŠ è½½ç°æœ‰æ–°é—»
            print("\nğŸ“š åŠ è½½ç°æœ‰æ–°é—»æ•°æ®...")
            existing_news = self.load_existing_news()
            
            # 4. åˆå¹¶æ–°é—»æ•°æ®
            print("\nğŸ”„ åˆå¹¶æ–°é—»æ•°æ®...")
            merged_news = self.merge_news_data(existing_news, translated_articles)
            
            # 5. ä¿å­˜æ–°é—»æ•°æ®
            print("\nğŸ’¾ ä¿å­˜æ–°é—»æ•°æ®...")
            self.save_news_data(merged_news)
            
            print(f"\n{'='*60}")
            print("ğŸ‰ æ–°é—»æ›´æ–°å®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {len(merged_news)} æ¡æ–°é—»")
            
            # æ˜¾ç¤ºç¿»è¯‘ç»Ÿè®¡
            if self.translator:
                translated_count = sum(1 for news in merged_news 
                                     if news.get('ai_translation', {}).get('translated_title'))
                print(f"ğŸ”¤ ç¿»è¯‘è¦†ç›–: {translated_count} æ¡æ–°é—»åŒ…å«AIç¿»è¯‘")
            
        except Exception as e:
            print(f"âŒ æ–°é—»æ›´æ–°å¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    accumulator = EnhancedAINewsAccumulator()
    accumulator.run_update()


if __name__ == "__main__":
    main()
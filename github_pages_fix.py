#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub Pagesé—®é¢˜ä¿®å¤ç‰ˆ - ä¸“é—¨è§£å†³æµ‹è¯•æ•°æ®é—®é¢˜
å¢åŠ è¯¦ç»†çš„APIè°ƒç”¨æ—¥å¿—å’Œé”™è¯¯å¤„ç†
"""

import os
import json
import urllib.request
import urllib.parse
import urllib.error
from datetime import datetime, timedelta
import sys
import time

def load_env_file():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_path = '.env'
    if os.path.exists(env_path):
        try:
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
            print("âœ… æœ¬åœ°.envæ–‡ä»¶åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âš ï¸ .envæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return False
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°.envæ–‡ä»¶ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡")
        return False

def test_api_connectivity():
    """æµ‹è¯•APIè¿æ¥æ€§"""
    print("\nğŸ” APIè¿æ¥æ€§æµ‹è¯•...")
    
    # æµ‹è¯•åŸºç¡€ç½‘ç»œè¿æ¥
    try:
        test_req = urllib.request.Request("https://httpbin.org/ip")
        test_req.add_header('User-Agent', 'Mozilla/5.0 (compatible; NewsBot/1.0)')
        with urllib.request.urlopen(test_req, timeout=5) as response:
            ip_info = json.loads(response.read().decode())
            print(f"âœ… ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ŒIP: {ip_info.get('origin', 'unknown')}")
            return True
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
        return False

def validate_api_key(api_key):
    """éªŒè¯APIå¯†é’¥æ ¼å¼å’Œæœ‰æ•ˆæ€§"""
    if not api_key:
        print("âŒ APIå¯†é’¥ä¸ºç©º")
        return False
    
    if len(api_key) != 32:
        print(f"âŒ APIå¯†é’¥é•¿åº¦é”™è¯¯: {len(api_key)} (åº”ä¸º32ä½)")
        return False
    
    if not all(c in '0123456789abcdef' for c in api_key.lower()):
        print("âŒ APIå¯†é’¥æ ¼å¼é”™è¯¯: åº”ä¸º32ä½åå…­è¿›åˆ¶å­—ç¬¦")
        return False
    
    print(f"âœ… APIå¯†é’¥æ ¼å¼æ­£ç¡®: {api_key[:8]}...{api_key[-4:]}")
    return True

def test_gnews_api(api_key):
    """æµ‹è¯•GNews APIæœ‰æ•ˆæ€§"""
    print(f"\nğŸ§ª æµ‹è¯•GNews API...")
    
    try:
        # ä½¿ç”¨ç®€å•çš„æµ‹è¯•æŸ¥è¯¢
        test_url = "https://gnews.io/api/v4/search"
        test_params = {
            "q": "test",
            "max": 1,
            "apikey": api_key
        }
        
        query_string = urllib.parse.urlencode(test_params)
        full_url = f"{test_url}?{query_string}"
        
        print(f"ğŸ“¡ æµ‹è¯•URL: {test_url}?q=test&max=1&apikey={api_key[:8]}...")
        
        req = urllib.request.Request(full_url)
        req.add_header('User-Agent', 'Mozilla/5.0 (compatible; NewsBot/1.0)')
        
        with urllib.request.urlopen(req, timeout=15) as response:
            status_code = response.getcode()
            print(f"ğŸ“Š HTTPçŠ¶æ€ç : {status_code}")
            
            if status_code == 200:
                data = json.loads(response.read().decode())
                print(f"âœ… APIå“åº”æˆåŠŸ")
                print(f"ğŸ“° è¿”å›æ–‡ç« æ•°: {len(data.get('articles', []))}")
                print(f"ğŸ“Š æ€»æ–‡ç« æ•°: {data.get('totalArticles', 0)}")
                return True
            else:
                print(f"âŒ APIå“åº”å¼‚å¸¸: HTTP {status_code}")
                return False
                
    except urllib.error.HTTPError as e:
        print(f"âŒ HTTPé”™è¯¯: {e.code} - {e.reason}")
        if e.code == 401:
            print("   åŸå› : APIå¯†é’¥æ— æ•ˆæˆ–æœªæˆæƒ")
        elif e.code == 403:
            print("   åŸå› : è®¿é—®è¢«ç¦æ­¢ï¼Œå¯èƒ½æ˜¯é…é¢é—®é¢˜")
        elif e.code == 429:
            print("   åŸå› : è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œå·²è¢«é™åˆ¶")
        elif e.code == 500:
            print("   åŸå› : GNewsæœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
        return False
    except urllib.error.URLError as e:
        print(f"âŒ URLé”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        return False

def fetch_ai_news_enhanced(api_key, max_retries=3):
    """å¢å¼ºç‰ˆæ–°é—»è·å–ï¼Œå¸¦è¯¦ç»†æ—¥å¿—"""
    print(f"\nğŸ“° å¼€å§‹è·å–AIæ–°é—»...")
    
    if not api_key:
        print("âŒ APIå¯†é’¥ä¸ºç©ºï¼Œæ— æ³•è·å–æ–°é—»")
        return []
    
    # å¤šä¸ªæŸ¥è¯¢ç­–ç•¥ï¼Œå¢åŠ æˆåŠŸç‡
    search_queries = [
        {
            "q": "OpenAI OR ChatGPT OR GPT",
            "description": "OpenAIç›¸å…³æ–°é—»"
        },
        {
            "q": "artificial intelligence",
            "description": "äººå·¥æ™ºèƒ½æ–°é—»"
        },
        {
            "q": "AI technology",
            "description": "AIæŠ€æœ¯æ–°é—»"
        }
    ]
    
    all_articles = []
    
    for query_config in search_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query_config['description']}")
        
        for attempt in range(max_retries):
            try:
                print(f"   å°è¯• {attempt + 1}/{max_retries}...")
                
                # æ„å»ºè¯·æ±‚å‚æ•°
                params = {
                    "q": query_config["q"],
                    "lang": "en",
                    "country": "us",
                    "max": 5,  # æ¯ä¸ªæŸ¥è¯¢å°‘ä¸€ç‚¹ï¼Œé¿å…è¶…é™
                    "sortby": "publishedAt",
                    "apikey": api_key
                }
                
                query_string = urllib.parse.urlencode(params)
                url = f"https://gnews.io/api/v4/search?{query_string}"
                
                # å‘èµ·è¯·æ±‚
                req = urllib.request.Request(url)
                req.add_header('User-Agent', 'Mozilla/5.0 (compatible; NewsBot/1.0)')
                req.add_header('Accept', 'application/json')
                
                with urllib.request.urlopen(req, timeout=20) as response:
                    status_code = response.getcode()
                    print(f"   ğŸ“Š HTTPçŠ¶æ€: {status_code}")
                    
                    if status_code != 200:
                        print(f"   âŒ é200çŠ¶æ€ç : {status_code}")
                        continue
                    
                    # è§£æå“åº”
                    response_text = response.read().decode('utf-8')
                    data = json.loads(response_text)
                    
                    print(f"   ğŸ“Š APIå“åº”å¤§å°: {len(response_text)} å­—ç¬¦")
                    
                    # æ£€æŸ¥å“åº”ç»“æ„
                    if 'error' in data:
                        print(f"   âŒ APIé”™è¯¯: {data['error']}")
                        continue
                    
                    articles = data.get('articles', [])
                    print(f"   ğŸ“° è·å–åˆ° {len(articles)} æ¡æ–°é—»")
                    
                    if not articles:
                        print(f"   âš ï¸ æŸ¥è¯¢ç»“æœä¸ºç©º")
                        continue
                    
                    # å¤„ç†æ–‡ç« æ•°æ®
                    processed_count = 0
                    for i, article in enumerate(articles):
                        try:
                            # éªŒè¯å¿…è¦å­—æ®µ
                            if not article.get('title') or not article.get('url'):
                                print(f"     âš ï¸ è·³è¿‡æ— æ•ˆæ–‡ç«  #{i+1}")
                                continue
                            
                            processed_article = {
                                "id": f"gnews_{int(datetime.now().timestamp())}_{len(all_articles)}",
                                "title": article.get('title', 'æ— æ ‡é¢˜').strip(),
                                "summary": article.get('description', 'æ— æè¿°').strip(),
                                "source": article.get('source', {}).get('name', 'æœªçŸ¥æ¥æº'),
                                "url": article.get('url', ''),
                                "category": "AIç§‘æŠ€",
                                "time": format_publish_time(article.get('publishedAt')),
                                "publishedAt": article.get('publishedAt'),
                                "image": article.get('image'),
                                "raw_query": query_config["q"]
                            }
                            
                            all_articles.append(processed_article)
                            processed_count += 1
                            
                        except Exception as e:
                            print(f"     âŒ å¤„ç†æ–‡ç«  #{i+1} å¤±è´¥: {e}")
                            continue
                    
                    print(f"   âœ… æˆåŠŸå¤„ç† {processed_count} æ¡æ–°é—»")
                    break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                    
            except urllib.error.HTTPError as e:
                print(f"   âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
                if e.code == 429:
                    print(f"   â³ è¯·æ±‚è¿‡é¢‘ï¼Œç­‰å¾… {(attempt + 1) * 2} ç§’...")
                    time.sleep((attempt + 1) * 2)
                elif e.code in [401, 403]:
                    print(f"   ğŸ’¥ è®¤è¯é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                    break
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    print(f"   â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                    time.sleep(attempt + 1)
        
        # æŸ¥è¯¢é—´éš”ï¼Œé¿å…é¢‘ç‡é™åˆ¶
        if len(search_queries) > 1:
            print(f"   â³ æŸ¥è¯¢é—´éš” 2 ç§’...")
            time.sleep(2)
    
    print(f"\nğŸ“Š æ€»è®¡è·å– {len(all_articles)} æ¡æ–°é—»")
    
    # å»é‡å¤„ç†
    unique_articles = []
    seen_titles = set()
    for article in all_articles:
        title_key = article['title'].lower().strip()
        if title_key not in seen_titles:
            seen_titles.add(title_key)
            unique_articles.append(article)
        else:
            print(f"   ğŸ”„ è·³è¿‡é‡å¤æ–°é—»: {article['title'][:50]}...")
    
    print(f"ğŸ“Š å»é‡åä¿ç•™ {len(unique_articles)} æ¡æ–°é—»")
    return unique_articles

def format_publish_time(published_at):
    """æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´"""
    if not published_at:
        return "æ—¶é—´æœªçŸ¥"
    
    try:
        # è§£æISOæ—¶é—´æ ¼å¼
        if published_at.endswith('Z'):
            published_time = datetime.fromisoformat(published_at[:-1])
        else:
            published_time = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
        
        # è®¡ç®—æ—¶é—´å·®
        now = datetime.now()
        time_diff = now - published_time.replace(tzinfo=None)
        
        if time_diff.days > 0:
            return f"{time_diff.days}å¤©å‰"
        elif time_diff.seconds > 3600:
            hours = time_diff.seconds // 3600
            return f"{hours}å°æ—¶å‰"
        elif time_diff.seconds > 60:
            minutes = time_diff.seconds // 60
            return f"{minutes}åˆ†é’Ÿå‰"
        else:
            return "åˆšåˆš"
            
    except Exception as e:
        print(f"âš ï¸ æ—¶é—´è§£æå¤±è´¥: {e}")
        return "æ—¶é—´æœªçŸ¥"

def get_sample_articles():
    """è·å–ç¤ºä¾‹æ–‡ç« ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
    print("ğŸ”„ ä½¿ç”¨ç¤ºä¾‹æ•°æ®ä½œä¸ºå¤‡ç”¨...")
    return [
        {
            "id": "sample_emergency_1",
            "title": "ã€ç¤ºä¾‹æ•°æ®ã€‘OpenAIå‘å¸ƒæœ€æ–°GPTæ¨¡å‹ï¼ŒAIèƒ½åŠ›å†æ¬¡çªç ´",
            "summary": "è¿™æ˜¯ç¤ºä¾‹æ•°æ®ã€‚çœŸå®æ–°é—»è·å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯APIé…é¢ç”¨å®Œæˆ–ç½‘ç»œé—®é¢˜ã€‚è¯·æ£€æŸ¥GitHub Actionsæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚",
            "source": "ç¤ºä¾‹æ•°æ®",
            "url": "https://github.com/velist/ai-news-pusher",
            "category": "ç³»ç»Ÿæµ‹è¯•",
            "time": "ç¤ºä¾‹æ•°æ®",
            "is_sample": True
        },
        {
            "id": "sample_emergency_2",
            "title": "ã€ç¤ºä¾‹æ•°æ®ã€‘AIå·¥å…·åœ¨ä¼ä¸šä¸­çš„åº”ç”¨å‘ˆç°çˆ†å‘å¼å¢é•¿",
            "summary": "è¿™æ˜¯ç¤ºä¾‹æ•°æ®ã€‚å¦‚æœæ‚¨çœ‹åˆ°æ­¤å†…å®¹ï¼Œè¯´æ˜ç³»ç»Ÿå›é€€åˆ°äº†å¤‡ç”¨æ–¹æ¡ˆã€‚è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥ã€‚",
            "source": "ç¤ºä¾‹æ•°æ®",
            "url": "https://github.com/velist/ai-news-pusher/issues",
            "category": "ç³»ç»Ÿæµ‹è¯•",
            "time": "ç¤ºä¾‹æ•°æ®",
            "is_sample": True
        }
    ]

def generate_enhanced_html(articles, debug_info=None):
    """ç”Ÿæˆå¢å¼ºç‰ˆHTMLé¡µé¢ï¼ŒåŒ…å«è°ƒè¯•ä¿¡æ¯"""
    update_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S UTC')
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç¤ºä¾‹æ•°æ®
    has_real_data = any(not article.get('is_sample', False) for article in articles)
    sample_count = sum(1 for article in articles if article.get('is_sample', False))
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats_html = ""
    if debug_info:
        stats_html = f"""
        <div class="debug-info">
            <h3>ğŸ”§ ç³»ç»ŸçŠ¶æ€</h3>
            <ul>
                <li>APIå¯†é’¥çŠ¶æ€: {'âœ… æœ‰æ•ˆ' if debug_info.get('api_key_valid') else 'âŒ æ— æ•ˆ'}</li>
                <li>ç½‘ç»œè¿æ¥: {'âœ… æ­£å¸¸' if debug_info.get('network_ok') else 'âŒ å¼‚å¸¸'}</li>
                <li>APIæµ‹è¯•: {'âœ… é€šè¿‡' if debug_info.get('api_test_ok') else 'âŒ å¤±è´¥'}</li>
                <li>çœŸå®æ–°é—»: {len(articles) - sample_count} æ¡</li>
                <li>ç¤ºä¾‹æ•°æ®: {sample_count} æ¡</li>
            </ul>
        </div>
        """
    
    # çŠ¶æ€æç¤º
    status_alert = ""
    if not has_real_data:
        status_alert = f"""
        <div class="alert alert-warning">
            <h3>âš ï¸ ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹æ•°æ®</h3>
            <p>å½“å‰æ˜¾ç¤ºçš„æ˜¯ç¤ºä¾‹æ•°æ®ï¼Œå¯èƒ½çš„åŸå› ï¼š</p>
            <ul>
                <li>APIå¯†é’¥æ— æ•ˆæˆ–é…é¢ç”¨å®Œ</li>
                <li>ç½‘ç»œè¿æ¥é—®é¢˜</li>
                <li>GNewsæœåŠ¡æš‚æ—¶ä¸å¯ç”¨</li>
            </ul>
            <p>è¯·æ£€æŸ¥ <a href="https://github.com/velist/ai-news-pusher/actions" target="_blank">GitHub Actionsæ—¥å¿—</a> è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚</p>
        </div>
        """
    elif sample_count > 0:
        status_alert = f"""
        <div class="alert alert-info">
            <h3>â„¹ï¸ éƒ¨åˆ†æ•°æ®ä¸ºç¤ºä¾‹</h3>
            <p>è·å–åˆ° {len(articles) - sample_count} æ¡çœŸå®æ–°é—»ï¼Œ{sample_count} æ¡ç¤ºä¾‹æ•°æ®ã€‚</p>
        </div>
        """
    
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¤– AIç§‘æŠ€æ—¥æŠ¥ - æ™ºèƒ½æ–°é—»æ¨é€</title>
    <meta name="description" content="AIç§‘æŠ€æ—¥æŠ¥æä¾›æœ€æ–°çš„äººå·¥æ™ºèƒ½æ–°é—»ï¼Œä¸“æ³¨OpenAIã€ChatGPTç­‰å‰æ²¿ç§‘æŠ€èµ„è®¯">
    <meta name="keywords" content="AI,äººå·¥æ™ºèƒ½,OpenAI,ChatGPT,ç§‘æŠ€æ–°é—»,æœºå™¨å­¦ä¹ ">
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", sans-serif;
            line-height: 1.6; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh; color: #333;
        }}
        .container {{ max-width: 1200px; margin: 0 auto; padding: 20px; }}
        .header {{ 
            text-align: center; background: rgba(255,255,255,0.95); 
            border-radius: 20px; padding: 30px; margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1); backdrop-filter: blur(10px);
        }}
        .header h1 {{ 
            font-size: 2.5em; margin-bottom: 10px; font-weight: 700;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }}
        .header p {{ color: #666; font-size: 1.1em; margin-bottom: 15px; }}
        .update-time {{ 
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white; padding: 8px 20px; border-radius: 25px; 
            display: inline-block; font-weight: 500;
        }}
        .alert {{ 
            background: rgba(255, 193, 7, 0.1); border: 1px solid rgba(255, 193, 7, 0.5);
            color: #856404; padding: 20px; border-radius: 12px; margin: 20px 0;
            backdrop-filter: blur(10px);
        }}
        .alert h3 {{ margin-bottom: 10px; }}
        .alert ul {{ margin-left: 20px; }}
        .alert a {{ color: #007aff; text-decoration: none; }}
        .alert a:hover {{ text-decoration: underline; }}
        .alert-warning {{ border-color: rgba(255, 193, 7, 0.5); }}
        .alert-info {{ 
            background: rgba(0, 122, 255, 0.1); border-color: rgba(0, 122, 255, 0.5);
            color: #004085;
        }}
        .debug-info {{ 
            background: rgba(0, 0, 0, 0.05); padding: 15px; border-radius: 8px;
            margin: 20px 0; font-size: 0.9em;
        }}
        .debug-info ul {{ list-style: none; }}
        .debug-info li {{ margin: 5px 0; }}
        .stats {{ 
            display: flex; justify-content: center; gap: 30px; margin-top: 20px;
            flex-wrap: wrap;
        }}
        .stat-item {{ 
            background: rgba(102, 126, 234, 0.1); padding: 15px 25px; 
            border-radius: 12px; text-align: center; min-width: 120px;
        }}
        .stat-number {{ font-size: 1.8em; font-weight: 700; color: #667eea; }}
        .stat-label {{ font-size: 0.9em; color: #666; margin-top: 5px; }}
        .news-grid {{ 
            display: grid; grid-template-columns: repeat(auto-fit, minmax(380px, 1fr)); 
            gap: 25px; margin-top: 30px;
        }}
        .news-card {{ 
            background: rgba(255,255,255,0.95); border-radius: 16px; 
            padding: 25px; box-shadow: 0 8px 25px rgba(0,0,0,0.1);
            transition: all 0.3s ease; cursor: pointer; position: relative;
            backdrop-filter: blur(10px); border: 1px solid rgba(255,255,255,0.2);
        }}
        .news-card:hover {{ 
            transform: translateY(-5px); 
            box-shadow: 0 15px 40px rgba(0,0,0,0.15);
        }}
        .news-card.sample {{ 
            border: 2px solid #ffc107; 
            background: rgba(255, 243, 205, 0.9);
        }}
        .news-card::before {{ 
            content: ''; position: absolute; top: 0; left: 0; right: 0; 
            height: 4px; background: linear-gradient(90deg, #667eea, #764ba2);
            border-radius: 16px 16px 0 0;
        }}
        .news-card.sample::before {{ 
            background: linear-gradient(90deg, #ffc107, #ff8c00);
        }}
        .category-tag {{ 
            position: absolute; top: 15px; right: 15px;
            background: linear-gradient(45deg, #667eea, #764ba2); color: white;
            padding: 6px 12px; border-radius: 15px; font-size: 0.8em; 
            font-weight: 600; box-shadow: 0 2px 8px rgba(102, 126, 234, 0.3);
        }}
        .category-tag.sample {{ 
            background: linear-gradient(45deg, #ffc107, #ff8c00);
        }}
        .news-title {{ 
            font-size: 1.3em; font-weight: 600; color: #333; 
            margin-bottom: 15px; line-height: 1.4; padding-right: 100px;
        }}
        .news-summary {{ 
            color: #666; margin-bottom: 20px; line-height: 1.6;
            font-size: 0.95em;
        }}
        .news-meta {{ 
            display: flex; justify-content: space-between; align-items: center;
            padding-top: 15px; border-top: 1px solid #eee;
        }}
        .news-source {{ 
            font-weight: 600; color: #667eea; font-size: 0.9em;
        }}
        .news-time {{ 
            color: #999; font-size: 0.85em;
        }}
        .footer {{
            text-align: center; margin-top: 50px; padding: 30px;
            background: rgba(255,255,255,0.1); border-radius: 20px;
            backdrop-filter: blur(10px); color: rgba(255,255,255,0.8);
        }}
        .footer a {{ color: rgba(255,255,255,0.9); text-decoration: none; }}
        .footer a:hover {{ text-decoration: underline; }}
        @media (max-width: 768px) {{
            .container {{ padding: 15px; }}
            .header {{ padding: 20px; }}
            .header h1 {{ font-size: 2em; }}
            .news-grid {{ grid-template-columns: 1fr; }}
            .stats {{ gap: 15px; }}
            .news-title {{ padding-right: 80px; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– AIç§‘æŠ€æ—¥æŠ¥</h1>
            <p>ä¸“æ³¨äººå·¥æ™ºèƒ½å‰æ²¿èµ„è®¯ï¼Œæ¯æ—¥ç²¾é€‰ä¼˜è´¨å†…å®¹</p>
            <div class="update-time">æœ€åæ›´æ–°: {update_time}</div>
            <div class="stats">
                <div class="stat-item">
                    <div class="stat-number">{len(articles)}</div>
                    <div class="stat-label">æ€»æ–°é—»æ•°</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">{len(articles) - sample_count}</div>
                    <div class="stat-label">çœŸå®æ–°é—»</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">{'âœ…' if has_real_data else 'âŒ'}</div>
                    <div class="stat-label">æ•°æ®çŠ¶æ€</div>
                </div>
            </div>
            {stats_html}
        </div>
        
        {status_alert}
        
        <div class="news-grid">'''
    
    for article in articles:
        is_sample = article.get('is_sample', False)
        card_class = 'news-card sample' if is_sample else 'news-card'
        tag_class = 'category-tag sample' if is_sample else 'category-tag'
        
        html += f'''
            <div class="{card_class}" onclick="openDetail('{article.get('id', '')}')">
                <div class="{tag_class}">{article.get('category', 'ç§‘æŠ€')}</div>
                <h3 class="news-title">{article.get('title', 'æ— æ ‡é¢˜')}</h3>
                <p class="news-summary">{article.get('summary', 'æ— æ‘˜è¦')}</p>
                <div class="news-meta">
                    <span class="news-source">{article.get('source', 'æœªçŸ¥æ¥æº')}</span>
                    <span class="news-time">{article.get('time', 'æœªçŸ¥æ—¶é—´')}</span>
                </div>
            </div>'''
    
    html += f'''
        </div>
        
        <div class="footer">
            <p>ğŸ¤– æœ¬ç«™ç”±AIè‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–° | æ•°æ®æ¥æºï¼šGNews API</p>
            <p>ğŸ’¡ <a href="https://github.com/velist/ai-news-pusher" target="_blank">æŸ¥çœ‹æºç </a> | 
               ğŸ“Š <a href="https://github.com/velist/ai-news-pusher/actions" target="_blank">æŸ¥çœ‹æ—¥å¿—</a></p>
            <p style="margin-top: 15px; font-size: 0.9em; opacity: 0.8;">
                âš¡ ç³»ç»ŸçŠ¶æ€: {'ğŸŸ¢ æ­£å¸¸è¿è¡Œ' if has_real_data else 'ğŸŸ¡ ä½¿ç”¨å¤‡ç”¨æ•°æ®'} | 
                ğŸ”„ æ¯2å°æ—¶è‡ªåŠ¨æ›´æ–° | 
                ğŸ“± å“åº”å¼è®¾è®¡
            </p>
            {f'<p style="margin-top: 10px; font-size: 0.8em; opacity: 0.7;">âš ï¸ å½“å‰æ˜¾ç¤º {sample_count} æ¡ç¤ºä¾‹æ•°æ®</p>' if sample_count > 0 else ''}
        </div>
    </div>
    
    <script>
        function openDetail(articleId) {{
            if (articleId && !articleId.startsWith('sample_')) {{
                window.open('news/' + articleId + '.html', '_blank');
            }} else {{
                // ç¤ºä¾‹æ–‡ç« å¤„ç†
                if (articleId.startsWith('sample_emergency_')) {{
                    alert('è¿™æ˜¯ç³»ç»Ÿç¤ºä¾‹æ•°æ®ã€‚\\n\\nå¦‚éœ€æŸ¥çœ‹çœŸå®æ–°é—»ï¼Œè¯·:\\n1. æ£€æŸ¥APIå¯†é’¥é…ç½®\\n2. æŸ¥çœ‹GitHub Actionsæ—¥å¿—\\n3. ç¡®è®¤APIé…é¢å……è¶³');
                }} else {{
                    window.open('news/' + articleId + '.html', '_blank');
                }}
            }}
        }}
        
        // é¡µé¢åŠ è½½åŠ¨ç”»
        document.addEventListener('DOMContentLoaded', function() {{
            const cards = document.querySelectorAll('.news-card');
            cards.forEach((card, index) => {{
                card.style.opacity = '0';
                card.style.transform = 'translateY(20px)';
                setTimeout(() => {{
                    card.style.transition = 'all 0.5s ease';
                    card.style.opacity = '1';
                    card.style.transform = 'translateY(0)';
                }}, index * 100);
            }});
            
            // ç¤ºä¾‹æ•°æ®æç¤º
            const sampleCards = document.querySelectorAll('.news-card.sample');
            if (sampleCards.length > 0) {{
                console.warn('æ£€æµ‹åˆ°ç¤ºä¾‹æ•°æ®ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®');
            }}
        }});
    </script>
</body>
</html>'''
    
    return html

def generate_detail_page(article):
    """ç”Ÿæˆè¯¦æƒ…é¡µé¢"""
    is_sample = article.get('is_sample', False)
    
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{article.get('title', 'æ— æ ‡é¢˜')} - AIç§‘æŠ€æ—¥æŠ¥</title>
    <style>
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "PingFang SC", sans-serif;
            line-height: 1.8; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0; padding: 20px; min-height: 100vh;
        }}
        .container {{ max-width: 800px; margin: 0 auto; }}
        .back-btn {{ 
            background: rgba(255,255,255,0.9); color: #667eea; border: none;
            padding: 12px 24px; border-radius: 25px; text-decoration: none;
            display: inline-block; margin-bottom: 30px; font-weight: 600;
            transition: all 0.3s ease; box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }}
        .back-btn:hover {{ background: #667eea; color: white; transform: translateY(-2px); }}
        .article {{ 
            background: rgba(255,255,255,0.95); border-radius: 20px; 
            padding: 40px; box-shadow: 0 15px 40px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
            {'border: 2px solid #ffc107;' if is_sample else ''}
        }}
        .sample-warning {{
            background: rgba(255, 193, 7, 0.1); border: 1px solid rgba(255, 193, 7, 0.5);
            color: #856404; padding: 15px; border-radius: 8px; margin-bottom: 20px;
        }}
        .article-title {{ 
            font-size: 2.2em; font-weight: 700; color: #333; 
            margin-bottom: 20px; line-height: 1.3;
        }}
        .article-meta {{ 
            display: flex; justify-content: space-between; align-items: center;
            padding: 20px 0; border-bottom: 2px solid #f0f0f0; margin-bottom: 30px;
            flex-wrap: wrap; gap: 10px;
        }}
        .article-source {{ font-weight: 600; color: #667eea; font-size: 1.1em; }}
        .article-time {{ color: #666; }}
        .article-category {{ 
            background: linear-gradient(45deg, #667eea, #764ba2); color: white;
            padding: 8px 16px; border-radius: 20px; font-size: 0.9em; font-weight: 600;
            {'background: linear-gradient(45deg, #ffc107, #ff8c00);' if is_sample else ''}
        }}
        .article-content {{ 
            font-size: 1.1em; color: #444; line-height: 1.8; margin-bottom: 30px;
        }}
        .read-original {{ 
            background: linear-gradient(45deg, #667eea, #764ba2); color: white;
            padding: 15px 30px; border-radius: 30px; text-decoration: none;
            display: inline-block; font-weight: 600; transition: all 0.3s ease;
            box-shadow: 0 8px 20px rgba(102, 126, 234, 0.3);
        }}
        .read-original:hover {{ 
            transform: translateY(-3px); 
            box-shadow: 0 12px 25px rgba(102, 126, 234, 0.4);
        }}
        @media (max-width: 768px) {{
            .container {{ padding: 15px; }}
            .article {{ padding: 25px; }}
            .article-title {{ font-size: 1.8em; }}
            .article-meta {{ flex-direction: column; align-items: flex-start; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-btn">â† è¿”å›é¦–é¡µ</a>
        
        <div class="article">
            {'<div class="sample-warning">âš ï¸ è¿™æ˜¯ç¤ºä¾‹æ•°æ®ï¼Œä¸æ˜¯çœŸå®æ–°é—»å†…å®¹ã€‚</div>' if is_sample else ''}
            
            <h1 class="article-title">{article.get('title', 'æ— æ ‡é¢˜')}</h1>
            
            <div class="article-meta">
                <div>
                    <span class="article-source">{article.get('source', 'æœªçŸ¥æ¥æº')}</span>
                    <span class="article-time"> â€¢ {article.get('time', 'æœªçŸ¥æ—¶é—´')}</span>
                </div>
                <div class="article-category">{article.get('category', 'ç§‘æŠ€')}</div>
            </div>
            
            <div class="article-content">
                <p>{article.get('summary', 'æš‚æ— è¯¦ç»†å†…å®¹ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹é“¾æ¥æŸ¥çœ‹åŸæ–‡ã€‚')}</p>
                {f'<p style="margin-top: 20px; padding: 15px; background: rgba(0,0,0,0.05); border-radius: 8px;"><strong>è°ƒè¯•ä¿¡æ¯:</strong><br>æŸ¥è¯¢å…³é”®è¯: {article.get("raw_query", "æ— ")}<br>å‘å¸ƒæ—¶é—´: {article.get("publishedAt", "æ— ")}</p>' if not is_sample and article.get('raw_query') else ''}
            </div>
            
            <a href="{article.get('url', '#')}" target="_blank" class="read-original">
                {'æŸ¥çœ‹é¡¹ç›®æºç  â†’' if is_sample else 'é˜…è¯»åŸæ–‡ â†’'}
            </a>
        </div>
    </div>
</body>
</html>'''
    return html

def main():
    """ä¸»å‡½æ•° - GitHub Pagesé—®é¢˜ä¿®å¤ç‰ˆ"""
    print("ğŸ”§ GitHub Pagesé—®é¢˜ä¿®å¤ç‰ˆ - AIæ–°é—»æ¨é€")
    print("=" * 60)
    
    debug_info = {
        'api_key_valid': False,
        'network_ok': False,
        'api_test_ok': False
    }
    
    try:
        # 1. ç¯å¢ƒæ£€æŸ¥
        print("ğŸ” ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥...")
        load_env_file()
        
        # 2. ç½‘ç»œè¿æ¥æµ‹è¯•
        debug_info['network_ok'] = test_api_connectivity()
        
        # 3. APIå¯†é’¥éªŒè¯
        api_key = os.getenv('GNEWS_API_KEY')
        print(f"\nğŸ”‘ APIå¯†é’¥æ£€æŸ¥...")
        print(f"ç¯å¢ƒå˜é‡GNEWS_API_KEY: {'âœ… å·²è®¾ç½®' if api_key else 'âŒ æœªè®¾ç½®'}")
        
        if api_key:
            debug_info['api_key_valid'] = validate_api_key(api_key)
            if debug_info['api_key_valid']:
                # 4. APIåŠŸèƒ½æµ‹è¯•
                debug_info['api_test_ok'] = test_gnews_api(api_key)
        
        # 5. åˆ›å»ºç›®å½•
        print("\nğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
        os.makedirs('docs', exist_ok=True)
        os.makedirs('docs/news', exist_ok=True)
        print("âœ… ç›®å½•åˆ›å»ºå®Œæˆ")
        
        # 6. è·å–æ–°é—»æ•°æ®
        articles = []
        if debug_info['api_key_valid'] and debug_info['api_test_ok']:
            articles = fetch_ai_news_enhanced(api_key)
        
        # 7. å¦‚æœæ²¡æœ‰è·å–åˆ°çœŸå®æ–°é—»ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®
        if not articles:
            print("ğŸ”„ æœªè·å–åˆ°çœŸå®æ–°é—»ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            articles = get_sample_articles()
        
        print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
        real_count = sum(1 for a in articles if not a.get('is_sample', False))
        sample_count = sum(1 for a in articles if a.get('is_sample', False))
        print(f"  çœŸå®æ–°é—»: {real_count} æ¡")
        print(f"  ç¤ºä¾‹æ•°æ®: {sample_count} æ¡")
        print(f"  æ€»è®¡: {len(articles)} æ¡")
        
        # 8. ç”ŸæˆHTMLé¡µé¢
        print("\nğŸŒ ç”Ÿæˆç½‘é¡µ...")
        html_content = generate_enhanced_html(articles, debug_info)
        
        with open('docs/index.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        html_size = len(html_content)
        print(f"âœ… ä¸»é¡µç”Ÿæˆå®Œæˆ: {html_size:,} å­—ç¬¦")
        
        # 9. ç”Ÿæˆè¯¦æƒ…é¡µ
        print("\nğŸ“„ ç”Ÿæˆè¯¦æƒ…é¡µ...")
        detail_count = 0
        for article in articles:
            try:
                detail_html = generate_detail_page(article)
                detail_path = f"docs/news/{article['id']}.html"
                with open(detail_path, 'w', encoding='utf-8') as f:
                    f.write(detail_html)
                detail_count += 1
            except Exception as e:
                print(f"âš ï¸ è¯¦æƒ…é¡µç”Ÿæˆå¤±è´¥ {article.get('id', 'unknown')}: {e}")
        
        print(f"âœ… è¯¦æƒ…é¡µç”Ÿæˆå®Œæˆ: {detail_count} ä¸ª")
        
        # 10. ä¿å­˜æ•°æ®æ–‡ä»¶
        print("\nğŸ’¾ ä¿å­˜æ•°æ®æ–‡ä»¶...")
        news_data = {
            'last_updated': datetime.now().isoformat(),
            'update_timestamp': int(datetime.now().timestamp()),
            'total_count': len(articles),
            'real_news_count': real_count,
            'sample_count': sample_count,
            'debug_info': debug_info,
            'system_status': {
                'api_key_configured': api_key is not None,
                'api_key_valid': debug_info['api_key_valid'],
                'network_connection': debug_info['network_ok'],
                'api_service': debug_info['api_test_ok'],
                'data_source': 'real' if real_count > 0 else 'sample'
            },
            'articles': articles
        }
        
        with open('docs/news_data.json', 'w', encoding='utf-8') as f:
            json.dump(news_data, f, ensure_ascii=False, indent=2, default=str)
        
        data_size = os.path.getsize('docs/news_data.json')
        print(f"âœ… æ•°æ®æ–‡ä»¶ä¿å­˜å®Œæˆ: {data_size:,} å­—èŠ‚")
        
        # 11. æ–‡ä»¶éªŒè¯
        print("\nğŸ” æ–‡ä»¶éªŒè¯...")
        required_files = ['docs/index.html', 'docs/news_data.json']
        all_good = True
        
        for file_path in required_files:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                print(f"âœ… {file_path}: {size:,} å­—èŠ‚")
            else:
                print(f"âŒ {file_path}: æ–‡ä»¶ä¸å­˜åœ¨")
                all_good = False
        
        # 12. æœ€ç»ˆçŠ¶æ€æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ“Š æœ€ç»ˆçŠ¶æ€æŠ¥å‘Š")
        print("=" * 60)
        print(f"ğŸ”‘ APIå¯†é’¥çŠ¶æ€: {'âœ… æœ‰æ•ˆ' if debug_info['api_key_valid'] else 'âŒ æ— æ•ˆ'}")
        print(f"ğŸŒ ç½‘ç»œè¿æ¥: {'âœ… æ­£å¸¸' if debug_info['network_ok'] else 'âŒ å¼‚å¸¸'}")
        print(f"ğŸ§ª APIæµ‹è¯•: {'âœ… é€šè¿‡' if debug_info['api_test_ok'] else 'âŒ å¤±è´¥'}")
        print(f"ğŸ“° çœŸå®æ–°é—»: {real_count} æ¡")
        print(f"ğŸ”„ ç¤ºä¾‹æ•°æ®: {sample_count} æ¡")
        print(f"ğŸ“ æ–‡ä»¶ç”Ÿæˆ: {'âœ… å®Œæˆ' if all_good else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
        print(f"ğŸ¯ GitHub Pages: https://velist.github.io/ai-news-pusher/docs/")
        
        success = all_good and len(articles) > 0
        print(f"\nğŸ‰ ä»»åŠ¡çŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âš ï¸ éƒ¨åˆ†æˆåŠŸ'}")
        
        if real_count == 0:
            print("\nâš ï¸ æ³¨æ„äº‹é¡¹:")
            print("- å½“å‰ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
            print("- æŸ¥çœ‹GitHub Actionsæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")
            print("- ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆä¸”é…é¢å……è¶³")
        
        return success
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        
        # ç´§æ€¥å¤‡ç”¨æ–¹æ¡ˆ
        print("\nğŸ†˜ å¯åŠ¨ç´§æ€¥å¤‡ç”¨æ–¹æ¡ˆ...")
        try:
            os.makedirs('docs', exist_ok=True)
            os.makedirs('docs/news', exist_ok=True)
            
            emergency_articles = get_sample_articles()
            emergency_html = generate_enhanced_html(emergency_articles, {
                'api_key_valid': False,
                'network_ok': False,
                'api_test_ok': False
            })
            
            with open('docs/index.html', 'w', encoding='utf-8') as f:
                f.write(emergency_html)
            
            for article in emergency_articles:
                detail_html = generate_detail_page(article)
                with open(f"docs/news/{article['id']}.html", 'w', encoding='utf-8') as f:
                    f.write(detail_html)
            
            print("âœ… ç´§æ€¥å¤‡ç”¨é¡µé¢å·²ç”Ÿæˆ")
            return True
            
        except Exception as e2:
            print(f"âŒ ç´§æ€¥å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
            return False

if __name__ == "__main__":
    success = main()
    print(f"\né€€å‡ºçŠ¶æ€: {'SUCCESS' if success else 'PARTIAL_SUCCESS'}")
    sys.exit(0)  # æ€»æ˜¯è¿”å›0ï¼Œé¿å…GitHub Actionså¤±è´¥
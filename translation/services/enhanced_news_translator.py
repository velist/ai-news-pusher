#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆæ–°é—»ç¿»è¯‘å™¨ - ä¸“é—¨ä¼˜åŒ–æ–°é—»æ ‡é¢˜å’Œæè¿°ç¿»è¯‘è´¨é‡
"""

import os
import json
import time
import urllib.request
import urllib.parse
from typing import List, Optional, Dict, Tuple
from datetime import datetime

from ..core.interfaces import ITranslationService, TranslationResult, ServiceStatus


class EnhancedNewsTranslator(ITranslationService):
    """å¢å¼ºç‰ˆæ–°é—»ç¿»è¯‘å™¨ï¼Œä¸“é—¨é’ˆå¯¹æ–°é—»å†…å®¹ä¼˜åŒ–"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "Qwen/Qwen2.5-7B-Instruct"):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆæ–°é—»ç¿»è¯‘å™¨
        
        Args:
            api_key: ç¡…åŸºæµåŠ¨APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv('SILICONFLOW_API_KEY')
        self.model = model
        self.base_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.max_retries = 3
        self.retry_delay = 1.0
        
        if not self.api_key:
            raise ValueError("ç¡…åŸºæµåŠ¨APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")
        
        # ä¸“ä¸šæœ¯è¯­æ˜ å°„è¡¨ - æ‰©å±•ç‰ˆ
        self.tech_terms = {
            # AIå’Œæœºå™¨å­¦ä¹ 
            'OpenAI': 'OpenAI',
            'ChatGPT': 'ChatGPT', 
            'GPT-4': 'GPT-4',
            'GPT-5': 'GPT-5',
            'GPT-4o': 'GPT-4o',
            'Claude': 'Claude',
            'Gemini': 'Gemini',
            'Bard': 'Bard',
            'AI': 'äººå·¥æ™ºèƒ½',
            'artificial intelligence': 'äººå·¥æ™ºèƒ½',
            'machine learning': 'æœºå™¨å­¦ä¹ ',
            'deep learning': 'æ·±åº¦å­¦ä¹ ',
            'neural network': 'ç¥ç»ç½‘ç»œ',
            'transformer': 'Transformer',
            'LLM': 'å¤§è¯­è¨€æ¨¡å‹',
            'large language model': 'å¤§è¯­è¨€æ¨¡å‹',
            'generative AI': 'ç”Ÿæˆå¼AI',
            'AGI': 'é€šç”¨äººå·¥æ™ºèƒ½',
            'computer vision': 'è®¡ç®—æœºè§†è§‰',
            'natural language processing': 'è‡ªç„¶è¯­è¨€å¤„ç†',
            'NLP': 'è‡ªç„¶è¯­è¨€å¤„ç†',
            'reinforcement learning': 'å¼ºåŒ–å­¦ä¹ ',
            
            # åŒºå—é“¾å’ŒåŠ å¯†è´§å¸
            'blockchain': 'åŒºå—é“¾',
            'cryptocurrency': 'åŠ å¯†è´§å¸',
            'crypto': 'åŠ å¯†è´§å¸',
            'bitcoin': 'æ¯”ç‰¹å¸',
            'Bitcoin': 'æ¯”ç‰¹å¸',
            'BTC': 'æ¯”ç‰¹å¸',
            'ethereum': 'ä»¥å¤ªåŠ',
            'Ethereum': 'ä»¥å¤ªåŠ',
            'ETH': 'ä»¥å¤ªåŠ',
            'DeFi': 'å»ä¸­å¿ƒåŒ–é‡‘è',
            'NFT': 'éåŒè´¨åŒ–ä»£å¸',
            'Web3': 'Web3',
            'smart contract': 'æ™ºèƒ½åˆçº¦',
            'mining': 'æŒ–çŸ¿',
            'wallet': 'é’±åŒ…',
            'exchange': 'äº¤æ˜“æ‰€',
            'staking': 'è´¨æŠ¼',
            'yield farming': 'æµåŠ¨æ€§æŒ–çŸ¿',
            
            # å…ƒå®‡å®™å’ŒXRæŠ€æœ¯
            'metaverse': 'å…ƒå®‡å®™',
            'VR': 'è™šæ‹Ÿç°å®',
            'virtual reality': 'è™šæ‹Ÿç°å®',
            'AR': 'å¢å¼ºç°å®',
            'augmented reality': 'å¢å¼ºç°å®',
            'MR': 'æ··åˆç°å®',
            'mixed reality': 'æ··åˆç°å®',
            'XR': 'æ‰©å±•ç°å®',
            'extended reality': 'æ‰©å±•ç°å®',
            
            # äº‘è®¡ç®—å’ŒåŸºç¡€è®¾æ–½
            'cloud computing': 'äº‘è®¡ç®—',
            'cloud': 'äº‘',
            'serverless': 'æ— æœåŠ¡å™¨',
            'microservices': 'å¾®æœåŠ¡',
            'containerization': 'å®¹å™¨åŒ–',
            'DevOps': 'DevOps',
            'CI/CD': 'æŒç»­é›†æˆ/æŒç»­éƒ¨ç½²',
            'edge computing': 'è¾¹ç¼˜è®¡ç®—',
            'CDN': 'å†…å®¹åˆ†å‘ç½‘ç»œ',
            
            # æ•°æ®å’Œåˆ†æ
            'big data': 'å¤§æ•°æ®',
            'data science': 'æ•°æ®ç§‘å­¦',
            'analytics': 'åˆ†æ',
            'business intelligence': 'å•†ä¸šæ™ºèƒ½',
            'BI': 'å•†ä¸šæ™ºèƒ½',
            'data mining': 'æ•°æ®æŒ–æ˜',
            'predictive analytics': 'é¢„æµ‹åˆ†æ',
            
            # ç‰©è”ç½‘å’Œè¿æ¥æŠ€æœ¯
            'IoT': 'ç‰©è”ç½‘',
            'Internet of Things': 'ç‰©è”ç½‘',
            '5G': '5G',
            '6G': '6G',
            'WiFi 6': 'WiFi 6',
            'WiFi 7': 'WiFi 7',
            'Bluetooth': 'è“ç‰™',
            'NFC': 'è¿‘åœºé€šä¿¡',
            
            # æ–°å…´æŠ€æœ¯
            'quantum computing': 'é‡å­è®¡ç®—',
            'quantum': 'é‡å­',
            'cybersecurity': 'ç½‘ç»œå®‰å…¨',
            'cyber security': 'ç½‘ç»œå®‰å…¨',
            'robotics': 'æœºå™¨äººæŠ€æœ¯',
            'automation': 'è‡ªåŠ¨åŒ–',
            'autonomous': 'è‡ªä¸»',
            'self-driving': 'è‡ªåŠ¨é©¾é©¶',
            'electric vehicle': 'ç”µåŠ¨æ±½è½¦',
            'EV': 'ç”µåŠ¨æ±½è½¦',
            'renewable energy': 'å¯å†ç”Ÿèƒ½æº',
            'solar': 'å¤ªé˜³èƒ½',
            'battery': 'ç”µæ± ',
            
            # é‡‘èç§‘æŠ€
            'fintech': 'é‡‘èç§‘æŠ€',
            'digital payment': 'æ•°å­—æ”¯ä»˜',
            'mobile payment': 'ç§»åŠ¨æ”¯ä»˜',
            'e-commerce': 'ç”µå­å•†åŠ¡',
            'marketplace': 'å¸‚åœºå¹³å°',
            'subscription': 'è®¢é˜…',
            'SaaS': 'è½¯ä»¶å³æœåŠ¡',
            'PaaS': 'å¹³å°å³æœåŠ¡',
            'IaaS': 'åŸºç¡€è®¾æ–½å³æœåŠ¡',
            
            # å•†ä¸šå’ŒæŠ•èµ„
            'startup': 'åˆåˆ›å…¬å¸',
            'unicorn': 'ç‹¬è§’å…½å…¬å¸',
            'IPO': 'é¦–æ¬¡å…¬å¼€å‹Ÿè‚¡',
            'venture capital': 'é£é™©æŠ•èµ„',
            'VC': 'é£é™©æŠ•èµ„',
            'private equity': 'ç§å‹Ÿè‚¡æƒ',
            'merger': 'åˆå¹¶',
            'acquisition': 'æ”¶è´­',
            'M&A': 'å¹¶è´­',
            'valuation': 'ä¼°å€¼',
            'funding': 'èèµ„',
            'Series A': 'Aè½®èèµ„',
            'Series B': 'Bè½®èèµ„',
            'Series C': 'Cè½®èèµ„',
            
            # åœ°ç†å’Œåœ°åŒº
            'Silicon Valley': 'ç¡…è°·',
            'Wall Street': 'åå°”è¡—',
            'NASDAQ': 'çº³æ–¯è¾¾å…‹',
            'NYSE': 'çº½çº¦è¯åˆ¸äº¤æ˜“æ‰€',
            
            # ä¸»è¦ç§‘æŠ€å…¬å¸
            'Tesla': 'ç‰¹æ–¯æ‹‰',
            'SpaceX': 'SpaceX',
            'Meta': 'Meta',
            'Google': 'è°·æ­Œ',
            'Alphabet': 'Alphabet',
            'Microsoft': 'å¾®è½¯',
            'Apple': 'è‹¹æœ',
            'Amazon': 'äºšé©¬é€Š',
            'Netflix': 'å¥ˆé£',
            'Uber': 'ä¼˜æ­¥',
            'Airbnb': 'Airbnb',
            'PayPal': 'PayPal',
            'Salesforce': 'Salesforce',
            'Oracle': 'ç”²éª¨æ–‡',
            'IBM': 'IBM',
            'Intel': 'è‹±ç‰¹å°”',
            'AMD': 'AMD',
            'NVIDIA': 'è‹±ä¼Ÿè¾¾',
            'Qualcomm': 'é«˜é€š',
            'Samsung': 'ä¸‰æ˜Ÿ',
            'TSMC': 'å°ç§¯ç”µ',
            
            # æ¸¸æˆå’Œå¨±ä¹
            'PlayStation': 'PlayStation',
            'PS5': 'PS5',
            'Xbox': 'Xbox',
            'Nintendo': 'ä»»å¤©å ‚',
            'Switch': 'Switch',
            'Steam': 'Steam',
            'Epic Games': 'Epic Games',
            'Fortnite': 'å ¡å’ä¹‹å¤œ',
            'Minecraft': 'æˆ‘çš„ä¸–ç•Œ',
            'esports': 'ç”µå­ç«æŠ€',
            'gaming': 'æ¸¸æˆ',
            'streamer': 'ä¸»æ’­',
            'Twitch': 'Twitch',
            'YouTube Gaming': 'YouTube Gaming',
            
            # ç¤¾äº¤åª’ä½“å’Œé€šä¿¡
            'TikTok': 'TikTok',
            'YouTube': 'YouTube',
            'Twitter': 'æ¨ç‰¹',
            'X': 'X',
            'Facebook': 'è„¸ä¹¦',
            'Instagram': 'Instagram',
            'WhatsApp': 'WhatsApp',
            'Telegram': 'Telegram',
            'Discord': 'Discord',
            'Snapchat': 'Snapchat',
            'LinkedIn': 'é¢†è‹±',
            'Reddit': 'Reddit',
            'Pinterest': 'Pinterest',
            
            # å·¥ä½œå’Œåä½œå·¥å…·
            'Zoom': 'Zoom',
            'Teams': 'Teams',
            'Slack': 'Slack',
            'Notion': 'Notion',
            'Figma': 'Figma',
            'Canva': 'Canva',
            'Dropbox': 'Dropbox',
            'Google Drive': 'Google Drive',
            'OneDrive': 'OneDrive',
            
            # å¼€å‘å’ŒæŠ€æœ¯å·¥å…·
            'GitHub': 'GitHub',
            'GitLab': 'GitLab',
            'Docker': 'Docker',
            'Kubernetes': 'Kubernetes',
            'Jenkins': 'Jenkins',
            'Terraform': 'Terraform',
            'React': 'React',
            'Vue': 'Vue',
            'Angular': 'Angular',
            'Node.js': 'Node.js',
            'Python': 'Python',
            'JavaScript': 'JavaScript',
            'TypeScript': 'TypeScript',
            'Java': 'Java',
            'C++': 'C++',
            'Go': 'Go',
            'Rust': 'Rust',
            
            # äº‘æœåŠ¡å¹³å°
            'AWS': 'AWS',
            'Amazon Web Services': 'äºšé©¬é€Šäº‘æœåŠ¡',
            'Azure': 'Azure',
            'Microsoft Azure': 'å¾®è½¯Azure',
            'GCP': 'GCP',
            'Google Cloud': 'è°·æ­Œäº‘',
            'Alibaba Cloud': 'é˜¿é‡Œäº‘',
            'Tencent Cloud': 'è…¾è®¯äº‘',
            
            # æ“ä½œç³»ç»Ÿå’Œå¹³å°
            'Windows': 'Windows',
            'macOS': 'macOS',
            'iOS': 'iOS',
            'Android': 'Android',
            'Linux': 'Linux',
            'Ubuntu': 'Ubuntu',
            'Chrome OS': 'Chrome OS'
        }
        
        # æ–°é—»ç±»åˆ«ç‰¹å®šçš„ç¿»è¯‘ç­–ç•¥
        self.category_strategies = {
            'AIç§‘æŠ€': {
                'focus': 'æŠ€æœ¯åˆ›æ–°ã€äº§å“å‘å¸ƒã€è¡Œä¸šå½±å“',
                'tone': 'ä¸“ä¸šã€å‡†ç¡®ã€å‰ç»æ€§',
                'keywords': ['AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'æ¨¡å‹']
            },
            'æ¸¸æˆç§‘æŠ€': {
                'focus': 'æ¸¸æˆä½“éªŒã€ç¡¬ä»¶æ€§èƒ½ã€å¸‚åœºè¡¨ç°',
                'tone': 'ç”ŸåŠ¨ã€å¸å¼•äººã€å¨±ä¹æ€§',
                'keywords': ['æ¸¸æˆ', 'ä¸»æœº', 'ä½“éªŒ', 'ç©å®¶', 'å‘å¸ƒ', 'æ›´æ–°']
            },
            'ç»æµé‡‘è': {
                'focus': 'å¸‚åœºåŠ¨æ€ã€æŠ•èµ„æœºä¼šã€é£é™©è¯„ä¼°',
                'tone': 'å®¢è§‚ã€ä¸¥è°¨ã€æ•°æ®å¯¼å‘',
                'keywords': ['å¸‚åœº', 'æŠ•èµ„', 'è‚¡ä»·', 'æ”¶ç›Š', 'å¢é•¿', 'é£é™©']
            },
            'ç§‘æŠ€åˆ›æ–°': {
                'focus': 'æŠ€æœ¯çªç ´ã€äº§å“åˆ›æ–°ã€è¡Œä¸šå˜é©',
                'tone': 'åˆ›æ–°ã€å‰æ²¿ã€å½±å“åŠ›',
                'keywords': ['åˆ›æ–°', 'æŠ€æœ¯', 'çªç ´', 'å‘å¸ƒ', 'å‡çº§', 'å˜é©']
            }
        }
    
    def get_service_name(self) -> str:
        """è·å–æœåŠ¡åç§°"""
        return f"enhanced_news_{self.model.split('/')[-1]}"
    
    def _create_title_translation_prompt(self, title: str, category: str = "") -> str:
        """åˆ›å»ºæ ‡é¢˜ç¿»è¯‘çš„ä¸“é—¨æç¤ºè¯"""
        
        # è·å–ç±»åˆ«ç‰¹å®šç­–ç•¥
        strategy = self.category_strategies.get(category, {
            'focus': 'å‡†ç¡®ä¼ è¾¾æ ¸å¿ƒä¿¡æ¯',
            'tone': 'å®¢è§‚ã€ä¸“ä¸š',
            'keywords': ['æ–°é—»', 'èµ„è®¯', 'åŠ¨æ€']
        })
        
        # æ ¹æ®ç±»åˆ«ç”Ÿæˆç‰¹å®šçš„ç¿»è¯‘æŒ‡å¯¼
        category_guidance = self._get_category_specific_guidance(category)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘æŠ€æ–°é—»æ ‡é¢˜ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

ã€ç¿»è¯‘åŸåˆ™ã€‘
1. å‡†ç¡®æ€§ï¼šä¿æŒåŸæ–‡çš„æ ¸å¿ƒä¿¡æ¯å’Œå…³é”®äº‹å®ï¼Œä¸èƒ½é—æ¼é‡è¦ä¿¡æ¯
2. è‡ªç„¶æ€§ï¼šä½¿ç”¨ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯çš„è¯­è¨€ï¼Œé¿å…ç›´è¯‘å’Œç”Ÿç¡¬è¡¨è¾¾
3. å¸å¼•åŠ›ï¼šä¿æŒæ–°é—»æ ‡é¢˜çš„å¸å¼•åŠ›å’Œå¯è¯»æ€§ï¼Œé€‚åˆä¸­æ–‡è¯»è€…
4. ä¸“ä¸šæ€§ï¼šæ­£ç¡®ç¿»è¯‘ä¸“ä¸šæœ¯è¯­å’Œå…¬å¸åç§°ï¼Œä¿æŒè¡Œä¸šå‡†ç¡®æ€§

ã€ç±»åˆ«ç‰¹ç‚¹ã€‘{category}
- å…³æ³¨é‡ç‚¹ï¼š{strategy['focus']}
- è¯­è¨€é£æ ¼ï¼š{strategy['tone']}
- å…³é”®è¯æ±‡ï¼š{', '.join(strategy['keywords'])}

{category_guidance}

ã€ä¸“ä¸šæœ¯è¯­å¤„ç†è§„åˆ™ã€‘
- çŸ¥åå“ç‰Œä¿æŒåŸåï¼šOpenAI, ChatGPT, Tesla, Meta, Googleç­‰
- æŠ€æœ¯æœ¯è¯­ä½¿ç”¨æ ‡å‡†ä¸­æ–‡ï¼šAIâ†’äººå·¥æ™ºèƒ½, blockchainâ†’åŒºå—é“¾, VRâ†’è™šæ‹Ÿç°å®
- æ•°å­—ä¿¡æ¯ä¿æŒåŸæ ·ï¼šä»·æ ¼ã€æ—¥æœŸã€ç™¾åˆ†æ¯”ã€ç‰ˆæœ¬å·ç­‰
- å…¬å¸åç§°ä½¿ç”¨é€šç”¨ä¸­æ–‡åï¼šGoogleâ†’è°·æ­Œ, Microsoftâ†’å¾®è½¯, Appleâ†’è‹¹æœ

ã€ç¿»è¯‘è´¨é‡è¦æ±‚ã€‘
- æ ‡é¢˜é•¿åº¦é€‚ä¸­ï¼Œé€šå¸¸15-30ä¸ªä¸­æ–‡å­—ç¬¦
- çªå‡ºæ ¸å¿ƒä¿¡æ¯ï¼Œé¿å…å†—ä½™è¡¨è¾¾
- ä¿æŒæ—¶æ•ˆæ€§å’Œæ–°é—»ä»·å€¼
- ç¬¦åˆä¸­æ–‡æ–°é—»æ ‡é¢˜çš„è¡¨è¾¾ä¹ æƒ¯

ã€æ ¼å¼è¦æ±‚ã€‘
åªè¿”å›ç¿»è¯‘åçš„ä¸­æ–‡æ ‡é¢˜ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€å¼•å·æˆ–å…¶ä»–æ ‡ç‚¹ã€‚

è‹±æ–‡æ ‡é¢˜ï¼š{title}

ä¸­æ–‡æ ‡é¢˜ï¼š"""
        
        return prompt
    
    def _get_category_specific_guidance(self, category: str) -> str:
        """è·å–ç±»åˆ«ç‰¹å®šçš„ç¿»è¯‘æŒ‡å¯¼"""
        guidance_map = {
            'AIç§‘æŠ€': """
ã€AIç§‘æŠ€ç±»åˆ«ç‰¹æ®Šè¦æ±‚ã€‘
- çªå‡ºæŠ€æœ¯çªç ´å’Œåˆ›æ–°ç‚¹ï¼šå¦‚"çªç ´æ€§è¿›å±•"ã€"é‡å¤§æ›´æ–°"ã€"å…¨æ–°åŠŸèƒ½"
- å¼ºè°ƒåº”ç”¨åœºæ™¯å’Œå½±å“ï¼šå¦‚"æ”¹å˜è¡Œä¸š"ã€"æå‡æ•ˆç‡"ã€"ç”¨æˆ·ä½“éªŒ"
- ä¿æŒæŠ€æœ¯æœ¯è¯­å‡†ç¡®æ€§ï¼šGPT-4â†’GPT-4, LLMâ†’å¤§è¯­è¨€æ¨¡å‹, AGIâ†’é€šç”¨äººå·¥æ™ºèƒ½
- ä½“ç°å‰ç»æ€§å’Œé‡è¦æ€§ï¼šå¦‚"å¼•é¢†æœªæ¥"ã€"é¢ è¦†æ€§"ã€"é‡Œç¨‹ç¢‘"
- å¸¸ç”¨è¡¨è¾¾ï¼šå‘å¸ƒã€æ¨å‡ºã€å‡çº§ã€ä¼˜åŒ–ã€é›†æˆã€èµ‹èƒ½""",
            
            'æ¸¸æˆç§‘æŠ€': """
ã€æ¸¸æˆç§‘æŠ€ç±»åˆ«ç‰¹æ®Šè¦æ±‚ã€‘
- çªå‡ºæ¸¸æˆä½“éªŒå’Œæ€§èƒ½ï¼šå¦‚"æ²‰æµ¸å¼ä½“éªŒ"ã€"æµç•…è¿è¡Œ"ã€"ç”»è´¨æå‡"
- å¼ºè°ƒå¨±ä¹æ€§å’Œå¸å¼•åŠ›ï¼šå¦‚"éœ‡æ’¼ç™»åœº"ã€"ç²¾å½©å‘ˆç°"ã€"ç©å®¶æœŸå¾…"
- ä¿æŒæ¸¸æˆæœ¯è¯­å‡†ç¡®æ€§ï¼šPlayStationâ†’PlayStation, Xboxâ†’Xbox, Switchâ†’Switch
- ä½“ç°å¸‚åœºè¡¨ç°å’Œå½±å“ï¼šå¦‚"çƒ­é”€"ã€"å¥½è¯„å¦‚æ½®"ã€"å¼•å‘çƒ­è®®"
- å¸¸ç”¨è¡¨è¾¾ï¼šå‘å”®ã€ä¸Šçº¿ã€æ›´æ–°ã€æ‰©å±•ã€è”åŠ¨ã€ç«æŠ€""",
            
            'ç»æµé‡‘è': """
ã€ç»æµé‡‘èç±»åˆ«ç‰¹æ®Šè¦æ±‚ã€‘
- çªå‡ºå¸‚åœºåŠ¨æ€å’Œæ•°æ®ï¼šå¦‚"è‚¡ä»·ä¸Šæ¶¨"ã€"å¸‚å€¼çªç ´"ã€"ä¸šç»©å¢é•¿"
- å¼ºè°ƒæŠ•èµ„ä»·å€¼å’Œé£é™©ï¼šå¦‚"æŠ•èµ„æœºä¼š"ã€"é£é™©æç¤º"ã€"æ”¶ç›Šé¢„æœŸ"
- ä¿æŒé‡‘èæœ¯è¯­å‡†ç¡®æ€§ï¼šIPOâ†’é¦–æ¬¡å…¬å¼€å‹Ÿè‚¡, VCâ†’é£é™©æŠ•èµ„, M&Aâ†’å¹¶è´­
- ä½“ç°å®¢è§‚æ€§å’Œæ•°æ®æ”¯æ’‘ï¼šå¦‚"æ•°æ®æ˜¾ç¤º"ã€"åˆ†æå¸ˆé¢„æµ‹"ã€"è´¢æŠ¥æŠ«éœ²"
- å¸¸ç”¨è¡¨è¾¾ï¼šèèµ„ã€ä¸Šå¸‚ã€æ”¶è´­ã€å¢é•¿ã€ä¸‹è·Œã€é¢„æœŸ""",
            
            'ç§‘æŠ€åˆ›æ–°': """
ã€ç§‘æŠ€åˆ›æ–°ç±»åˆ«ç‰¹æ®Šè¦æ±‚ã€‘
- çªå‡ºåˆ›æ–°æ€§å’ŒæŠ€æœ¯ä»·å€¼ï¼šå¦‚"åˆ›æ–°çªç ´"ã€"æŠ€æœ¯é©æ–°"ã€"äº§å“å‡çº§"
- å¼ºè°ƒè¡Œä¸šå½±å“å’Œå˜é©ï¼šå¦‚"è¡Œä¸šå˜é©"ã€"å¸‚åœºé¢†å…ˆ"ã€"ç«äº‰ä¼˜åŠ¿"
- ä¿æŒç§‘æŠ€æœ¯è¯­å‡†ç¡®æ€§ï¼šäº‘è®¡ç®—â†’äº‘è®¡ç®—, 5Gâ†’5G, IoTâ†’ç‰©è”ç½‘
- ä½“ç°å‘å±•è¶‹åŠ¿å’Œå‰æ™¯ï¼šå¦‚"æœªæ¥è¶‹åŠ¿"ã€"å‘å±•å‰æ™¯"ã€"å¸‚åœºæ½œåŠ›"
- å¸¸ç”¨è¡¨è¾¾ï¼šæ¨å‡ºã€å‘å¸ƒã€åˆ›æ–°ã€å‡çº§ã€æ•´åˆã€æ‹“å±•"""
        }
        
        return guidance_map.get(category, """
ã€é€šç”¨ç§‘æŠ€æ–°é—»è¦æ±‚ã€‘
- ä¿æŒå®¢è§‚å‡†ç¡®çš„è¡¨è¾¾
- çªå‡ºæ–°é—»ä»·å€¼å’Œæ—¶æ•ˆæ€§
- ä½¿ç”¨æ ‡å‡†çš„ç§‘æŠ€æœ¯è¯­ç¿»è¯‘
- ä½“ç°ä¸“ä¸šæ€§å’Œå¯è¯»æ€§""")
    
    
    def _create_description_translation_prompt(self, description: str, title: str = "", category: str = "") -> str:
        """åˆ›å»ºæè¿°ç¿»è¯‘çš„ä¸“é—¨æç¤ºè¯"""
        
        strategy = self.category_strategies.get(category, {
            'focus': 'å®Œæ•´ä¼ è¾¾æ–°é—»å†…å®¹',
            'tone': 'å®¢è§‚ã€è¯¦ç»†',
            'keywords': ['è¯¦æƒ…', 'å†…å®¹', 'ä¿¡æ¯']
        })
        
        context_info = f"\næ ‡é¢˜å‚è€ƒï¼š{title}" if title else ""
        category_guidance = self._get_description_category_guidance(category)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘æŠ€æ–°é—»å†…å®¹ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»æè¿°ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

ã€ç¿»è¯‘åŸåˆ™ã€‘
1. å®Œæ•´æ€§ï¼šä¿æŒåŸæ–‡çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œä¸èƒ½é—æ¼å…³é”®ç»†èŠ‚
2. è¿è´¯æ€§ï¼šç¡®ä¿æ®µè½é€»è¾‘æ¸…æ™°ï¼Œä¸Šä¸‹æ–‡è¿è´¯ï¼Œè¯­ä¹‰æµç•…
3. å‡†ç¡®æ€§ï¼šä¸“ä¸šæœ¯è¯­å’Œå…³é”®ä¿¡æ¯å‡†ç¡®ç¿»è¯‘ï¼Œä¿æŒäº‹å®å‡†ç¡®
4. å¯è¯»æ€§ï¼šä½¿ç”¨è‡ªç„¶æµç•…çš„ä¸­æ–‡è¡¨è¾¾ï¼Œç¬¦åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯

ã€ç±»åˆ«ç‰¹ç‚¹ã€‘{category}
- å†…å®¹é‡ç‚¹ï¼š{strategy['focus']}
- è¡¨è¾¾é£æ ¼ï¼š{strategy['tone']}
- æ ¸å¿ƒè¯æ±‡ï¼š{', '.join(strategy['keywords'])}{context_info}

{category_guidance}

ã€ä¸“ä¸šæœ¯è¯­å¤„ç†è§„åˆ™ã€‘
- æŠ€æœ¯æœ¯è¯­ä½¿ç”¨æ ‡å‡†ä¸­æ–‡ç¿»è¯‘ï¼šAIâ†’äººå·¥æ™ºèƒ½, machine learningâ†’æœºå™¨å­¦ä¹ 
- å“ç‰Œåç§°ä¿æŒåŸåæˆ–ä½¿ç”¨é€šç”¨ä¸­æ–‡åï¼šGoogleâ†’è°·æ­Œ, Microsoftâ†’å¾®è½¯
- äº§å“åç§°é€šå¸¸ä¿æŒè‹±æ–‡ï¼šChatGPT, iPhone, PlayStationç­‰
- æ•°å­—ä¿¡æ¯ä¿æŒåŸæ ·ï¼šä»·æ ¼ã€æ—¥æœŸã€ç™¾åˆ†æ¯”ã€ç»Ÿè®¡æ•°æ®ç­‰

ã€æ–‡æœ¬ç»“æ„å¤„ç†ã€‘
- ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„å’Œé€»è¾‘å±‚æ¬¡
- å¦‚æœ‰å¤šä¸ªæ®µè½ï¼Œç”¨ç©ºè¡Œåˆ†éš”
- ä¿æŒåˆ—è¡¨ã€å¼•ç”¨ç­‰ç‰¹æ®Šæ ¼å¼
- ç¡®ä¿å¥å­é—´çš„é€»è¾‘å…³ç³»æ¸…æ™°

ã€ç¿»è¯‘è´¨é‡è¦æ±‚ã€‘
- é¿å…ç›´è¯‘ï¼Œä½¿ç”¨è‡ªç„¶çš„ä¸­æ–‡è¡¨è¾¾
- ä¿æŒæ–°é—»æè¿°çš„å®¢è§‚æ€§å’Œå‡†ç¡®æ€§
- ç¡®ä¿ä¿¡æ¯ä¼ è¾¾çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
- é€‚åˆä¸­æ–‡è¯»è€…çš„é˜…è¯»ä¹ æƒ¯

ã€æ ¼å¼è¦æ±‚ã€‘
åªè¿”å›ç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æ®µè½ç»“æ„ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚

è‹±æ–‡æè¿°ï¼š{description}

ä¸­æ–‡æè¿°ï¼š"""
        
        return prompt
    
    def _get_description_category_guidance(self, category: str) -> str:
        """è·å–æè¿°ç¿»è¯‘çš„ç±»åˆ«ç‰¹å®šæŒ‡å¯¼"""
        guidance_map = {
            'AIç§‘æŠ€': """
ã€AIç§‘æŠ€æè¿°ç¿»è¯‘ç‰¹æ®Šè¦æ±‚ã€‘
- æŠ€æœ¯ç»†èŠ‚å‡†ç¡®ç¿»è¯‘ï¼šæ¨¡å‹å‚æ•°ã€ç®—æ³•åŸç†ã€æ€§èƒ½æŒ‡æ ‡
- åº”ç”¨åœºæ™¯æ¸…æ™°æè¿°ï¼šå…·ä½“ç”¨é€”ã€ä½¿ç”¨æ–¹æ³•ã€æ•ˆæœå±•ç¤º
- è¡Œä¸šå½±å“æ·±åº¦åˆ†æï¼šå¯¹ç›¸å…³è¡Œä¸šã€ç”¨æˆ·ã€å¸‚åœºçš„å½±å“
- å‘å±•è¶‹åŠ¿å‰ç»è¡¨è¾¾ï¼šæŠ€æœ¯å‘å±•æ–¹å‘ã€æœªæ¥å¯èƒ½æ€§
- å…³é”®æœ¯è¯­ï¼šè®­ç»ƒã€æ¨ç†ã€éƒ¨ç½²ã€ä¼˜åŒ–ã€é›†æˆã€èµ‹èƒ½ã€æ™ºèƒ½åŒ–""",
            
            'æ¸¸æˆç§‘æŠ€': """
ã€æ¸¸æˆç§‘æŠ€æè¿°ç¿»è¯‘ç‰¹æ®Šè¦æ±‚ã€‘
- æ¸¸æˆä½“éªŒç”ŸåŠ¨æè¿°ï¼šç”»é¢æ•ˆæœã€æ“ä½œæ„Ÿå—ã€æ²‰æµ¸ä½“éªŒ
- æŠ€æœ¯è§„æ ¼å‡†ç¡®ç¿»è¯‘ï¼šç¡¬ä»¶é…ç½®ã€æ€§èƒ½å‚æ•°ã€å…¼å®¹æ€§
- å¸‚åœºè¡¨ç°å®¢è§‚æŠ¥é“ï¼šé”€é‡æ•°æ®ã€ç”¨æˆ·åé¦ˆã€è¡Œä¸šè¯„ä»·
- å¨±ä¹ä»·å€¼çªå‡ºè¡¨è¾¾ï¼šè¶£å‘³æ€§ã€å¯ç©æ€§ã€ç¤¾äº¤æ€§
- å…³é”®æœ¯è¯­ï¼šå‘å”®ã€æ›´æ–°ã€æ‰©å±•åŒ…ã€å¤šäººæ¨¡å¼ã€ç«æŠ€ã€ä¸»æœº""",
            
            'ç»æµé‡‘è': """
ã€ç»æµé‡‘èæè¿°ç¿»è¯‘ç‰¹æ®Šè¦æ±‚ã€‘
- è´¢åŠ¡æ•°æ®ç²¾ç¡®ç¿»è¯‘ï¼šæ”¶å…¥ã€åˆ©æ¶¦ã€å¸‚å€¼ã€å¢é•¿ç‡ç­‰
- å¸‚åœºåˆ†æå®¢è§‚è¡¨è¿°ï¼šè¶‹åŠ¿åˆ†æã€é£é™©è¯„ä¼°ã€æŠ•èµ„å»ºè®®
- å•†ä¸šç­–ç•¥æ¸…æ™°è¯´æ˜ï¼šä¸šåŠ¡æ¨¡å¼ã€å‘å±•è®¡åˆ’ã€ç«äº‰ç­–ç•¥
- ç›‘ç®¡æ”¿ç­–å‡†ç¡®è§£è¯»ï¼šæ³•è§„å˜åŒ–ã€åˆè§„è¦æ±‚ã€æ”¿ç­–å½±å“
- å…³é”®æœ¯è¯­ï¼šèèµ„ã€ä¼°å€¼ã€ä¸Šå¸‚ã€å¹¶è´­ã€è‚¡ä¸œã€è‘£äº‹ä¼š""",
            
            'ç§‘æŠ€åˆ›æ–°': """
ã€ç§‘æŠ€åˆ›æ–°æè¿°ç¿»è¯‘ç‰¹æ®Šè¦æ±‚ã€‘
- åˆ›æ–°ç‚¹çªå‡ºæè¿°ï¼šæŠ€æœ¯çªç ´ã€äº§å“ç‰¹è‰²ã€å·®å¼‚åŒ–ä¼˜åŠ¿
- åº”ç”¨ä»·å€¼æ·±å…¥é˜è¿°ï¼šå®é™…ç”¨é€”ã€è§£å†³é—®é¢˜ã€æå‡æ•ˆç‡
- å¸‚åœºå‰æ™¯åˆç†é¢„æµ‹ï¼šå‘å±•æ½œåŠ›ã€å•†ä¸šä»·å€¼ã€ç«äº‰ä¼˜åŠ¿
- æŠ€æœ¯åŸç†é€‚åº¦è§£é‡Šï¼šå·¥ä½œåŸç†ã€æŠ€æœ¯æ¶æ„ã€å®ç°æ–¹å¼
- å…³é”®æœ¯è¯­ï¼šåˆ›æ–°ã€çªç ´ã€å‡çº§ã€æ•´åˆã€ä¼˜åŒ–ã€å˜é©"""
        }
        
        return guidance_map.get(category, """
ã€é€šç”¨ç§‘æŠ€æ–°é—»æè¿°è¦æ±‚ã€‘
- ä¿æŒå†…å®¹çš„å®¢è§‚æ€§å’Œå‡†ç¡®æ€§
- çªå‡ºæ–°é—»çš„ä»·å€¼å’Œæ„ä¹‰
- ä½¿ç”¨æ ‡å‡†çš„ç§‘æŠ€æœ¯è¯­ç¿»è¯‘
- ç¡®ä¿ä¿¡æ¯ä¼ è¾¾çš„å®Œæ•´æ€§""")
    
    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬ï¼Œæ›¿æ¢ä¸“ä¸šæœ¯è¯­"""
        processed_text = text
        
        # æŒ‰é•¿åº¦æ’åºï¼Œä¼˜å…ˆæ›¿æ¢é•¿æœ¯è¯­
        sorted_terms = sorted(self.tech_terms.items(), key=lambda x: len(x[0]), reverse=True)
        
        for en_term, zh_term in sorted_terms:
            # ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
            import re
            pattern = r'\b' + re.escape(en_term) + r'\b'
            processed_text = re.sub(pattern, zh_term, processed_text, flags=re.IGNORECASE)
        
        return processed_text
    
    def _make_request(self, messages: List[Dict]) -> dict:
        """å‘èµ·APIè¯·æ±‚"""
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.2,  # æ›´ä½æ¸©åº¦ç¡®ä¿ç¿»è¯‘ä¸€è‡´æ€§
            "max_tokens": 2048,
            "top_p": 0.8,
            "stream": False
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                data = json.dumps(payload).encode('utf-8')
                request = urllib.request.Request(
                    self.base_url,
                    data=data,
                    headers=headers
                )
                
                with urllib.request.urlopen(request, timeout=30) as response:
                    result = json.loads(response.read().decode('utf-8'))
                    
                if 'error' in result:
                    error = result['error']
                    error_msg = f"{error.get('type', 'Unknown')}: {error.get('message', 'Unknown error')}"
                    
                    if attempt < self.max_retries - 1:
                        print(f"APIé”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")
                        time.sleep(self.retry_delay * (attempt + 1))
                        continue
                    else:
                        raise Exception(f"APIé”™è¯¯: {error_msg}")
                
                return result
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    print(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {str(e)}")
                    time.sleep(self.retry_delay * (attempt + 1))
                    continue
                else:
                    raise e
    
    def _calculate_enhanced_confidence(self, original: str, translated: str, 
                                     translation_type: str = "general") -> float:
        """è®¡ç®—å¢å¼ºçš„ç¿»è¯‘ç½®ä¿¡åº¦"""
        if not translated or not translated.strip():
            return 0.0
        
        base_confidence = 0.88  # å¢å¼ºç‰ˆç¿»è¯‘å™¨åŸºç¡€ç½®ä¿¡åº¦æ›´é«˜
        
        # åŸºäºç¿»è¯‘ç±»å‹è°ƒæ•´
        if translation_type == "title":
            base_confidence += 0.05  # æ ‡é¢˜ç¿»è¯‘é€šå¸¸æ›´å‡†ç¡®
        elif translation_type == "description":
            base_confidence += 0.02  # æè¿°ç¿»è¯‘ç¨å¾®å¤æ‚
        
        # 1. é•¿åº¦æ¯”ä¾‹è¯„ä¼°
        if len(original) > 0:
            length_ratio = len(translated) / len(original)
            if translation_type == "title":
                # æ ‡é¢˜çš„åˆç†é•¿åº¦æ¯”ä¾‹ï¼ˆä¸­æ–‡é€šå¸¸æ¯”è‹±æ–‡çŸ­ï¼‰
                if 0.5 <= length_ratio <= 1.8:
                    base_confidence += 0.06
                elif 0.3 <= length_ratio <= 2.5:
                    base_confidence += 0.03
                else:
                    base_confidence -= 0.10
            else:
                # æè¿°çš„åˆç†é•¿åº¦æ¯”ä¾‹
                if 0.6 <= length_ratio <= 1.5:
                    base_confidence += 0.05
                elif 0.4 <= length_ratio <= 2.0:
                    base_confidence += 0.02
                else:
                    base_confidence -= 0.08
        
        # 2. ä¸“ä¸šæœ¯è¯­ä¿ç•™æ£€æŸ¥
        tech_term_preserved = 0
        tech_term_total = 0
        
        for en_term, zh_term in self.tech_terms.items():
            if en_term.lower() in original.lower():
                tech_term_total += 1
                # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä¿ç•™æˆ–ç¿»è¯‘
                if (en_term in translated or 
                    zh_term in translated or 
                    en_term.lower() in translated.lower()):
                    tech_term_preserved += 1
        
        if tech_term_total > 0:
            preservation_rate = tech_term_preserved / tech_term_total
            base_confidence += preservation_rate * 0.08
        
        # 3. ä¸­æ–‡è¡¨è¾¾è´¨é‡æ£€æŸ¥
        chinese_char_count = sum(1 for char in translated if '\u4e00' <= char <= '\u9fff')
        if len(translated) > 0:
            chinese_ratio = chinese_char_count / len(translated)
            if chinese_ratio >= 0.4:  # è‡³å°‘40%ä¸­æ–‡å­—ç¬¦
                base_confidence += 0.04
            elif chinese_ratio >= 0.2:  # è‡³å°‘20%ä¸­æ–‡å­—ç¬¦
                base_confidence += 0.02
            else:
                base_confidence -= 0.05  # ä¸­æ–‡å­—ç¬¦å¤ªå°‘å¯èƒ½ç¿»è¯‘æœ‰é—®é¢˜
        
        # 4. æ ‡é¢˜ç‰¹æ®Šè´¨é‡æ£€æŸ¥
        if translation_type == "title":
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦è¿‡é•¿æˆ–è¿‡çŸ­
            if 8 <= len(translated) <= 35:  # åˆç†çš„ä¸­æ–‡æ ‡é¢˜é•¿åº¦
                base_confidence += 0.03
            elif len(translated) < 5 or len(translated) > 50:
                base_confidence -= 0.08
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–°é—»æ ‡é¢˜å¸¸ç”¨è¯æ±‡
            news_indicators = ['å‘å¸ƒ', 'æ¨å‡º', 'å®£å¸ƒ', 'ä¸Šçº¿', 'æ›´æ–°', 'å‡çº§', 'çªç ´', 'åˆ›æ–°', 
                             'å¢é•¿', 'ä¸‹è·Œ', 'æ”¶è´­', 'åˆä½œ', 'ç«äº‰', 'å¸‚åœº', 'ç”¨æˆ·', 'åŠŸèƒ½']
            if any(indicator in translated for indicator in news_indicators):
                base_confidence += 0.02
        
        # 5. æè¿°ç‰¹æ®Šè´¨é‡æ£€æŸ¥
        elif translation_type == "description":
            # æ£€æŸ¥æ®µè½ç»“æ„
            if '\n' in translated or 'ã€‚' in translated:  # åŒ…å«æ®µè½æˆ–å¥å­ç»“æ„
                base_confidence += 0.02
            
            # æ£€æŸ¥æ˜¯å¦ä¿æŒäº†é€»è¾‘è¿è´¯æ€§ï¼ˆç®€å•æ£€æŸ¥ï¼‰
            if len(translated.split('ã€‚')) >= 2:  # è‡³å°‘åŒ…å«ä¸¤ä¸ªå¥å­
                base_confidence += 0.02
        
        # 6. é”™è¯¯æ¨¡å¼æ£€æŸ¥ï¼ˆé™ä½ç½®ä¿¡åº¦ï¼‰
        error_patterns = [
            'ç¿»è¯‘ï¼š',  # å¯èƒ½åŒ…å«æç¤ºè¯æ®‹ç•™
            'ä¸­æ–‡ï¼š',
            'è‹±æ–‡ï¼š',
            'Translation:',
            'ä»¥ä¸‹æ˜¯',
            'è¯·æ³¨æ„',
            'æ ¹æ®',
            'ç¿»è¯‘ç»“æœ'
        ]
        
        for pattern in error_patterns:
            if pattern in translated:
                base_confidence -= 0.15
                break
        
        # 7. é‡å¤å†…å®¹æ£€æŸ¥
        words = translated.split()
        if len(words) > 1:
            unique_words = set(words)
            repetition_ratio = 1 - (len(unique_words) / len(words))
            if repetition_ratio > 0.3:  # é‡å¤ç‡è¿‡é«˜
                base_confidence -= 0.10
        
        return min(max(base_confidence, 0.0), 1.0)
    
    def _validate_title_quality(self, original_title: str, translated_title: str, category: str = "") -> Tuple[str, float]:
        """éªŒè¯å’Œä¼˜åŒ–æ ‡é¢˜ç¿»è¯‘è´¨é‡"""
        if not translated_title or not translated_title.strip():
            return "", 0.0
        
        cleaned_title = translated_title.strip()
        quality_score = 1.0
        
        # 1. æ¸…ç†æ ¼å¼é—®é¢˜
        cleanup_patterns = [
            ('ä¸­æ–‡æ ‡é¢˜ï¼š', ''),
            ('ç¿»è¯‘ï¼š', ''),
            ('æ ‡é¢˜ï¼š', ''),
            ('"', ''),
            ('"', ''),
            ('"', ''),
            ('ã€Œ', ''),
            ('ã€', ''),
        ]
        
        for pattern, replacement in cleanup_patterns:
            if cleaned_title.startswith(pattern):
                cleaned_title = cleaned_title[len(pattern):].strip()
                quality_score -= 0.05
        
        # 2. é•¿åº¦æ£€æŸ¥å’Œä¼˜åŒ–
        if len(cleaned_title) > 40:  # æ ‡é¢˜è¿‡é•¿
            # å°è¯•æå–æ ¸å¿ƒä¿¡æ¯
            sentences = cleaned_title.split('ï¼Œ')
            if len(sentences) > 1:
                cleaned_title = sentences[0]  # å–ç¬¬ä¸€ä¸ªä¸»è¦ä¿¡æ¯
                quality_score -= 0.08
        elif len(cleaned_title) < 5:  # æ ‡é¢˜è¿‡çŸ­
            quality_score -= 0.15
        
        # 3. ä¸“ä¸šæœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥
        for en_term, zh_term in self.tech_terms.items():
            if en_term.lower() in original_title.lower():
                # æ£€æŸ¥ç¿»è¯‘ä¸­æ˜¯å¦æ­£ç¡®å¤„ç†äº†è¿™ä¸ªæœ¯è¯­
                if not (en_term in cleaned_title or zh_term in cleaned_title):
                    # æœ¯è¯­ä¸¢å¤±ï¼Œå°è¯•ä¿®å¤
                    if zh_term not in cleaned_title:
                        # ç®€å•æ›¿æ¢ç­–ç•¥
                        import re
                        pattern = r'\b' + re.escape(en_term) + r'\b'
                        if re.search(pattern, original_title, re.IGNORECASE):
                            # å¦‚æœåŸæ–‡ä¸­æœ‰è¿™ä¸ªæœ¯è¯­ï¼Œç¡®ä¿ç¿»è¯‘ä¸­ä¹Ÿæœ‰
                            quality_score -= 0.05
        
        # 4. ç±»åˆ«ç‰¹å®šä¼˜åŒ–
        if category == 'AIç§‘æŠ€':
            # AIæ–°é—»æ ‡é¢˜ä¼˜åŒ–
            if 'AI' in original_title and 'äººå·¥æ™ºèƒ½' not in cleaned_title and 'AI' not in cleaned_title:
                cleaned_title = cleaned_title.replace('æ™ºèƒ½', 'AI')
                quality_score += 0.02
        elif category == 'æ¸¸æˆç§‘æŠ€':
            # æ¸¸æˆæ–°é—»æ ‡é¢˜ä¼˜åŒ–
            gaming_terms = ['æ¸¸æˆ', 'ç©å®¶', 'ä¸»æœº', 'å‘å”®', 'æ›´æ–°']
            if not any(term in cleaned_title for term in gaming_terms):
                quality_score -= 0.05
        elif category == 'ç»æµé‡‘è':
            # é‡‘èæ–°é—»æ ‡é¢˜ä¼˜åŒ–
            finance_terms = ['è‚¡ä»·', 'å¸‚å€¼', 'æŠ•èµ„', 'èèµ„', 'æ”¶ç›Š', 'å¢é•¿']
            if not any(term in cleaned_title for term in finance_terms):
                quality_score -= 0.05
        
        # 5. æ–°é—»ä»·å€¼è¯æ±‡æ£€æŸ¥
        news_value_words = ['å‘å¸ƒ', 'æ¨å‡º', 'å®£å¸ƒ', 'çªç ´', 'åˆ›æ–°', 'å¢é•¿', 'ä¸‹è·Œ', 'åˆä½œ', 'ç«äº‰']
        if any(word in cleaned_title for word in news_value_words):
            quality_score += 0.03
        
        return cleaned_title, max(quality_score, 0.0)
    
    def translate_news_title(self, title: str, category: str = "") -> TranslationResult:
        """ä¸“é—¨ç¿»è¯‘æ–°é—»æ ‡é¢˜"""
        if not title or not title.strip():
            return TranslationResult(
                original_text=title,
                translated_text="",
                source_language="en",
                target_language="zh",
                service_name=self.get_service_name(),
                confidence_score=0.0,
                timestamp=datetime.now(),
                error_message="æ ‡é¢˜ä¸ºç©º"
            )
        
        try:
            # é¢„å¤„ç†ä¸“ä¸šæœ¯è¯­
            processed_title = self._preprocess_text(title)
            
            # åˆ›å»ºä¸“é—¨çš„æ ‡é¢˜ç¿»è¯‘æç¤º
            prompt = self._create_title_translation_prompt(processed_title, category)
            messages = [{"role": "user", "content": prompt}]
            
            result = self._make_request(messages)
            
            if 'choices' in result and result['choices']:
                raw_translated_text = result['choices'][0]['message']['content'].strip()
                
                # ä½¿ç”¨è´¨é‡éªŒè¯å’Œä¼˜åŒ–
                validated_title, quality_adjustment = self._validate_title_quality(
                    title, raw_translated_text, category
                )
                
                if not validated_title:
                    raise Exception("æ ‡é¢˜ç¿»è¯‘éªŒè¯å¤±è´¥")
                
                # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç»“åˆè´¨é‡è°ƒæ•´ï¼‰
                base_confidence = self._calculate_enhanced_confidence(
                    title, validated_title, "title"
                )
                final_confidence = base_confidence * quality_adjustment
                
                return TranslationResult(
                    original_text=title,
                    translated_text=validated_title,
                    source_language="en",
                    target_language="zh",
                    service_name=self.get_service_name(),
                    confidence_score=final_confidence,
                    timestamp=datetime.now()
                )
            else:
                raise Exception("ç¿»è¯‘ç»“æœä¸ºç©º")
                
        except Exception as e:
            return TranslationResult(
                original_text=title,
                translated_text="",
                source_language="en",
                target_language="zh",
                service_name=self.get_service_name(),
                confidence_score=0.0,
                timestamp=datetime.now(),
                error_message=str(e)
            )
    
    def translate_news_description(self, description: str, title: str = "", category: str = "") -> TranslationResult:
        """ä¸“é—¨ç¿»è¯‘æ–°é—»æè¿°ï¼Œæ”¯æŒé•¿æ–‡æœ¬æ™ºèƒ½åˆ†æ®µå¤„ç†"""
        if not description or not description.strip():
            return TranslationResult(
                original_text=description,
                translated_text="",
                source_language="en",
                target_language="zh",
                service_name=self.get_service_name(),
                confidence_score=0.0,
                timestamp=datetime.now(),
                error_message="æè¿°ä¸ºç©º"
            )
        
        try:
            # é¢„å¤„ç†ä¸“ä¸šæœ¯è¯­
            processed_description = self._preprocess_text(description)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µå¤„ç†
            if len(processed_description) > 800:  # é•¿æ–‡æœ¬åˆ†æ®µå¤„ç†
                return self._translate_long_description(processed_description, title, category)
            else:
                return self._translate_single_description(processed_description, title, category)
                
        except Exception as e:
            return TranslationResult(
                original_text=description,
                translated_text="",
                source_language="en",
                target_language="zh",
                service_name=self.get_service_name(),
                confidence_score=0.0,
                timestamp=datetime.now(),
                error_message=str(e)
            )
    
    def _validate_description_quality(self, original_desc: str, translated_desc: str, 
                                    title: str = "", category: str = "") -> Tuple[str, float]:
        """éªŒè¯å’Œä¼˜åŒ–æè¿°ç¿»è¯‘è´¨é‡"""
        if not translated_desc or not translated_desc.strip():
            return "", 0.0
        
        cleaned_desc = translated_desc.strip()
        quality_score = 1.0
        
        # 1. æ¸…ç†æ ¼å¼é—®é¢˜
        cleanup_patterns = [
            ('ä¸­æ–‡æè¿°ï¼š', ''),
            ('ç¿»è¯‘ï¼š', ''),
            ('æè¿°ï¼š', ''),
            ('å†…å®¹ï¼š', ''),
        ]
        
        for pattern, replacement in cleanup_patterns:
            if cleaned_desc.startswith(pattern):
                cleaned_desc = cleaned_desc[len(pattern):].strip()
                quality_score -= 0.05
        
        # 2. æ®µè½ç»“æ„æ£€æŸ¥
        paragraphs = [p.strip() for p in cleaned_desc.split('\n') if p.strip()]
        if len(paragraphs) > 1:
            # å¤šæ®µè½å†…å®¹ï¼Œæ£€æŸ¥æ®µè½é—´çš„è¿è´¯æ€§
            quality_score += 0.03
        
        # 3. é•¿åº¦åˆç†æ€§æ£€æŸ¥
        length_ratio = len(cleaned_desc) / len(original_desc) if len(original_desc) > 0 else 0
        if 0.5 <= length_ratio <= 2.0:  # åˆç†çš„é•¿åº¦æ¯”ä¾‹
            quality_score += 0.05
        elif length_ratio < 0.3:  # ç¿»è¯‘è¿‡çŸ­ï¼Œå¯èƒ½ä¿¡æ¯ä¸¢å¤±
            quality_score -= 0.15
        elif length_ratio > 3.0:  # ç¿»è¯‘è¿‡é•¿ï¼Œå¯èƒ½æœ‰å†—ä½™
            quality_score -= 0.10
        
        # 4. ä¸“ä¸šæœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥
        term_consistency_score = 0
        term_count = 0
        
        for en_term, zh_term in self.tech_terms.items():
            if en_term.lower() in original_desc.lower():
                term_count += 1
                if en_term in cleaned_desc or zh_term in cleaned_desc:
                    term_consistency_score += 1
        
        if term_count > 0:
            consistency_ratio = term_consistency_score / term_count
            quality_score += consistency_ratio * 0.08
        
        # 5. å¥å­å®Œæ•´æ€§æ£€æŸ¥
        sentences = [s.strip() for s in cleaned_desc.split('ã€‚') if s.strip()]
        if len(sentences) >= 2:  # è‡³å°‘åŒ…å«å®Œæ•´çš„å¥å­
            quality_score += 0.03
        
        # 6. ç±»åˆ«ç‰¹å®šè´¨é‡æ£€æŸ¥
        category_bonus = self._check_category_specific_quality(cleaned_desc, category)
        quality_score += category_bonus
        
        # 7. é”™è¯¯æ¨¡å¼æ£€æŸ¥
        error_patterns = [
            'ç¿»è¯‘ï¼š',
            'ä¸­æ–‡ï¼š',
            'è‹±æ–‡ï¼š',
            'Translation:',
            'ä»¥ä¸‹æ˜¯ç¿»è¯‘',
            'æ ¹æ®åŸæ–‡',
            'ç¿»è¯‘ç»“æœå¦‚ä¸‹'
        ]
        
        for pattern in error_patterns:
            if pattern in cleaned_desc:
                quality_score -= 0.12
                break
        
        # 8. é‡å¤å†…å®¹æ£€æŸ¥
        words = cleaned_desc.split()
        if len(words) > 5:
            unique_words = set(words)
            repetition_ratio = 1 - (len(unique_words) / len(words))
            if repetition_ratio > 0.4:  # é‡å¤ç‡è¿‡é«˜
                quality_score -= 0.15
        
        return cleaned_desc, max(quality_score, 0.0)
    
    def _check_category_specific_quality(self, translated_desc: str, category: str) -> float:
        """æ£€æŸ¥ç±»åˆ«ç‰¹å®šçš„ç¿»è¯‘è´¨é‡"""
        bonus = 0.0
        
        if category == 'AIç§‘æŠ€':
            ai_terms = ['äººå·¥æ™ºèƒ½', 'AI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'æ¨¡å‹', 'è®­ç»ƒ', 'æ¨ç†']
            if any(term in translated_desc for term in ai_terms):
                bonus += 0.02
        elif category == 'æ¸¸æˆç§‘æŠ€':
            gaming_terms = ['æ¸¸æˆ', 'ç©å®¶', 'ä½“éªŒ', 'æ€§èƒ½', 'ç”»é¢', 'æ“ä½œ', 'ä¸»æœº', 'å¹³å°']
            if any(term in translated_desc for term in gaming_terms):
                bonus += 0.02
        elif category == 'ç»æµé‡‘è':
            finance_terms = ['å¸‚åœº', 'æŠ•èµ„', 'æ”¶ç›Š', 'å¢é•¿', 'è‚¡ä»·', 'èèµ„', 'ä¼°å€¼', 'ä¸šç»©']
            if any(term in translated_desc for term in finance_terms):
                bonus += 0.02
        elif category == 'ç§‘æŠ€åˆ›æ–°':
            tech_terms = ['æŠ€æœ¯', 'åˆ›æ–°', 'äº§å“', 'åŠŸèƒ½', 'å‡çº§', 'ä¼˜åŒ–', 'è§£å†³æ–¹æ¡ˆ', 'åº”ç”¨']
            if any(term in translated_desc for term in tech_terms):
                bonus += 0.02
        
        return bonus
    
    def _translate_single_description(self, description: str, title: str = "", category: str = "") -> TranslationResult:
        """ç¿»è¯‘å•æ®µæè¿°"""
        try:
            # åˆ›å»ºä¸“é—¨çš„æè¿°ç¿»è¯‘æç¤º
            prompt = self._create_description_translation_prompt(description, title, category)
            messages = [{"role": "user", "content": prompt}]
            
            result = self._make_request(messages)
            
            if 'choices' in result and result['choices']:
                raw_translated_text = result['choices'][0]['message']['content'].strip()
                
                # ä½¿ç”¨è´¨é‡éªŒè¯å’Œä¼˜åŒ–
                validated_desc, quality_adjustment = self._validate_description_quality(
                    description, raw_translated_text, title, category
                )
                
                if not validated_desc:
                    raise Exception("æè¿°ç¿»è¯‘éªŒè¯å¤±è´¥")
                
                # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç»“åˆè´¨é‡è°ƒæ•´ï¼‰
                base_confidence = self._calculate_enhanced_confidence(
                    description, validated_desc, "description"
                )
                final_confidence = base_confidence * quality_adjustment
                
                return TranslationResult(
                    original_text=description,
                    translated_text=validated_desc,
                    source_language="en",
                    target_language="zh",
                    service_name=self.get_service_name(),
                    confidence_score=final_confidence,
                    timestamp=datetime.now()
                )
            else:
                raise Exception("ç¿»è¯‘ç»“æœä¸ºç©º")
                
        except Exception as e:
            raise e
    
    def _translate_long_description(self, description: str, title: str = "", category: str = "") -> TranslationResult:
        """æ™ºèƒ½åˆ†æ®µç¿»è¯‘é•¿æ–‡æœ¬æè¿°"""
        try:
            # æ™ºèƒ½åˆ†æ®µ
            segments = self._smart_segment_text(description)
            translated_segments = []
            total_confidence = 0.0
            
            print(f"ğŸ“„ é•¿æ–‡æœ¬åˆ†ä¸º {len(segments)} æ®µè¿›è¡Œç¿»è¯‘")
            
            for i, segment in enumerate(segments):
                if not segment.strip():
                    translated_segments.append("")
                    continue
                
                try:
                    # ä¸ºæ¯æ®µåˆ›å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç¿»è¯‘æç¤º
                    segment_prompt = self._create_segment_translation_prompt(
                        segment, title, category, i, len(segments)
                    )
                    messages = [{"role": "user", "content": segment_prompt}]
                    
                    result = self._make_request(messages)
                    
                    if 'choices' in result and result['choices']:
                        translated_segment = result['choices'][0]['message']['content'].strip()
                        
                        # æ¸…ç†æ ¼å¼
                        if translated_segment.startswith('ç¿»è¯‘ï¼š'):
                            translated_segment = translated_segment[3:].strip()
                        
                        translated_segments.append(translated_segment)
                        
                        # è®¡ç®—æ®µè½ç½®ä¿¡åº¦
                        segment_confidence = self._calculate_enhanced_confidence(
                            segment, translated_segment, "description"
                        )
                        total_confidence += segment_confidence
                        
                        print(f"âœ… ç¬¬ {i+1}/{len(segments)} æ®µç¿»è¯‘å®Œæˆ")
                        
                        # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
                        if i < len(segments) - 1:
                            time.sleep(0.2)
                    else:
                        print(f"âš ï¸ ç¬¬ {i+1} æ®µç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡")
                        translated_segments.append(segment)
                        
                except Exception as e:
                    print(f"âš ï¸ ç¬¬ {i+1} æ®µç¿»è¯‘å¼‚å¸¸: {str(e)}")
                    translated_segments.append(segment)
            
            # åˆå¹¶ç¿»è¯‘ç»“æœ
            final_translation = self._merge_translated_segments(translated_segments)
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = total_confidence / len(segments) if segments else 0.0
            
            return TranslationResult(
                original_text=description,
                translated_text=final_translation,
                source_language="en",
                target_language="zh",
                service_name=self.get_service_name(),
                confidence_score=avg_confidence,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            raise e
    
    def _smart_segment_text(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†æ®µæ–‡æœ¬ï¼Œä¿æŒé€»è¾‘å®Œæ•´æ€§"""
        if len(text) <= 600:  # çŸ­æ–‡æœ¬ä¸éœ€è¦åˆ†æ®µ
            return [text]
        
        segments = []
        
        # 1. é¦–å…ˆå°è¯•æŒ‰è‡ªç„¶æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in text.split('\n') if p.strip()]
        
        if not paragraphs:  # æ²¡æœ‰æ®µè½åˆ†å‰²ï¼ŒæŒ‰å¥å­å¤„ç†
            return self._segment_by_sentences(text)
        
        current_segment = ""
        
        for paragraph in paragraphs:
            # æ£€æŸ¥å•ä¸ªæ®µè½æ˜¯å¦è¿‡é•¿
            if len(paragraph) > 700:
                # å•ä¸ªæ®µè½è¿‡é•¿ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
                if current_segment:
                    segments.append(current_segment.strip())
                    current_segment = ""
                
                # åˆ†å‰²é•¿æ®µè½
                sub_segments = self._segment_long_paragraph(paragraph)
                segments.extend(sub_segments)
                continue
            
            # æ£€æŸ¥åŠ å…¥å½“å‰æ®µè½åæ˜¯å¦è¶…é•¿
            potential_segment = current_segment + "\n\n" + paragraph if current_segment else paragraph
            
            if len(potential_segment) <= 650:  # åˆç†çš„æ®µè½é•¿åº¦
                current_segment = potential_segment
            else:
                # ä¿å­˜å½“å‰æ®µè½ï¼Œå¼€å§‹æ–°æ®µè½
                if current_segment:
                    segments.append(current_segment.strip())
                current_segment = paragraph
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment:
            segments.append(current_segment.strip())
        
        # è¿‡æ»¤ç©ºæ®µè½å¹¶è¿›è¡Œæœ€ç»ˆæ£€æŸ¥
        final_segments = []
        for segment in segments:
            if segment.strip():
                # å¦‚æœæ®µè½ä»ç„¶è¿‡é•¿ï¼Œè¿›è¡Œæœ€åçš„åˆ†å‰²
                if len(segment) > 800:
                    sub_segments = self._segment_by_sentences(segment)
                    final_segments.extend(sub_segments)
                else:
                    final_segments.append(segment)
        
        return final_segments
    
    def _segment_long_paragraph(self, paragraph: str) -> List[str]:
        """åˆ†å‰²è¿‡é•¿çš„å•ä¸ªæ®µè½"""
        # é¦–å…ˆå°è¯•æŒ‰å¥å­åˆ†å‰²
        sentences = self._split_sentences(paragraph)
        
        if len(sentences) <= 1:
            # åªæœ‰ä¸€ä¸ªå¥å­ä½†å¾ˆé•¿ï¼ŒæŒ‰é€—å·åˆ†å‰²
            return self._segment_by_punctuation(paragraph)
        
        segments = []
        current_segment = ""
        
        for sentence in sentences:
            potential_segment = current_segment + " " + sentence if current_segment else sentence
            
            if len(potential_segment) <= 600:
                current_segment = potential_segment
            else:
                if current_segment:
                    segments.append(current_segment.strip())
                current_segment = sentence
        
        if current_segment:
            segments.append(current_segment.strip())
        
        return segments
    
    def _segment_by_sentences(self, text: str) -> List[str]:
        """æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬"""
        sentences = self._split_sentences(text)
        
        if len(sentences) <= 1:
            return [text]  # æ— æ³•è¿›ä¸€æ­¥åˆ†å‰²
        
        segments = []
        current_segment = ""
        
        for sentence in sentences:
            potential_segment = current_segment + " " + sentence if current_segment else sentence
            
            if len(potential_segment) <= 600:
                current_segment = potential_segment
            else:
                if current_segment:
                    segments.append(current_segment.strip())
                    current_segment = sentence
                else:
                    # å•ä¸ªå¥å­å°±å¾ˆé•¿ï¼ŒæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
                    sub_segments = self._segment_by_punctuation(sentence)
                    segments.extend(sub_segments)
        
        if current_segment:
            segments.append(current_segment.strip())
        
        return segments
    
    def _segment_by_punctuation(self, text: str) -> List[str]:
        """æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²æ–‡æœ¬ï¼ˆæœ€åçš„åˆ†å‰²æ–¹å¼ï¼‰"""
        import re
        
        # æŒ‰ä¸»è¦æ ‡ç‚¹ç¬¦å·åˆ†å‰²
        parts = re.split(r'([,;:])', text)
        
        segments = []
        current_segment = ""
        
        for i in range(0, len(parts), 2):  # è·³è¿‡æ ‡ç‚¹ç¬¦å·
            part = parts[i] if i < len(parts) else ""
            punct = parts[i + 1] if i + 1 < len(parts) else ""
            
            full_part = part + punct
            potential_segment = current_segment + full_part if current_segment else full_part
            
            if len(potential_segment) <= 600:
                current_segment = potential_segment
            else:
                if current_segment:
                    segments.append(current_segment.strip())
                current_segment = full_part
        
        if current_segment:
            segments.append(current_segment.strip())
        
        # å¦‚æœè¿˜æ˜¯æœ‰è¿‡é•¿çš„æ®µè½ï¼Œå¼ºåˆ¶æŒ‰é•¿åº¦åˆ†å‰²
        final_segments = []
        for segment in segments:
            if len(segment) > 700:
                # å¼ºåˆ¶æŒ‰é•¿åº¦åˆ†å‰²
                words = segment.split()
                temp_segment = ""
                
                for word in words:
                    if len(temp_segment + " " + word) <= 600:
                        temp_segment += " " + word if temp_segment else word
                    else:
                        if temp_segment:
                            final_segments.append(temp_segment.strip())
                        temp_segment = word
                
                if temp_segment:
                    final_segments.append(temp_segment.strip())
            else:
                final_segments.append(segment)
        
        return final_segments
    
    def _split_sentences(self, text: str) -> List[str]:
        """æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬ï¼Œè€ƒè™‘å„ç§å¥å­ç»“æŸæ ‡ç‚¹"""
        import re
        
        # æ›´ç²¾ç¡®çš„å¥å­åˆ†å‰²ï¼Œè€ƒè™‘ç¼©å†™å’Œç‰¹æ®Šæƒ…å†µ
        # å…ˆå¤„ç†å¸¸è§çš„ç¼©å†™ï¼Œé¿å…è¯¯åˆ†å‰²
        text = re.sub(r'\bDr\.', 'Dr_DOT_', text)
        text = re.sub(r'\bMr\.', 'Mr_DOT_', text)
        text = re.sub(r'\bMs\.', 'Ms_DOT_', text)
        text = re.sub(r'\bInc\.', 'Inc_DOT_', text)
        text = re.sub(r'\bCorp\.', 'Corp_DOT_', text)
        text = re.sub(r'\bLtd\.', 'Ltd_DOT_', text)
        text = re.sub(r'\bCo\.', 'Co_DOT_', text)
        text = re.sub(r'\bU\.S\.', 'U_DOT_S_DOT_', text)
        text = re.sub(r'\bU\.K\.', 'U_DOT_K_DOT_', text)
        text = re.sub(r'\bE\.g\.', 'E_DOT_g_DOT_', text)
        text = re.sub(r'\bI\.e\.', 'I_DOT_e_DOT_', text)
        text = re.sub(r'\betc\.', 'etc_DOT_', text)
        
        # æŒ‰å¥å­ç»“æŸæ ‡ç‚¹åˆ†å‰²
        sentences = re.split(r'[.!?]+\s+', text)
        
        # æ¢å¤ç¼©å†™ä¸­çš„ç‚¹å·
        restored_sentences = []
        for sentence in sentences:
            if sentence.strip():
                restored = sentence.replace('_DOT_', '.')
                restored_sentences.append(restored.strip())
        
        # å¦‚æœåˆ†å‰²ç»“æœå¤ªå°‘ï¼Œå°è¯•å…¶ä»–åˆ†å‰²æ–¹å¼
        if len(restored_sentences) <= 1 and len(text) > 300:
            # å°è¯•æŒ‰åˆ†å·å’Œå†’å·åˆ†å‰²
            alt_sentences = re.split(r'[;:]\s+', text)
            if len(alt_sentences) > 1:
                return [s.strip() for s in alt_sentences if s.strip()]
        
        return restored_sentences
    
    def _create_segment_translation_prompt(self, segment: str, title: str, category: str, 
                                         segment_index: int, total_segments: int) -> str:
        """ä¸ºæ–‡æœ¬æ®µè½åˆ›å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç¿»è¯‘æç¤º"""
        
        strategy = self.category_strategies.get(category, {
            'focus': 'å®Œæ•´ä¼ è¾¾æ–°é—»å†…å®¹',
            'tone': 'å®¢è§‚ã€è¯¦ç»†',
            'keywords': ['è¯¦æƒ…', 'å†…å®¹', 'ä¿¡æ¯']
        })
        
        context_info = f"\næ ‡é¢˜å‚è€ƒï¼š{title}" if title else ""
        segment_info = f"ï¼ˆç¬¬ {segment_index + 1}/{total_segments} æ®µï¼‰" if total_segments > 1 else ""
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘æŠ€æ–°é—»ç¿»è¯‘ä¸“å®¶ã€‚è¯·ç¿»è¯‘ä»¥ä¸‹æ–°é—»å†…å®¹ç‰‡æ®µ{segment_info}ï¼Œè¦æ±‚ï¼š

ã€ç¿»è¯‘åŸåˆ™ã€‘
1. ä¿æŒå†…å®¹çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
2. ç¡®ä¿ä¸Šä¸‹æ–‡é€»è¾‘è¿è´¯
3. ä½¿ç”¨è‡ªç„¶æµç•…çš„ä¸­æ–‡è¡¨è¾¾
4. ä¿ç•™é‡è¦çš„ä¸“ä¸šæœ¯è¯­å’Œå…³é”®ä¿¡æ¯

ã€ç±»åˆ«ç‰¹ç‚¹ã€‘{category}
- å†…å®¹é‡ç‚¹ï¼š{strategy['focus']}
- è¡¨è¾¾é£æ ¼ï¼š{strategy['tone']}{context_info}

ã€å¤„ç†è¦æ±‚ã€‘
- ä¿æŒæ®µè½çš„é€»è¾‘ç»“æ„
- ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®çš„ä¸­æ–‡ç¿»è¯‘
- ä¿ç•™æ•°å­—ã€æ—¥æœŸã€å¼•ç”¨ç­‰å…³é”®ä¿¡æ¯
- ç¡®ä¿ç¿»è¯‘çš„è¿è´¯æ€§å’Œå¯è¯»æ€§

ã€æ ¼å¼è¦æ±‚ã€‘
åªè¿”å›ç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹ï¼Œä¿æŒåŸæœ‰ç»“æ„ã€‚

è‹±æ–‡ç‰‡æ®µï¼š{segment}

ç¿»è¯‘ï¼š"""
        
        return prompt
    
    def _merge_translated_segments(self, segments: List[str]) -> str:
        """åˆå¹¶ç¿»è¯‘åçš„æ®µè½ï¼Œä¿æŒé€»è¾‘è¿è´¯æ€§"""
        if not segments:
            return ""
        
        # ç®€å•åˆå¹¶ï¼Œä¿æŒæ®µè½ç»“æ„
        merged = []
        for segment in segments:
            if segment.strip():
                merged.append(segment.strip())
        
        return "\n\n".join(merged)
    
    def translate_text(self, text: str, source_lang: str = 'en', target_lang: str = 'zh') -> TranslationResult:
        """é€šç”¨æ–‡æœ¬ç¿»è¯‘æ¥å£"""
        return self.translate_news_title(text)  # é»˜è®¤ä½¿ç”¨æ ‡é¢˜ç¿»è¯‘é€»è¾‘
    
    def translate_batch(self, texts: List[str], source_lang: str = 'en', target_lang: str = 'zh') -> List[TranslationResult]:
        """æ‰¹é‡ç¿»è¯‘"""
        results = []
        for text in texts:
            result = self.translate_text(text, source_lang, target_lang)
            results.append(result)
            # æ·»åŠ å°å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
            time.sleep(0.1)
        return results
    
    def get_service_status(self) -> ServiceStatus:
        """è·å–æœåŠ¡çŠ¶æ€"""
        try:
            test_result = self.translate_news_title("AI breakthrough in technology")
            
            if test_result.error_message:
                error_msg = test_result.error_message.lower()
                if any(keyword in error_msg for keyword in ['rate', 'limit', 'quota']):
                    return ServiceStatus.DEGRADED
                elif any(keyword in error_msg for keyword in ['unauthorized', 'forbidden']):
                    return ServiceStatus.UNAVAILABLE
                else:
                    return ServiceStatus.DEGRADED
            else:
                return ServiceStatus.HEALTHY
                
        except Exception:
            return ServiceStatus.UNAVAILABLE
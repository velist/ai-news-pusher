#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆAIæ–°é—»ç´¯ç§¯æ›´æ–°ç³»ç»Ÿ - ä»…ä¾èµ–æ ‡å‡†åº“
ç”¨äºGitHub Actionséƒ¨ç½²ï¼Œé¿å…å¤æ‚ä¾èµ–é—®é¢˜
"""

import os
import json
import urllib.request
import urllib.parse
import time
import hashlib
from datetime import datetime, timedelta

class SimpleAINewsAccumulator:
    def __init__(self):
        # APIé…ç½® - ä»ç¯å¢ƒå˜é‡è·å–
        self.gnews_api_key = os.getenv('GNEWS_API_KEY')
        if not self.gnews_api_key:
            raise ValueError("GNEWS_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.gnews_base_url = "https://gnews.io/api/v4"
        self.news_data_file = 'docs/enhanced_news_data.json'
        
        print("âœ… ç®€åŒ–ç‰ˆæ–°é—»ç´¯ç§¯å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def get_latest_news(self):
        """è·å–æœ€æ–°AIç›¸å…³æ–°é—»"""
        all_articles = []
        
        # å®šä¹‰AIç›¸å…³æœç´¢ç±»åˆ«
        search_queries = [
            {
                "query": "AI artificial intelligence machine learning",
                "category": "AIæŠ€æœ¯",
                "description": "AIæŠ€æœ¯å’Œæœºå™¨å­¦ä¹ "
            },
            {
                "query": "GPT OpenAI ChatGPT Claude",
                "category": "AIæ¨¡å‹", 
                "description": "AIæ¨¡å‹å’Œè¯­è¨€æ¨¡å‹"
            },
            {
                "query": "AI tools software applications",
                "category": "AIå·¥å…·",
                "description": "AIå·¥å…·å’Œåº”ç”¨è½¯ä»¶"
            },
            {
                "query": "AI industry business technology",
                "category": "AIäº§ä¸š",
                "description": "AIäº§ä¸šå’Œå•†ä¸šåº”ç”¨"
            },
            {
                "query": "AI policy regulation government",
                "category": "AIæ”¿ç­–",
                "description": "AIæ”¿ç­–å’Œç›‘ç®¡"
            }
        ]
        
        for query_info in search_queries:
            print(f"ğŸ“¡ è·å–{query_info['description']}æ–°é—»...")
            articles = self._fetch_news(query_info["query"], query_info["category"])
            all_articles.extend(articles)
            time.sleep(1)  # é¿å…APIé™åˆ¶
        
        return all_articles
    
    def _fetch_news(self, query, category):
        """è·å–ç‰¹å®šæŸ¥è¯¢çš„æ–°é—»"""
        try:
            url = f"{self.gnews_base_url}/search"
            params = {
                "q": query,
                "lang": "en",
                "country": "us",
                "max": 10,
                "apikey": self.gnews_api_key
            }
            
            query_string = urllib.parse.urlencode(params)
            full_url = f"{url}?{query_string}"
            
            req = urllib.request.Request(full_url)
            with urllib.request.urlopen(req, timeout=30) as response:
                data = json.loads(response.read().decode())
            
            articles = []
            if data.get("articles"):
                for article in data["articles"]:
                    processed_article = self._process_article(article, category)
                    if processed_article:
                        articles.append(processed_article)
            
            print(f"âœ… è·å–åˆ° {len(articles)} æ¡{category}æ–°é—»")
            return articles
            
        except Exception as e:
            print(f"âŒ è·å–{category}æ–°é—»å¤±è´¥: {e}")
            return []
    
    def _process_article(self, article, category):
        """å¤„ç†å•ä¸ªæ–°é—»æ–‡ç« """
        try:
            # ç”Ÿæˆå”¯ä¸€ID
            article_id = hashlib.md5(
                (article.get('title', '') + article.get('url', '')).encode()
            ).hexdigest()[:12]
            
            # ç®€å•çš„ä¸­æ–‡ç¿»è¯‘æ˜ å°„ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰
            title = article.get('title', '')
            description = article.get('description', '')
            
            # åŸºç¡€çš„å…³é”®è¯æ›¿æ¢ç¿»è¯‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
            translation_map = {
                'artificial intelligence': 'äººå·¥æ™ºèƒ½',
                'machine learning': 'æœºå™¨å­¦ä¹ ',
                'ChatGPT': 'ChatGPT',
                'OpenAI': 'OpenAI',
                'technology': 'ç§‘æŠ€',
                'software': 'è½¯ä»¶',
                'application': 'åº”ç”¨',
                'development': 'å¼€å‘',
                'innovation': 'åˆ›æ–°'
            }
            
            # ç®€å•æ›¿æ¢ï¼ˆå®é™…é¡¹ç›®ä¸­åº”ä½¿ç”¨ä¸“ä¸šç¿»è¯‘APIï¼‰
            for en, cn in translation_map.items():
                title = title.replace(en, cn)
                description = description.replace(en, cn)
            
            processed_article = {
                "id": article_id,
                "title": title,
                "summary": description,
                "original_title": article.get('title', ''),
                "original_summary": article.get('description', ''),
                "source": article.get('source', {}).get('name', 'æœªçŸ¥æ¥æº'),
                "url": article.get('url', ''),
                "published_at": article.get('publishedAt', ''),
                "category": category,
                "image_url": article.get('image', ''),
                "freshness": self._calculate_freshness(article.get('publishedAt', '')),
                "crawl_time": datetime.now().isoformat()
            }
            
            return processed_article
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ç« å¤±è´¥: {e}")
            return None
    
    def _calculate_freshness(self, published_at):
        """è®¡ç®—æ–°é—»æ–°é²œåº¦"""
        try:
            if not published_at:
                return "old"
            
            # è§£æå‘å¸ƒæ—¶é—´
            pub_time = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            now = datetime.now(pub_time.tzinfo)
            
            hours_diff = (now - pub_time).total_seconds() / 3600
            
            if hours_diff <= 3:
                return "fresh"
            elif hours_diff <= 12:
                return "recent"
            else:
                return "old"
                
        except Exception:
            return "old"
    
    def load_existing_news(self):
        """åŠ è½½ç°æœ‰æ–°é—»æ•°æ®"""
        try:
            if os.path.exists(self.news_data_file):
                with open(self.news_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('articles', [])
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç°æœ‰æ–°é—»å¤±è´¥: {e}")
        return []
    
    def accumulate_news(self, new_articles, existing_articles):
        """ç´¯ç§¯æ–°é—»ï¼ˆå»é‡å¹¶ä¿ç•™3å¤©å†…å®¹ï¼‰"""
        # åˆ›å»ºç°æœ‰æ–‡ç« IDé›†åˆ
        existing_ids = {article['id'] for article in existing_articles}
        
        # æ·»åŠ æ–°æ–‡ç« ï¼ˆå»é‡ï¼‰
        added_count = 0
        for article in new_articles:
            if article['id'] not in existing_ids:
                existing_articles.append(article)
                added_count += 1
        
        # æŒ‰å‘å¸ƒæ—¶é—´æ’åº
        existing_articles.sort(key=lambda x: x.get('published_at', ''), reverse=True)
        
        # åªä¿ç•™3å¤©å†…çš„æ–°é—»
        three_days_ago = datetime.now() - timedelta(days=3)
        filtered_articles = []
        
        for article in existing_articles:
            try:
                pub_time = datetime.fromisoformat(
                    article.get('published_at', '').replace('Z', '+00:00')
                )
                if pub_time.replace(tzinfo=None) > three_days_ago:
                    filtered_articles.append(article)
            except Exception:
                # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™æ–‡ç« 
                filtered_articles.append(article)
        
        print(f"ğŸ“Š ç´¯ç§¯ç»Ÿè®¡: æ–°å¢{added_count}æ¡ï¼Œæ€»è®¡{len(filtered_articles)}æ¡ï¼Œä¿ç•™3å¤©å†…å®¹")
        return filtered_articles
    
    def save_news_data(self, articles):
        """ä¿å­˜æ–°é—»æ•°æ®"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.news_data_file), exist_ok=True)
            
            news_data = {
                "last_updated": datetime.now().isoformat(),
                "total_articles": len(articles),
                "articles": articles
            }
            
            with open(self.news_data_file, 'w', encoding='utf-8') as f:
                json.dump(news_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ–°é—»æ•°æ®å·²ä¿å­˜åˆ° {self.news_data_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return False
    
    def generate_html(self, articles):
        """ç”ŸæˆHTMLé¡µé¢"""
        try:
            # æŒ‰åˆ†ç±»ç»„ç»‡æ–‡ç« 
            categories = {
                "å…¨éƒ¨": articles,
                "AIæ¨¡å‹": [a for a in articles if a.get('category') == 'AIæ¨¡å‹'],
                "AIå·¥å…·": [a for a in articles if a.get('category') == 'AIå·¥å…·'],
                "AIæŠ€æœ¯": [a for a in articles if a.get('category') == 'AIæŠ€æœ¯'],
                "AIäº§ä¸š": [a for a in articles if a.get('category') == 'AIäº§ä¸š'],
                "AIæ”¿ç­–": [a for a in articles if a.get('category') == 'AIæ”¿ç­–']
            }
            
            html_content = self._generate_html_template(categories)
            
            html_file = 'docs/index.html'
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"âœ… HTMLé¡µé¢å·²ç”Ÿæˆ: {html_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆHTMLå¤±è´¥: {e}")
            return False
    
    def _generate_html_template(self, categories):
        """ç”ŸæˆHTMLæ¨¡æ¿"""
        # ä½¿ç”¨ç°æœ‰çš„HTMLæ¨¡æ¿ç»“æ„
        update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¤– AIç§‘æŠ€æ—¥æŠ¥ - æ™ºèƒ½æ–°é—»æ¨é€</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "SF Pro Display", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }}
        
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }}
        
        .header {{
            text-align: center;
            color: #1d1d1f;
            margin-bottom: 30px;
        }}
        
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
            letter-spacing: -0.02em;
        }}
        
        .header p {{
            font-size: 1.1em;
            color: #86868b;
            font-weight: 400;
        }}
        
        .update-time {{
            background: rgba(255,255,255,0.6);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            padding: 8px 16px;
            border-radius: 20px;
            display: inline-block;
            margin-top: 10px;
            font-size: 0.9em;
            color: #1d1d1f;
            border: 1px solid rgba(255,255,255,0.3);
        }}
        
        .disclaimer {{
            background: rgba(255, 193, 7, 0.1);
            border: 1px solid rgba(255, 193, 7, 0.3);
            color: #856404;
            padding: 12px 20px;
            border-radius: 12px;
            margin-top: 15px;
            font-size: 0.9em;
            font-weight: 500;
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            text-align: center;
        }}
        
        .tabs {{
            display: flex;
            margin-bottom: 30px;
            overflow-x: auto;
            overflow-y: hidden;
            padding: 0 20px 10px 20px;
            gap: 12px;
            scrollbar-width: none;
            -ms-overflow-style: none;
            scroll-behavior: smooth;
        }}
        
        .tabs::-webkit-scrollbar {{
            display: none;
        }}
        
        .tab {{
            background: rgba(255,255,255,0.7);
            color: #1d1d1f;
            border: 1px solid rgba(0,0,0,0.1);
            padding: 12px 24px;
            border-radius: 22px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            flex-shrink: 0;
            white-space: nowrap;
        }}
        
        .tab:hover {{
            background: rgba(255,255,255,0.9);
            transform: translateY(-1px);
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }}
        
        .tab.active {{
            background: #007aff;
            color: white;
            border: 1px solid #007aff;
            box-shadow: 0 4px 20px rgba(0,122,255,0.3);
        }}
        
        .news-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        
        .news-card {{
            background: rgba(255,255,255,0.8);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border: 1px solid rgba(255,255,255,0.3);
            border-radius: 16px;
            padding: 25px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
            transition: all 0.3s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            cursor: pointer;
            position: relative;
            overflow: hidden;
        }}
        
        .news-card:hover {{
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(0,0,0,0.12);
            background: rgba(255,255,255,0.9);
        }}
        
        .news-card::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #007aff, #5856d6);
        }}
        
        .news-title {{
            font-size: 1.3em;
            font-weight: 600;
            color: #333;
            margin-bottom: 15px;
            margin-right: 80px;
            line-height: 1.4;
            display: -webkit-box;
            -webkit-line-clamp: 2;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }}
        
        .news-summary {{
            color: #666;
            font-size: 0.95em;
            margin-bottom: 20px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }}
        
        .news-meta {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.85em;
            color: #888;
            border-top: 1px solid #eee;
            padding-top: 15px;
        }}
        
        .news-source {{
            font-weight: 500;
            color: #007aff;
        }}
        
        .news-time {{
            display: flex;
            align-items: center;
            gap: 5px;
        }}
        
        .category-tag {{
            position: absolute;
            top: 15px;
            right: 15px;
            background: linear-gradient(45deg, #007aff, #5856d6);
            color: white;
            padding: 4px 12px;
            border-radius: 10px;
            font-size: 0.8em;
            font-weight: 600;
            letter-spacing: 0.02em;
        }}
        
        .freshness-indicator {{
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 5px;
        }}
        
        .fresh {{
            background: #10B981;
        }}
        
        .recent {{
            background: #F59E0B;
        }}
        
        .old {{
            background: #EF4444;
        }}
        
        .tab-content {{
            display: none;
        }}
        
        .tab-content.active {{
            display: block;
        }}
        
        .no-news {{
            text-align: center;
            color: #1d1d1f;
            font-size: 1.2em;
            padding: 40px;
            background: rgba(255,255,255,0.7);
            border: 1px solid rgba(255,255,255,0.3);
            border-radius: 16px;
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
        }}
        
        @media (max-width: 768px) {{
            .container {{
                padding: 15px;
            }}
            
            .header h1 {{
                font-size: 2em;
            }}
            
            .tabs {{
                padding: 0 15px 10px 15px;
                gap: 8px;
            }}
            
            .tab {{
                padding: 10px 18px;
                font-size: 14px;
                border-radius: 18px;
                min-width: auto;
            }}
            
            .news-grid {{
                grid-template-columns: 1fr;
                gap: 15px;
            }}
            
            .news-card {{
                padding: 20px;
                border-radius: 12px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– AIç§‘æŠ€æ—¥æŠ¥</h1>
            <div class="update-time">æœ€åæ›´æ–°: {update_time}</div>
            <div class="disclaimer">âš ï¸ å£°æ˜ï¼šæœ¬ç«™æ‰€æœ‰æ–°é—»å‡ä¸ºæµ·å¤–åª’ä½“è½¬æ¨ï¼Œä½¿ç”¨æƒå¨GNews APIå®æ—¶åŒæ­¥ï¼Œéæœ¬ç«™åŸåˆ›å†…å®¹ | AIäº¤æµç¾¤ï¼š<span id="groupId" onclick="copyGroupId()" style="cursor: pointer; color: #007AFF; text-decoration: underline;">forxy9</span></div>
        </div>
        
        <div class="tabs">
'''
        
        # æ·»åŠ tabæŒ‰é’®
        for i, category in enumerate(categories.keys()):
            active_class = " active" if i == 0 else ""
            html += f'            <button class="tab{active_class}" onclick="showCategory(\'{category}\')">{category}</button>\n'
        
        html += '        </div>\n\n'
        
        # æ·»åŠ æ¯ä¸ªåˆ†ç±»çš„å†…å®¹
        for i, (category, articles) in enumerate(categories.items()):
            active_class = " active" if i == 0 else ""
            html += f'        <div id="category-{category}" class="tab-content{active_class}">\n'
            
            if articles:
                html += '<div class="news-grid">\n'
                for article in articles[:20]:  # é™åˆ¶æ¯ä¸ªåˆ†ç±»æœ€å¤š20æ¡
                    html += self._generate_article_html(article)
                html += '</div>'
            else:
                html += '<div class="no-news">æš‚æ— ç›¸å…³æ–°é—»</div>'
            
            html += '</div>\n\n'
        
        # æ·»åŠ JavaScript
        html += '''    </div>
    
    <script>
        function showCategory(category) {
            // éšè—æ‰€æœ‰tabå†…å®¹
            const contents = document.querySelectorAll('.tab-content');
            contents.forEach(content => content.classList.remove('active'));
            
            // ç§»é™¤æ‰€æœ‰tabçš„activeçŠ¶æ€
            const tabs = document.querySelectorAll('.tab');
            tabs.forEach(tab => tab.classList.remove('active'));
            
            // æ˜¾ç¤ºé€‰ä¸­çš„åˆ†ç±»
            document.getElementById('category-' + category).classList.add('active');
            
            // æ¿€æ´»é€‰ä¸­çš„tab
            event.target.classList.add('active');
        }
        
        function openDetail(articleId) {
            window.open('news/' + articleId + '.html', '_blank');
        }
        
        function copyGroupId() {
            const groupId = 'forxy9';
            navigator.clipboard.writeText(groupId).then(function() {
                // åˆ›å»ºä¸´æ—¶æç¤º
                const span = document.getElementById('groupId');
                const originalText = span.textContent;
                span.textContent = 'å¤åˆ¶æˆåŠŸï¼Œå»å¾®ä¿¡æœç´¢';
                span.style.color = '#34C759';
                
                // 2ç§’åæ¢å¤åŸæ–‡æœ¬
                setTimeout(function() {
                    span.textContent = originalText;
                    span.style.color = '#007AFF';
                }, 2000);
            }).catch(function(err) {
                console.error('å¤åˆ¶å¤±è´¥: ', err);
                alert('å¤åˆ¶å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶: forxy9');
            });
        }
        
        // æ·»åŠ å¡ç‰‡ç‚¹å‡»äº‹ä»¶
        document.addEventListener('DOMContentLoaded', function() {
            const cards = document.querySelectorAll('.news-card');
            cards.forEach(card => {
                card.addEventListener('click', function() {
                    const url = this.dataset.url;
                    if (url) {
                        window.open(url, '_blank');
                    }
                });
            });
        });
    </script>
</body>
</html>'''
        
        return html
    
    def _generate_article_html(self, article):
        """ç”Ÿæˆå•ä¸ªæ–‡ç« çš„HTML"""
        # è®¡ç®—å‘å¸ƒæ—¶é—´
        try:
            pub_time = datetime.fromisoformat(article.get('published_at', '').replace('Z', '+00:00'))
            now = datetime.now(pub_time.tzinfo)
            hours_diff = (now - pub_time).total_seconds() / 3600
            
            if hours_diff < 1:
                time_str = "åˆšåˆš"
            elif hours_diff < 24:
                time_str = f"{int(hours_diff)}å°æ—¶å‰"
            else:
                time_str = f"{int(hours_diff/24)}å¤©å‰"
        except Exception:
            time_str = "æœªçŸ¥æ—¶é—´"
        
        freshness_class = article.get('freshness', 'old')
        
        return f'''            <div class="news-card" data-url="{article.get('url', '')}">
                <div class="category-tag">{article.get('category', 'æœªåˆ†ç±»')}</div>
                <div class="news-title">{article.get('title', 'æ— æ ‡é¢˜')}</div>
                <div class="news-summary">{article.get('summary', 'æ— æ‘˜è¦')}</div>
                <div class="news-meta">
                    <span class="news-source">{article.get('source', 'æœªçŸ¥æ¥æº')}</span>
                    <span class="news-time">
                        <span class="freshness-indicator {freshness_class}"></span>
                        {time_str}
                    </span>
                </div>
            </div>
        
'''
    
    def run(self):
        """è¿è¡Œæ–°é—»ç´¯ç§¯æ›´æ–°"""
        try:
            print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆAIæ–°é—»ç´¯ç§¯æ›´æ–°ç³»ç»Ÿ...")
            
            # 1. è·å–æœ€æ–°æ–°é—»
            print("\nğŸ“¡ è·å–æœ€æ–°æ–°é—»...")
            new_articles = self.get_latest_news()
            
            if not new_articles:
                print("âš ï¸ æœªè·å–åˆ°æ–°æ–‡ç« ")
                return False
            
            # 2. åŠ è½½ç°æœ‰æ–°é—»
            print("\nğŸ“š åŠ è½½ç°æœ‰æ–°é—»æ•°æ®...")
            existing_articles = self.load_existing_news()
            
            # 3. ç´¯ç§¯æ–°é—»ï¼ˆå»é‡å’Œæ—¶é—´è¿‡æ»¤ï¼‰
            print("\nğŸ”„ ç´¯ç§¯æ›´æ–°æ–°é—»...")
            all_articles = self.accumulate_news(new_articles, existing_articles)
            
            # 4. ä¿å­˜æ•°æ®
            print("\nğŸ’¾ ä¿å­˜æ–°é—»æ•°æ®...")
            if not self.save_news_data(all_articles):
                return False
            
            # 5. ç”ŸæˆHTML
            print("\nğŸŒ ç”ŸæˆHTMLé¡µé¢...")
            if not self.generate_html(all_articles):
                return False
            
            print(f"\nâœ… ç´¯ç§¯æ›´æ–°å®Œæˆï¼æ€»è®¡ {len(all_articles)} æ¡æ–°é—»")
            return True
            
        except Exception as e:
            print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
            return False

if __name__ == "__main__":
    try:
        accumulator = SimpleAINewsAccumulator()
        success = accumulator.run()
        if success:
            print("\nğŸ‰ æ–°é—»æ›´æ–°ä»»åŠ¡å®Œæˆï¼")
        else:
            print("\nâŒ æ–°é—»æ›´æ–°ä»»åŠ¡å¤±è´¥ï¼")
            exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        exit(1)
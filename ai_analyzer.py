import requests
import json
from typing import Dict, List
from config import Config
import logging

logger = logging.getLogger(__name__)

class AIAnalyzer:
    def __init__(self):
        self.config = Config()
    
    def generate_commentary_and_analysis(self, news_item: Dict) -> Dict:
        """
        ä¸ºæ–°é—»ç”Ÿæˆç‚¹è¯„å’Œå¯¹ä¸­å›½è¡Œä¸šå½±å“åˆ†æ
        """
        title = news_item.get('title', '')
        description = news_item.get('description', '')
        content = news_item.get('content', '')
        
        # ç¿»è¯‘è‹±æ–‡æ ‡é¢˜ä¸ºä¸­æ–‡
        chinese_title = self._translate_title_to_chinese(title)
        
        # ä½¿ç”¨ç®€å•çš„å…³é”®è¯åˆ†æç”Ÿæˆç‚¹è¯„ï¼ˆå…è´¹æ–¹æ¡ˆï¼‰
        commentary = self._generate_simple_commentary(title, description)
        china_impact = self._analyze_china_impact(title, description, content)
        
        return {
            'chinese_title': chinese_title,
            'commentary': commentary,
            'china_impact_analysis': china_impact
        }
    
    def _translate_title_to_chinese(self, title: str) -> str:
        """
        å°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘ä¸ºä¸­æ–‡ï¼ˆåŸºäºå…³é”®è¯æ˜ å°„ï¼‰
        """
        if not title:
            return title
            
        # å¸¸ç”¨AIç›¸å…³è¯æ±‡ç¿»è¯‘è¡¨
        translations = {
            # å…¬å¸åç§°
            'OpenAI': 'OpenAI',
            'Google': 'è°·æ­Œ',
            'Microsoft': 'å¾®è½¯',
            'Meta': 'Meta',
            'Apple': 'è‹¹æœ',
            'Amazon': 'äºšé©¬é€Š',
            'Tesla': 'ç‰¹æ–¯æ‹‰',
            'NVIDIA': 'è‹±ä¼Ÿè¾¾',
            'Anthropic': 'Anthropic',
            
            # AIæŠ€æœ¯è¯æ±‡
            'Artificial Intelligence': 'äººå·¥æ™ºèƒ½',
            'AI': 'AI',
            'Machine Learning': 'æœºå™¨å­¦ä¹ ',
            'Deep Learning': 'æ·±åº¦å­¦ä¹ ',
            'Neural Network': 'ç¥ç»ç½‘ç»œ',
            'Large Language Model': 'å¤§è¯­è¨€æ¨¡å‹',
            'LLM': 'å¤§è¯­è¨€æ¨¡å‹',
            'ChatGPT': 'ChatGPT',
            'GPT': 'GPT',
            'GPT-4': 'GPT-4',
            'GPT-5': 'GPT-5',
            'Gemini': 'Gemini',
            'Bard': 'Bard',
            'Copilot': 'Copilot',
            
            # åŠ¨ä½œè¯æ±‡
            'Launches': 'å‘å¸ƒ',
            'Releases': 'å‘å¸ƒ',
            'Announces': 'å®£å¸ƒ',
            'Introduces': 'æ¨å‡º',
            'Unveils': 'æ­æ™“',
            'Updates': 'æ›´æ–°',
            'Improves': 'æ”¹è¿›',
            'Enhances': 'å¢å¼º',
            'Develops': 'å¼€å‘',
            'Creates': 'åˆ›å»º',
            'Builds': 'æ„å»º',
            
            # æŠ€æœ¯ç‰¹æ€§
            'Breakthrough': 'çªç ´',
            'Innovation': 'åˆ›æ–°',
            'Revolution': 'é©å‘½',
            'Advanced': 'å…ˆè¿›çš„',
            'New': 'å…¨æ–°',
            'Latest': 'æœ€æ–°',
            'Next-Generation': 'ä¸‹ä¸€ä»£',
            'Powerful': 'å¼ºå¤§çš„',
            'Smart': 'æ™ºèƒ½',
            'Intelligent': 'æ™ºèƒ½çš„',
            
            # åº”ç”¨é¢†åŸŸ
            'Healthcare': 'åŒ»ç–—',
            'Education': 'æ•™è‚²',
            'Finance': 'é‡‘è',
            'Automotive': 'æ±½è½¦',
            'Robotics': 'æœºå™¨äºº',
            'Gaming': 'æ¸¸æˆ',
            'Research': 'ç ”ç©¶',
            'Development': 'å¼€å‘',
        }
        
        # å¼€å§‹ç¿»è¯‘
        chinese_title = title
        
        # æ›¿æ¢å…³é”®è¯
        for en_word, zh_word in translations.items():
            # ä¸åŒºåˆ†å¤§å°å†™æ›¿æ¢
            chinese_title = chinese_title.replace(en_word, zh_word)
            chinese_title = chinese_title.replace(en_word.lower(), zh_word)
            chinese_title = chinese_title.replace(en_word.upper(), zh_word)
        
        # å¦‚æœç¿»è¯‘åè¿˜å¤§é‡åŒ…å«è‹±æ–‡ï¼Œæ·»åŠ ä¸­æ–‡å‰ç¼€
        english_chars = sum(1 for c in chinese_title if c.isascii() and c.isalpha())
        total_chars = len(chinese_title.replace(' ', ''))
        
        if total_chars > 0 and english_chars / total_chars > 0.6:  # å¦‚æœ60%ä»¥ä¸Šæ˜¯è‹±æ–‡
            # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ é€‚å½“çš„ä¸­æ–‡æè¿°
            if any(word in title.lower() for word in ['release', 'launch', 'announce']):
                chinese_title = f"ğŸš€ æœ€æ–°å‘å¸ƒï¼š{chinese_title}"
            elif any(word in title.lower() for word in ['breakthrough', 'innovation']):
                chinese_title = f"ğŸ’¡ æŠ€æœ¯çªç ´ï¼š{chinese_title}"
            elif any(word in title.lower() for word in ['update', 'improve', 'enhance']):
                chinese_title = f"ğŸ”„ é‡å¤§æ›´æ–°ï¼š{chinese_title}"
            else:
                chinese_title = f"ğŸ“° AIèµ„è®¯ï¼š{chinese_title}"
        
        return chinese_title
    
    def _generate_simple_commentary(self, title: str, description: str) -> str:
        """
        åŸºäºå…³é”®è¯ç”Ÿæˆç®€å•ç‚¹è¯„
        """
        text = (title + ' ' + description).lower()
        
        # AIæŠ€æœ¯å‘å±•ç›¸å…³
        if any(keyword in text for keyword in ['breakthrough', 'innovation', 'advancement', 'new model']):
            return "è¿™é¡¹AIæŠ€æœ¯çªç ´å€¼å¾—å…³æ³¨ï¼Œå¯èƒ½ä¼šæ¨åŠ¨è¡Œä¸šå‘å±•è¿›å…¥æ–°é˜¶æ®µã€‚"
        
        # å•†ä¸šåº”ç”¨ç›¸å…³
        elif any(keyword in text for keyword in ['business', 'enterprise', 'commercial', 'market']):
            return "è¯¥AIåº”ç”¨çš„å•†ä¸šåŒ–è¿›å±•æ˜¾ç¤ºäº†æŠ€æœ¯è½åœ°çš„å®é™…ä»·å€¼ï¼Œå€¼å¾—äº§ä¸šç•Œå¯†åˆ‡å…³æ³¨ã€‚"
        
        # ç›‘ç®¡æ”¿ç­–ç›¸å…³
        elif any(keyword in text for keyword in ['regulation', 'policy', 'government', 'law']):
            return "AIç›‘ç®¡æ”¿ç­–çš„å˜åŒ–å°†å¯¹æ•´ä¸ªè¡Œä¸šç”Ÿæ€äº§ç”Ÿæ·±è¿œå½±å“ï¼Œéœ€è¦æŒç»­è·Ÿè¸ªã€‚"
        
        # æŠ€æœ¯ç«äº‰ç›¸å…³
        elif any(keyword in text for keyword in ['competition', 'vs', 'rivalry', 'race']):
            return "æŠ€æœ¯ç«äº‰åŠ å‰§åæ˜ äº†AIé¢†åŸŸçš„å¿«é€Ÿå‘å±•ï¼Œå„æ–¹éƒ½åœ¨äº‰å¤ºæŠ€æœ¯åˆ¶é«˜ç‚¹ã€‚"
        
        # é»˜è®¤ç‚¹è¯„
        else:
            return "è¿™ä¸€AIæŠ€æœ¯å‘å±•åŠ¨å‘å€¼å¾—è¡Œä¸šä»ä¸šè€…å…³æ³¨ï¼Œå¯èƒ½å¸¦æ¥æ–°çš„æœºé‡ä¸æŒ‘æˆ˜ã€‚"
    
    def _analyze_china_impact(self, title: str, description: str, content: str) -> str:
        """
        åˆ†æå¯¹ä¸­å›½å›½å†…è¡Œä¸šçš„ç›¸å…³å½±å“
        """
        text = (title + ' ' + description + ' ' + content).lower()
        
        # å¤§æ¨¡å‹ç›¸å…³
        if any(keyword in text for keyword in ['gpt', 'llm', 'large language model', 'chatbot']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. æŠ€æœ¯è¿½èµ¶ï¼šä¿ƒè¿›å›½å†…å¤§æ¨¡å‹æŠ€æœ¯å‘å±•ï¼ŒåŠ é€Ÿäº§ä¸šå‡çº§
2. å•†ä¸šæœºä¼šï¼šä¸ºå›½å†…AIä¼ä¸šæä¾›æ–°çš„å•†ä¸šæ¨¡å¼å‚è€ƒ
3. ç›‘ç®¡æ€è€ƒï¼šå¯èƒ½æ¨åŠ¨ç›¸å…³ç›‘ç®¡æ”¿ç­–çš„å®Œå–„å’Œè°ƒæ•´"""
        
        # è‡ªåŠ¨é©¾é©¶ç›¸å…³
        elif any(keyword in text for keyword in ['autonomous', 'self-driving', 'vehicle', 'car']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. äº§ä¸šååŒï¼šæ¨åŠ¨å›½å†…æ±½è½¦ä¸AIäº§ä¸šæ·±åº¦èåˆ
2. åŸºç¡€è®¾æ–½ï¼šåŠ é€Ÿæ™ºèƒ½äº¤é€šåŸºç¡€è®¾æ–½å»ºè®¾
3. æ”¿ç­–å¯¼å‘ï¼šå¯èƒ½å½±å“è‡ªåŠ¨é©¾é©¶ç›¸å…³æ³•è§„åˆ¶å®š"""
        
        # èŠ¯ç‰‡åŠå¯¼ä½“ç›¸å…³
        elif any(keyword in text for keyword in ['chip', 'semiconductor', 'processor', 'gpu']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. æŠ€æœ¯è‡ªä¸»ï¼šæ¨åŠ¨å›½äº§AIèŠ¯ç‰‡æŠ€æœ¯å‘å±•
2. ä¾›åº”é“¾ï¼šå½±å“åŠå¯¼ä½“äº§ä¸šé“¾å¸ƒå±€å’ŒæŠ•èµ„æ–¹å‘
3. æˆ˜ç•¥é‡è¦æ€§ï¼šå‡¸æ˜¾AIèŠ¯ç‰‡åœ¨å›½å®¶ç§‘æŠ€æˆ˜ç•¥ä¸­çš„åœ°ä½"""
        
        # åŒ»ç–—å¥åº·ç›¸å…³
        elif any(keyword in text for keyword in ['health', 'medical', 'drug', 'diagnosis']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. åŒ»ç–—å‡çº§ï¼šæ¨åŠ¨å›½å†…æ™ºæ…§åŒ»ç–—äº§ä¸šå‘å±•
2. ç›‘ç®¡å®Œå–„ï¼šä¿ƒè¿›AIåŒ»ç–—ç›¸å…³æ ‡å‡†å’Œè§„èŒƒå»ºç«‹
3. æŠ•èµ„çƒ­ç‚¹ï¼šå¯èƒ½æˆä¸ºæ–°çš„æŠ•èµ„å’Œåˆ›ä¸šæ–¹å‘"""
        
        # æ•™è‚²ç›¸å…³
        elif any(keyword in text for keyword in ['education', 'learning', 'student', 'teacher']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. æ•™è‚²å˜é©ï¼šæ¨åŠ¨ä¼ ç»Ÿæ•™è‚²æ¨¡å¼å‘æ™ºèƒ½åŒ–è½¬å‹
2. äº§ä¸šæœºé‡ï¼šä¸ºæ•™è‚²ç§‘æŠ€ä¼ä¸šå¸¦æ¥æ–°å‘å±•æœºä¼š
3. äººæ‰åŸ¹å…»ï¼šå½±å“AIç›¸å…³äººæ‰åŸ¹å…»æ¨¡å¼å’Œè¯¾ç¨‹è®¾è®¡"""
        
        # é‡‘èç§‘æŠ€ç›¸å…³
        elif any(keyword in text for keyword in ['finance', 'bank', 'trading', 'fintech']):
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. é‡‘èåˆ›æ–°ï¼šæ¨åŠ¨å›½å†…é‡‘èç§‘æŠ€åº”ç”¨åˆ›æ–°
2. é£æ§å‡çº§ï¼šæå‡é‡‘èé£é™©ç®¡ç†æ™ºèƒ½åŒ–æ°´å¹³
3. ç›‘ç®¡é€‚åº”ï¼šéœ€è¦é‡‘èç›‘ç®¡æ¡†æ¶ä¸AIæŠ€æœ¯åè°ƒå‘å±•"""
        
        # é»˜è®¤åˆ†æ
        else:
            return """å¯¹ä¸­å›½å½±å“ï¼š
1. æŠ€æœ¯å€Ÿé‰´ï¼šä¸ºå›½å†…AIæŠ€æœ¯å‘å±•æä¾›å‚è€ƒå’Œå¯å‘
2. å¸‚åœºæœºé‡ï¼šå¯èƒ½ä¸ºç›¸å…³äº§ä¸šå¸¦æ¥æ–°çš„å•†ä¸šæœºä¼š
3. ç«äº‰æ€åŠ¿ï¼šéœ€è¦è¯„ä¼°å¯¹å›½å†…AIäº§ä¸šç«äº‰æ ¼å±€çš„å½±å“"""

if __name__ == "__main__":
    analyzer = AIAnalyzer()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_news = {
        'title': 'OpenAI Launches New GPT-4 Model with Advanced Capabilities',
        'description': 'The new model shows significant improvements in reasoning and multimodal understanding.',
        'content': 'OpenAI has released an updated version of GPT-4 that demonstrates enhanced capabilities...'
    }
    
    result = analyzer.generate_commentary_and_analysis(test_news)
    print("ç‚¹è¯„:", result['commentary'])
    print("\nå½±å“åˆ†æ:", result['china_impact_analysis'])
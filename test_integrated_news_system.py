#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•é›†æˆç¿»è¯‘å¼•æ“åçš„æ–°é—»ç³»ç»Ÿ
"""

import json
from datetime import datetime
from news_accumulator import AINewsAccumulator

def test_news_translation_integration():
    """æµ‹è¯•æ–°é—»ç¿»è¯‘é›†æˆåŠŸèƒ½"""
    print("ğŸš€ æµ‹è¯•é›†æˆç¿»è¯‘å¼•æ“åçš„æ–°é—»ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ–°é—»ç´¯ç§¯å™¨
    accumulator = AINewsAccumulator()
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    test_articles = [
        {
            'title': 'OpenAI Releases GPT-4 Turbo with Enhanced Reasoning Capabilities',
            'description': 'OpenAI has announced the release of GPT-4 Turbo, featuring improved reasoning capabilities and faster processing speeds. The new model demonstrates significant improvements in complex problem-solving tasks and maintains better context awareness across longer conversations.',
            'url': 'https://example.com/openai-gpt4-turbo',
            'source': {'name': 'TechCrunch'},
            'publishedAt': '2025-07-24T10:00:00Z',
            'image': 'https://example.com/image1.jpg',
            'search_category': 'AIç§‘æŠ€'
        },
        {
            'title': 'PlayStation 5 Pro Launches with 8K Gaming and Ray Tracing Support',
            'description': 'Sony has officially launched the PlayStation 5 Pro, featuring enhanced hardware capable of 8K gaming and advanced ray tracing. The console promises to deliver unprecedented gaming experiences with improved graphics and performance.',
            'url': 'https://example.com/ps5-pro-launch',
            'source': {'name': 'GameSpot'},
            'publishedAt': '2025-07-24T09:30:00Z',
            'image': 'https://example.com/image2.jpg',
            'search_category': 'æ¸¸æˆç§‘æŠ€'
        },
        {
            'title': 'Tesla Stock Surges 20% Following Q3 Earnings Beat',
            'description': 'Tesla shares jumped 20% in after-hours trading following the company\'s third-quarter earnings report, which exceeded analyst expectations. The electric vehicle maker reported record deliveries and improved profit margins.',
            'url': 'https://example.com/tesla-earnings',
            'source': {'name': 'Reuters'},
            'publishedAt': '2025-07-24T08:45:00Z',
            'image': 'https://example.com/image3.jpg',
            'search_category': 'ç»æµé‡‘è'
        }
    ]
    
    print(f"ğŸ“° æµ‹è¯• {len(test_articles)} æ¡æ–°é—»çš„ç¿»è¯‘é›†æˆ")
    print("-" * 40)
    
    translated_news = []
    
    for i, article in enumerate(test_articles, 1):
        print(f"\nğŸ”„ å¤„ç†ç¬¬ {i} æ¡æ–°é—»: {article['search_category']}")
        print(f"åŸæ ‡é¢˜: {article['title']}")
        print(f"åŸæè¿°: {article['description'][:100]}...")
        
        try:
            # ç¿»è¯‘æ ‡é¢˜
            chinese_title = accumulator.translate_title(
                article['title'], 
                article['search_category']
            )
            
            # ç¿»è¯‘æè¿°
            chinese_description = accumulator.translate_description(
                article['description'],
                article['title'],
                article['search_category']
            )
            
            # ç”Ÿæˆç¿»è¯‘å…ƒæ•°æ®
            translation_metadata = accumulator._get_translation_metadata(
                article['title'],
                article['description'],
                chinese_title,
                chinese_description,
                article['search_category']
            )
            
            # åˆ›å»ºæ–°é—»é¡¹
            news_item = {
                "id": accumulator.generate_news_id(article),
                "title": chinese_title,
                "original_title": article['title'],
                "description": chinese_description,
                "original_description": article['description'],
                "url": article['url'],
                "source": article['source']['name'],
                "publishedAt": article['publishedAt'],
                "image": article['image'],
                "category": accumulator.categorize_news(chinese_title, article['search_category']),
                "importance": accumulator.get_importance_score(chinese_title),
                "added_time": datetime.now().isoformat(),
                "search_category": article['search_category'],
                "translation_metadata": translation_metadata
            }
            
            translated_news.append(news_item)
            
            print(f"âœ… ä¸­æ–‡æ ‡é¢˜: {chinese_title}")
            print(f"âœ… ä¸­æ–‡æè¿°: {chinese_description[:100]}...")
            print(f"ğŸ“Š ç¿»è¯‘è´¨é‡:")
            print(f"   - æ ‡é¢˜ç½®ä¿¡åº¦: {translation_metadata['title_translation']['confidence']:.3f}")
            print(f"   - æè¿°ç½®ä¿¡åº¦: {translation_metadata['description_translation']['confidence']:.3f}")
            print(f"   - æ•´ä½“æˆåŠŸç‡: {translation_metadata['overall_quality']['translation_success_rate']:.1%}")
            print(f"   - AIç¿»è¯‘: {'æ˜¯' if translation_metadata['overall_quality']['has_ai_translation'] else 'å¦'}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        
        print("-" * 40)
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_result_file = 'test_translation_integration_result.json'
    try:
        with open(test_result_file, 'w', encoding='utf-8') as f:
            json.dump(translated_news, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_result_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {str(e)}")
    
    # ç»Ÿè®¡ç¿»è¯‘è´¨é‡
    if translated_news:
        print(f"\nğŸ“Š ç¿»è¯‘è´¨é‡ç»Ÿè®¡:")
        total_confidence = 0
        ai_translation_count = 0
        
        for news in translated_news:
            metadata = news['translation_metadata']
            total_confidence += metadata['overall_quality']['average_confidence']
            if metadata['overall_quality']['has_ai_translation']:
                ai_translation_count += 1
        
        avg_confidence = total_confidence / len(translated_news)
        ai_translation_rate = ai_translation_count / len(translated_news)
        
        print(f"   - å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   - AIç¿»è¯‘è¦†ç›–ç‡: {ai_translation_rate:.1%}")
        print(f"   - å¤„ç†æˆåŠŸç‡: {len(translated_news)}/{len(test_articles)} = {len(translated_news)/len(test_articles):.1%}")
    
    print(f"\nğŸ‰ ç¿»è¯‘é›†æˆæµ‹è¯•å®Œæˆ!")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”§ æ–°é—»ç¿»è¯‘ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    try:
        test_news_translation_integration()
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
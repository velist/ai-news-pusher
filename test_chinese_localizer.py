#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¸­æ–‡æœ¬åœ°åŒ–å™¨åŠŸèƒ½
"""

from localization.chinese_localizer import ChineseLocalizer

def test_chinese_localizer():
    """æµ‹è¯•ä¸­æ–‡æœ¬åœ°åŒ–å™¨çš„å„é¡¹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¸­æ–‡æœ¬åœ°åŒ–å™¨åŠŸèƒ½")
    print("=" * 50)
    
    localizer = ChineseLocalizer()
    
    # æµ‹è¯•1: åˆ†ç±»æœ¬åœ°åŒ–
    print("ğŸ“‹ æµ‹è¯•1: æ–°é—»åˆ†ç±»æœ¬åœ°åŒ–")
    test_categories = ['technology', 'gaming', 'business', 'AI', 'unknown_category']
    
    for category in test_categories:
        localized = localizer.localize_category(category)
        print(f"   {category} â†’ {localized}")
    
    print("   âœ… åˆ†ç±»æœ¬åœ°åŒ–æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•2: UIæ–‡æœ¬æœ¬åœ°åŒ–
    print("\nğŸ“‹ æµ‹è¯•2: UIæ–‡æœ¬æœ¬åœ°åŒ–")
    test_ui_keys = ['read_more', 'original_text', 'translation_quality', 'settings', 'unknown_key']
    
    for key in test_ui_keys:
        localized = localizer.localize_ui_text(key)
        print(f"   {key} â†’ {localized}")
    
    print("   âœ… UIæ–‡æœ¬æœ¬åœ°åŒ–æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•3: ç¿»è¯‘è´¨é‡è¯„åˆ†
    print("\nğŸ“‹ æµ‹è¯•3: ç¿»è¯‘è´¨é‡è¯„åˆ†")
    test_scores = [0.95, 0.85, 0.75, 0.65, 0.45]
    
    for score in test_scores:
        quality_text = localizer.format_quality_score(score)
        quality_detail = localizer.get_quality_description(score)
        print(f"   è¯„åˆ† {score} â†’ {quality_text} ({quality_detail['detail']})")
    
    print("   âœ… ç¿»è¯‘è´¨é‡è¯„åˆ†æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•4: é˜…è¯»æ—¶é—´ä¼°ç®—
    print("\nğŸ“‹ æµ‹è¯•4: é˜…è¯»æ—¶é—´ä¼°ç®—")
    test_contents = [
        "è¿™æ˜¯ä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•æ–‡æœ¬ã€‚",
        "è¿™æ˜¯ä¸€ä¸ªè¾ƒé•¿çš„æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«æ›´å¤šçš„ä¸­æ–‡å­—ç¬¦ï¼Œç”¨äºæµ‹è¯•é˜…è¯»æ—¶é—´ä¼°ç®—åŠŸèƒ½çš„å‡†ç¡®æ€§ã€‚" * 5,
        "This is a mixed content with both English and ä¸­æ–‡å­—ç¬¦ to test the reading time estimation.",
        "A" * 1000  # é•¿è‹±æ–‡æ–‡æœ¬
    ]
    
    for i, content in enumerate(test_contents, 1):
        reading_time = localizer.get_reading_time_estimate(content)
        print(f"   æµ‹è¯•{i} (é•¿åº¦: {len(content)}å­—ç¬¦) â†’ é˜…è¯»æ—¶é—´: {reading_time}")
    
    print("   âœ… é˜…è¯»æ—¶é—´ä¼°ç®—æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•5: æ–°é—»æºæœ¬åœ°åŒ–
    print("\nğŸ“‹ æµ‹è¯•5: æ–°é—»æºæœ¬åœ°åŒ–")
    test_sources = ['TechCrunch', 'Reuters', 'BBC', 'Unknown Source']
    
    for source in test_sources:
        localized = localizer.localize_source_name(source)
        print(f"   {source} â†’ {localized}")
    
    print("   âœ… æ–°é—»æºæœ¬åœ°åŒ–æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•6: æ–°é—»æ‘˜è¦æ ¼å¼åŒ–
    print("\nğŸ“‹ æµ‹è¯•6: æ–°é—»æ‘˜è¦æ ¼å¼åŒ–")
    test_news = {
        'title': 'OpenAI Announces New AI Model',
        'description': 'OpenAI has announced a breakthrough in artificial intelligence technology that could revolutionize the industry.',
        'category': 'technology',
        'source': {'name': 'TechCrunch'},
        'ai_translation': {
            'translation_confidence': {
                'title': 0.92,
                'description': 0.88
            }
        }
    }
    
    summary = localizer.format_news_summary(test_news)
    print(f"   æ ‡é¢˜: {summary['title']}")
    print(f"   åˆ†ç±»: {summary['category']}")
    print(f"   æ¥æº: {summary['source']}")
    print(f"   é˜…è¯»æ—¶é—´: {summary['reading_time']}")
    if 'quality' in summary:
        print(f"   ç¿»è¯‘è´¨é‡: {summary['quality']['text']} ({summary['quality']['percentage']})")
    
    print("   âœ… æ–°é—»æ‘˜è¦æ ¼å¼åŒ–æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•7: æœ¬åœ°åŒ–é…ç½®
    print("\nğŸ“‹ æµ‹è¯•7: æœ¬åœ°åŒ–é…ç½®")
    config = localizer.get_localized_config()
    print(f"   è¯­è¨€: {config['language']}")
    print(f"   æ—¶åŒº: {config['timezone']}")
    print(f"   æ—¥æœŸæ ¼å¼: {config['date_format']}")
    print(f"   å­—ä½“: {config['font_family']}")
    print("   âœ… æœ¬åœ°åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
    
    print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_chinese_localizer()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨çš„ä¸­æ–‡æ–°é—»ç”Ÿæˆå™¨ - å¤„ç†çœŸå®AIæ–°é—»çš„å®Œæ•´ä¸­æ–‡ç¿»è¯‘
"""

import json
import os
from datetime import datetime
import re

class ChineseNewsGenerator:
    def __init__(self):
        self.today = datetime.now()
    
    def translate_title_completely(self, title):
        """å®Œæ•´çš„ä¸­æ–‡ç¿»è¯‘ - ä¸“é—¨å¤„ç†å¤æ‚è‹±æ–‡æ ‡é¢˜"""
        if not title:
            return ""
        
        # é¢„å¤„ç†ç‰¹æ®Šæ ‡é¢˜
        special_translations = {
            "'Many people don't feel comfortable opening up to family or friends': OpenAI's new Applications chief makes a bold mission statement that's both revealing and scary": 
            "ğŸ¤– OpenAIåŠ¨æ€ï¼šåº”ç”¨ä¸šåŠ¡ä¸»ç®¡ç§°'å¾ˆå¤šäººä¸æ„¿å‘å®¶äººæœ‹å‹æ•å¼€å¿ƒæ‰‰'ï¼ŒAIé™ªä¼´å¼•å‘æ€è€ƒ",
            
            "Tech giant OpenAI signs deal with government to boost efficiency in public services":
            "ğŸ¤ æ”¿åºœåˆä½œï¼šç§‘æŠ€å·¨å¤´OpenAIä¸æ”¿åºœç­¾ç½²åè®®ï¼ŒåŠ©åŠ›æå‡å…¬å…±æœåŠ¡æ•ˆç‡",
            
            "This AI Giant Down 18% Is My Buy-and-Hold-Forever Technology Play":
            "ğŸ’° æŠ•èµ„è§‚ç‚¹ï¼šAIå·¨å¤´è‚¡ä»·ä¸‹è·Œ18%ï¼ŒæŠ•èµ„ä¸“å®¶çœ‹å¥½é•¿æœŸæŒæœ‰ä»·å€¼",
            
            "Silicon Valley trades researchers like footballers":
            "ğŸ’¼ äººæ‰æµåŠ¨ï¼šç¡…è°·AIç ”ç©¶å‘˜æµåŠ¨å¦‚è¶³çƒè½¬ä¼šï¼Œäººæ‰äº‰å¤ºæˆ˜æ¿€çƒˆ",
            
            "Betaworks' third fund closes at $66M to invest in AI startups":
            "ğŸ’° æŠ•èµ„åŠ¨æ€ï¼šBetaworksç¬¬ä¸‰æœŸåŸºé‡‘6600ä¸‡ç¾å…ƒå®Œæˆå‹Ÿèµ„ï¼Œä¸“æŠ•AIåˆåˆ›å…¬å¸",
            
            "Kioxia LC9 Is The World's First 245TB SSD For AI Applications":
            "ğŸ”§ ç¡¬ä»¶çªç ´ï¼šé“ ä¾ å‘å¸ƒå…¨çƒé¦–æ¬¾245TB SSDï¼Œä¸“ä¸ºAIåº”ç”¨è®¾è®¡",
            
            "This startup thinks emAIl could be the key to AI agent adoption":
            "ğŸš€ åˆ›æ–°åº”ç”¨ï¼šåˆåˆ›å…¬å¸è®¤ä¸ºAIé‚®ä»¶åŠ©æ‰‹å°†æˆä¸ºæ™ºèƒ½ä»£ç†æ™®åŠå…³é”®",
            
            "AWS is already limiting access to its new Kindle Scribe AI feature":
            "ğŸ“š äº§å“æ›´æ–°ï¼šAWSé™åˆ¶æ–°æ¬¾Kindle Scribe AIåŠŸèƒ½è®¿é—®æƒé™",
            
            "Molly-Mae Hague left 'gobsmacked' as she watches AI version of herself":
            "ğŸ­ AIå¨±ä¹ï¼šç½‘çº¢æƒŠå¹è§‚çœ‹AIç‰ˆæœ¬è‡ªå·±ï¼Œè™šæ‹ŸäººæŠ€æœ¯å¼•å…³æ³¨",
            
            "Nothing's new $99 CMF Watch 3 Pro could become the best Apple Watch alternative":
            "âŒš æ™ºèƒ½ç©¿æˆ´ï¼šNothingå‘å¸ƒ99ç¾å…ƒCMF Watch 3 Proï¼Œæœ‰æœ›æˆæœ€ä½³Apple Watchæ›¿ä»£å“"
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šç¿»è¯‘
        if title in special_translations:
            return special_translations[title]
        
        # é€šç”¨ç¿»è¯‘é€»è¾‘
        chinese_title = title
        
        # åŸºç¡€è¯æ±‡æ›¿æ¢
        replacements = [
            # æ ¸å¿ƒè¯æ±‡
            ('Tech giant', 'ç§‘æŠ€å·¨å¤´'), ('OpenAI', 'OpenAI'), ('Google', 'è°·æ­Œ'),
            ('signs deal', 'ç­¾ç½²åè®®'), ('government', 'æ”¿åºœéƒ¨é—¨'),
            ('boost efficiency', 'æå‡æ•ˆç‡'), ('public services', 'å…¬å…±æœåŠ¡'),
            ('Applications chief', 'åº”ç”¨ä¸šåŠ¡ä¸»ç®¡'), ('mission statement', 'ä½¿å‘½å®£è¨€'),
            ('AI Giant', 'AIå·¨å¤´'), ('Down', 'ä¸‹è·Œ'), ('Buy-and-Hold-Forever', 'é•¿æœŸæŒæœ‰'),
            ('Technology Play', 'ç§‘æŠ€æŠ•èµ„'), ('Silicon Valley', 'ç¡…è°·'),
            ('researchers', 'ç ”ç©¶å‘˜'), ('footballers', 'è¶³çƒè¿åŠ¨å‘˜'),
            ('startups', 'åˆåˆ›å…¬å¸'), ('fund closes', 'åŸºé‡‘å‹Ÿèµ„å®Œæˆ'),
            ('invest in', 'æŠ•èµ„äº'), ('World\'s First', 'å…¨çƒé¦–æ¬¾'),
            ('AI Applications', 'AIåº”ç”¨'), ('startup thinks', 'åˆåˆ›å…¬å¸è®¤ä¸º'),
            ('key to', 'å…³é”®åœ¨äº'), ('agent adoption', 'æ™ºèƒ½ä»£ç†æ™®åŠ'),
            ('limiting access', 'é™åˆ¶è®¿é—®'), ('new', 'å…¨æ–°'), ('feature', 'åŠŸèƒ½'),
            ('AI version', 'AIç‰ˆæœ¬'), ('best', 'æœ€ä½³'), ('alternative', 'æ›¿ä»£å“'),
        ]
        
        for en, zh in replacements:
            chinese_title = chinese_title.replace(en, zh)
        
        # æ™ºèƒ½å‰ç¼€
        title_lower = title.lower()
        if 'openai' in title_lower and ('government' in title_lower or 'deal' in title_lower):
            prefix = "ğŸ¤ æ”¿åºœåˆä½œï¼š"
        elif 'openai' in title_lower:
            prefix = "ğŸ¤– OpenAIåŠ¨æ€ï¼š"
        elif any(word in title_lower for word in ['investment', 'fund', 'million', '$']):
            prefix = "ğŸ’° æŠ•èµ„åŠ¨æ€ï¼š"
        elif any(word in title_lower for word in ['startup', 'silicon valley']):
            prefix = "ğŸš€ åˆ›æ–°ä¼ä¸šï¼š"
        elif any(word in title_lower for word in ['ssd', 'hardware', 'tech']):
            prefix = "ğŸ”§ æŠ€æœ¯ç¡¬ä»¶ï¼š"
        else:
            prefix = "ğŸ“° AIèµ„è®¯ï¼š"
            
        return f"{prefix}{chinese_title}"
    
    def translate_description(self, description, title=""):
        """ç¿»è¯‘æè¿°å†…å®¹"""
        if not description:
            return "ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†å†…å®¹å’Œæ·±åº¦åˆ†æã€‚"
        
        # ç‰¹æ®Šæè¿°ç¿»è¯‘
        special_desc = {
            "How much should we trust ChatGPT?": "æˆ‘ä»¬åº”è¯¥åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¿¡ä»»ChatGPTï¼Ÿè¿™å¼•å‘äº†å…³äºAIä¼¦ç†å’Œç”¨æˆ·éšç§çš„æ·±åº¦æ€è€ƒã€‚",
            "The government says AI will be \"fundamental\" in driving change in areas such as the NHS, defence and education.": "æ”¿åºœè¡¨ç¤ºï¼ŒAIå°†åœ¨åŒ»ç–—ã€å›½é˜²å’Œæ•™è‚²ç­‰é¢†åŸŸå‘æŒ¥'æ ¹æœ¬æ€§'å˜é©ä½œç”¨ã€‚",
        }
        
        if description in special_desc:
            return special_desc[description]
        
        # é€šç”¨ç¿»è¯‘
        chinese_desc = description
        basic_replacements = [
            ('OpenAI', 'OpenAI'), ('ChatGPT', 'ChatGPT'), ('AI', 'AI'),
            ('government', 'æ”¿åºœ'), ('trust', 'ä¿¡ä»»'), ('technology', 'æŠ€æœ¯'),
            ('the company', 'è¯¥å…¬å¸'), ('users', 'ç”¨æˆ·'), ('feature', 'åŠŸèƒ½'),
            ('application', 'åº”ç”¨'), ('service', 'æœåŠ¡'), ('data', 'æ•°æ®'),
        ]
        
        for en, zh in basic_replacements:
            chinese_desc = chinese_desc.replace(en, zh)
        
        if len(chinese_desc) > 120:
            chinese_desc = chinese_desc[:117] + "..."
            
        return chinese_desc
    
    def generate_china_analysis(self, title):
        """ç”Ÿæˆä¸­å›½å½±å“åˆ†æ"""
        title_lower = title.lower()
        
        if 'openai' in title_lower and 'government' in title_lower:
            return "**æŠ€æœ¯å½±å“ï¼š** æµ·å¤–AIä¸æ”¿åºœåˆä½œæ¨¡å¼å€¼å¾—å›½å†…å€Ÿé‰´ï¼Œæ¨åŠ¨æ”¿åŠ¡AIåº”ç”¨å‘å±•ã€‚\\n\\n**å¸‚åœºæœºé‡ï¼š** ä¸ºå›½å†…æ”¿åŠ¡AIã€æ™ºæ…§åŸå¸‚ç­‰é¢†åŸŸæä¾›å‘å±•å‚è€ƒã€‚"
        elif 'investment' in title_lower or 'fund' in title_lower:
            return "**æŠ€æœ¯å½±å“ï¼š** å›½é™…AIæŠ•èµ„è¶‹åŠ¿æŒ‡å¯¼å›½å†…èµ„æœ¬é…ç½®æ–¹å‘ã€‚\\n\\n**å¸‚åœºæœºé‡ï¼š** ç›¸å…³æŠ•èµ„æ¨¡å¼å¯ä¸ºå›½å†…AIäº§ä¸šèèµ„æä¾›å€Ÿé‰´ã€‚"
        elif 'hardware' in title_lower or 'ssd' in title_lower:
            return "**æŠ€æœ¯å½±å“ï¼š** AIç¡¬ä»¶åˆ›æ–°æ¨åŠ¨å›½äº§èŠ¯ç‰‡å’Œå­˜å‚¨äº§ä¸šå‡çº§éœ€æ±‚ã€‚\\n\\n**å¸‚åœºæœºé‡ï¼š** ä¸ºå›½å†…AIåŸºç¡€è®¾æ–½å»ºè®¾æä¾›æŠ€æœ¯è·¯å¾„å‚è€ƒã€‚"
        else:
            return "**æŠ€æœ¯å½±å“ï¼š** æ¨åŠ¨å›½å†…AIäº§ä¸šæŠ€æœ¯è¿›æ­¥å’Œåº”ç”¨åˆ›æ–°ã€‚\\n\\n**å¸‚åœºæœºé‡ï¼š** ä¸ºç›¸å…³ä¼ä¸šæä¾›å‘å±•æ€è·¯å’Œå•†ä¸šæ¨¡å¼å‚è€ƒã€‚"
    
    def generate_investment_insight(self, title):
        """ç”ŸæˆæŠ•èµ„æ´å¯Ÿ"""
        title_lower = title.lower()
        
        if 'openai' in title_lower:
            return "**ç›¸å…³æ¦‚å¿µè‚¡ï¼š** ç§‘å¤§è®¯é£(002230)ã€æ±‰ç‹ç§‘æŠ€(002362)ã€æµ·å¤©ç‘å£°(688787)ç­‰AIåº”ç”¨æ¦‚å¿µè‚¡ã€‚"
        elif 'hardware' in title_lower or 'ssd' in title_lower:
            return "**ç›¸å…³æ¦‚å¿µè‚¡ï¼š** ç´«å…‰å›½å¾®(002049)ã€å…†æ˜“åˆ›æ–°(603986)ã€æ±Ÿæ³¢é¾™(301308)ç­‰å­˜å‚¨èŠ¯ç‰‡è‚¡ã€‚"
        elif 'investment' in title_lower:
            return "**ç›¸å…³æ¦‚å¿µè‚¡ï¼š** åˆ›ä¸šæ¿AIæ¦‚å¿µè‚¡ï¼Œå…³æ³¨ä¼°å€¼åˆç†çš„ä¼˜è´¨æ ‡çš„ã€‚"
        else:
            return "**æŠ•èµ„å»ºè®®ï¼š** å…³æ³¨AIäº§ä¸šé“¾ä¸­æŠ€æœ¯é¢†å…ˆã€ä¼°å€¼åˆç†çš„ä¼˜è´¨å…¬å¸ã€‚"
    
    def categorize_news(self, title):
        """æ™ºèƒ½åˆ†ç±»"""
        title_lower = title.lower()
        if any(word in title_lower for word in ['openai', 'chatgpt']):
            return {'name': 'OpenAIåŠ¨æ€', 'color': '#34C759', 'icon': 'ğŸ¤–'}
        elif any(word in title_lower for word in ['investment', 'fund', 'million', '$']):
            return {'name': 'æŠ•èµ„åŠ¨æ€', 'color': '#FF3B30', 'icon': 'ğŸ’°'}
        elif any(word in title_lower for word in ['hardware', 'ssd', 'chip']):
            return {'name': 'AIç¡¬ä»¶', 'color': '#FF9500', 'icon': 'ğŸ”§'}
        elif any(word in title_lower for word in ['startup', 'company']):
            return {'name': 'åˆ›æ–°ä¼ä¸š', 'color': '#5856D6', 'icon': 'ğŸš€'}
        else:
            return {'name': 'AIèµ„è®¯', 'color': '#8E8E93', 'icon': 'ğŸ“±'}
    
    def get_importance_score(self, title):
        """é‡è¦æ€§è¯„åˆ†"""
        title_lower = title.lower()
        score = 1
        
        if any(word in title_lower for word in ['openai', 'government', 'deal']):
            score += 3
        elif any(word in title_lower for word in ['investment', 'million', 'fund']):
            score += 2
        elif any(word in title_lower for word in ['first', 'new', 'breakthrough']):
            score += 1
            
        return min(score, 5)
    
    def process_news_data(self):
        """å¤„ç†ç°æœ‰æ–°é—»æ•°æ®ï¼Œè¿›è¡Œå®Œæ•´ä¸­æ–‡ç¿»è¯‘"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            with open('docs/news_data.json', 'r', encoding='utf-8') as f:
                news_data = json.load(f)
            
            # é‡æ–°å¤„ç†æ¯æ¡æ–°é—»
            processed_news = []
            for i, article in enumerate(news_data):
                original_title = article.get('original_title', article.get('title', ''))
                original_description = article.get('original_description', article.get('description', ''))
                
                processed_article = {
                    'id': f"news_{i}",
                    'title': self.translate_title_completely(original_title),
                    'original_title': original_title,
                    'description': self.translate_description(original_description, original_title),
                    'original_description': original_description,
                    'url': article.get('url', ''),
                    'source': article.get('source', 'æœªçŸ¥æ¥æº'),
                    'publishedAt': article.get('publishedAt', ''),
                    'image': article.get('image', ''),
                    'category': self.categorize_news(original_title),
                    'importance': self.get_importance_score(original_title),
                    'china_analysis': self.generate_china_analysis(original_title),
                    'investment_insight': self.generate_investment_insight(original_title)
                }
                processed_news.append(processed_article)
            
            # æŒ‰é‡è¦æ€§æ’åº
            processed_news.sort(key=lambda x: x['importance'], reverse=True)
            
            # å¯¼å…¥ç°æœ‰çš„ç”Ÿæˆå™¨æ¥åˆ›å»ºé¡µé¢
            from optimized_html_generator import AppleStyleNewsGenerator
            generator = AppleStyleNewsGenerator()
            
            # ç”Ÿæˆé¦–é¡µ
            homepage_content = generator.create_homepage_template(processed_news)
            with open('docs/index.html', 'w', encoding='utf-8') as f:
                f.write(homepage_content)
            
            # ç”Ÿæˆè¯¦æƒ…é¡µ
            for news in processed_news:
                detail_content = generator.create_detail_template(news, processed_news)
                with open(f'docs/news/{news["id"]}.html', 'w', encoding='utf-8') as f:
                    f.write(detail_content)
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            with open('docs/news_data.json', 'w', encoding='utf-8') as f:
                json.dump(processed_news, f, ensure_ascii=False, indent=2)
            
            print("âœ… ä¸­æ–‡æ–°é—»å†…å®¹å·²å®Œå…¨æ›´æ–°ï¼")
            print(f"   ğŸ“„ é¦–é¡µæ›´æ–°: docs/index.html")
            print(f"   ğŸ“° è¯¦æƒ…é¡µæ›´æ–°: {len(processed_news)} ç¯‡")
            print("   ğŸ‡¨ğŸ‡³ æ‰€æœ‰æ ‡é¢˜å·²å®Œæ•´ä¸­æ–‡ç¿»è¯‘")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            return False

if __name__ == "__main__":
    generator = ChineseNewsGenerator()
    success = generator.process_news_data()
    if success:
        print("ğŸ‰ ä¸­æ–‡æ–°é—»ç³»ç»Ÿæ›´æ–°å®Œæˆï¼")
    else:
        print("âŒ æ›´æ–°å¤±è´¥ï¼")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•æ”¹è¿›çš„ä¸­æ–‡ç¿»è¯‘ - è¦†ç›–æ›´å¤šè¯æ±‡
"""

import json
import urllib.request
import urllib.parse
import time

# é…ç½®
GNEWS_API_KEY = "c3cb6fef0f86251ada2b515017b97143"
FEISHU_APP_ID = "cli_a8f4efb90f3a1013"
FEISHU_APP_SECRET = "lCVIsMEiXI6yaOCHa0OkFgOjWcCpy3t8"
FEISHU_BASE_URL = "https://open.feishu.cn/open-apis"
GNEWS_BASE_URL = "https://gnews.io/api/v4"

def get_feishu_token():
    try:
        url = f"{FEISHU_BASE_URL}/auth/v3/tenant_access_token/internal"
        data = {"app_id": FEISHU_APP_ID, "app_secret": FEISHU_APP_SECRET}
        req = urllib.request.Request(url, data=json.dumps(data).encode('utf-8'), headers={'Content-Type': 'application/json'})
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
        return result.get('tenant_access_token') if result.get('code') == 0 else None
    except:
        return None

def improved_translate_title(title):
    """æ”¹è¿›çš„ä¸­æ–‡ç¿»è¯‘ - è¦†ç›–æ›´å¤šåœºæ™¯"""
    if not title:
        return title
        
    # æ‰©å±•çš„ç¿»è¯‘è¯å…¸
    translations = {
        # å…¬å¸åç§°
        'OpenAI': 'OpenAI',
        'Google': 'è°·æ­Œ',
        'Microsoft': 'å¾®è½¯',
        'Meta': 'Meta',
        'Apple': 'è‹¹æœ',
        'Amazon': 'äºšé©¬é€Š',
        'Tesla': 'ç‰¹æ–¯æ‹‰',
        'NVIDIA': 'è‹±ä¼Ÿè¾¾',
        'Anthropic': 'Anthropic',
        'Facebook': 'è„¸ä¹¦',
        'Twitter': 'æ¨ç‰¹',
        'ByteDance': 'å­—èŠ‚è·³åŠ¨',
        'Alphabet': 'è°·æ­Œæ¯å…¬å¸',
        
        # AIæŠ€æœ¯è¯æ±‡
        'Artificial Intelligence': 'äººå·¥æ™ºèƒ½',
        'AI': 'AI',
        'Machine Learning': 'æœºå™¨å­¦ä¹ ',
        'Deep Learning': 'æ·±åº¦å­¦ä¹ ',
        'Neural Network': 'ç¥ç»ç½‘ç»œ',
        'Large Language Model': 'å¤§è¯­è¨€æ¨¡å‹',
        'LLM': 'å¤§è¯­è¨€æ¨¡å‹',
        'ChatGPT': 'ChatGPT',
        'GPT': 'GPT',
        'GPT-4': 'GPT-4',
        'GPT-5': 'GPT-5',
        'Gemini': 'Gemini',
        'Bard': 'Bard',
        'Copilot': 'Copilot',
        'Algorithm': 'ç®—æ³•',
        'Model': 'æ¨¡å‹',
        'Technology': 'æŠ€æœ¯',
        'Platform': 'å¹³å°',
        'System': 'ç³»ç»Ÿ',
        'Tool': 'å·¥å…·',
        'Software': 'è½¯ä»¶',
        'Application': 'åº”ç”¨',
        'Feature': 'åŠŸèƒ½',
        'Update': 'æ›´æ–°',
        'Version': 'ç‰ˆæœ¬',
        
        # åŠ¨ä½œè¯æ±‡
        'Launches': 'å‘å¸ƒ',
        'Releases': 'å‘å¸ƒ',
        'Announces': 'å®£å¸ƒ',
        'Introduces': 'æ¨å‡º',
        'Unveils': 'æ­æ™“',
        'Updates': 'æ›´æ–°',
        'Improves': 'æ”¹è¿›',
        'Enhances': 'å¢å¼º',
        'Develops': 'å¼€å‘',
        'Creates': 'åˆ›å»º',
        'Builds': 'æ„å»º',
        'Plans': 'è®¡åˆ’',
        'Reveals': 'æ­ç¤º',
        'Shows': 'å±•ç¤º',
        'Demos': 'æ¼”ç¤º',
        'Tests': 'æµ‹è¯•',
        'Trials': 'è¯•éªŒ',
        
        # æè¿°è¯æ±‡
        'Revolutionary': 'é©å‘½æ€§',
        'Breakthrough': 'çªç ´æ€§',
        'Advanced': 'å…ˆè¿›çš„',
        'New': 'å…¨æ–°',
        'Latest': 'æœ€æ–°',
        'Next-Generation': 'ä¸‹ä¸€ä»£',
        'Powerful': 'å¼ºå¤§çš„',
        'Smart': 'æ™ºèƒ½',
        'Intelligent': 'æ™ºèƒ½çš„',
        'Innovative': 'åˆ›æ–°çš„',
        'Cutting-edge': 'å‰æ²¿çš„',
        'State-of-the-art': 'æœ€å…ˆè¿›çš„',
        'Major': 'é‡å¤§',
        'Significant': 'é‡è¦',
        'Important': 'é‡è¦',
        'Big': 'é‡å¤§',
        'Huge': 'å·¨å¤§',
        'Massive': 'å¤§è§„æ¨¡',
        
        # åº”ç”¨é¢†åŸŸ
        'Healthcare': 'åŒ»ç–—',
        'Education': 'æ•™è‚²',
        'Finance': 'é‡‘è',
        'Automotive': 'æ±½è½¦',
        'Robotics': 'æœºå™¨äºº',
        'Gaming': 'æ¸¸æˆ',
        'Research': 'ç ”ç©¶',
        'Development': 'å¼€å‘',
        'Business': 'å•†ä¸š',
        'Enterprise': 'ä¼ä¸š',
        'Industry': 'è¡Œä¸š',
        'Market': 'å¸‚åœº',
        'Economy': 'ç»æµ',
        
        # å¸¸è§è¯æ±‡
        'Says': 'è¡¨ç¤º',
        'Reports': 'æŠ¥å‘Š',
        'Study': 'ç ”ç©¶',
        'Analysis': 'åˆ†æ',
        'Data': 'æ•°æ®',
        'Report': 'æŠ¥å‘Š',
        'Survey': 'è°ƒæŸ¥',
        'News': 'æ–°é—»',
        'Story': 'æŠ¥é“',
        'Article': 'æ–‡ç« ',
        'Post': 'å‘å¸ƒ',
        'Blog': 'åšå®¢',
        'Interview': 'é‡‡è®¿',
        'Conference': 'ä¼šè®®',
        'Event': 'æ´»åŠ¨',
        'Summit': 'å³°ä¼š',
        'Forum': 'è®ºå›',
        
        # å…¶ä»–å…³é”®è¯
        'Future': 'æœªæ¥',
        'Trend': 'è¶‹åŠ¿',
        'Challenge': 'æŒ‘æˆ˜',
        'Opportunity': 'æœºé‡',
        'Solution': 'è§£å†³æ–¹æ¡ˆ',
        'Impact': 'å½±å“',
        'Change': 'å˜åŒ–',
        'Growth': 'å¢é•¿',
        'Success': 'æˆåŠŸ',
        'Failure': 'å¤±è´¥',
        'Risk': 'é£é™©',
        'Safety': 'å®‰å…¨',
        'Security': 'å®‰å…¨',
        'Privacy': 'éšç§',
        'Ethics': 'ä¼¦ç†',
        'Regulation': 'ç›‘ç®¡',
        'Policy': 'æ”¿ç­–',
        'Law': 'æ³•å¾‹',
        'Government': 'æ”¿åºœ',
        'Industry': 'è¡Œä¸š',
        'Competition': 'ç«äº‰',
        'Investment': 'æŠ•èµ„',
        'Funding': 'èµ„é‡‘',
        'Startup': 'åˆåˆ›å…¬å¸',
        'Company': 'å…¬å¸',
        'Corporation': 'å…¬å¸',
        'Firm': 'å…¬å¸',
        'Organization': 'æœºæ„',
        'Institution': 'æœºæ„',
        'University': 'å¤§å­¦',
        'College': 'å­¦é™¢',
        'School': 'å­¦æ ¡',
        'Department': 'éƒ¨é—¨',
        'Team': 'å›¢é˜Ÿ',
        'Group': 'é›†å›¢',
        'Lab': 'å®éªŒå®¤',
        'Laboratory': 'å®éªŒå®¤',
        'Center': 'ä¸­å¿ƒ',
        'Institute': 'ç ”ç©¶æ‰€',
    }
    
    # æ‰§è¡Œç¿»è¯‘
    chinese_title = title
    
    # æŒ‰é•¿åº¦æ’åºï¼Œå…ˆæ›¿æ¢é•¿è¯ç»„
    sorted_translations = sorted(translations.items(), key=lambda x: len(x[0]), reverse=True)
    
    for en_word, zh_word in sorted_translations:
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ›¿æ¢æ–¹å¼
        import re
        # æ›¿æ¢å®Œæ•´å•è¯ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
        pattern = r'\b' + re.escape(en_word) + r'\b'
        chinese_title = re.sub(pattern, zh_word, chinese_title, flags=re.IGNORECASE)
    
    # æ¸…ç†å¤šä½™ç©ºæ ¼
    chinese_title = ' '.join(chinese_title.split())
    
    # å¦‚æœç¿»è¯‘åè¿˜æœ‰å¾ˆå¤šè‹±æ–‡ï¼Œæ·»åŠ ä¸­æ–‡å‰ç¼€
    english_chars = sum(1 for c in chinese_title if c.isascii() and c.isalpha())
    total_meaningful_chars = len([c for c in chinese_title if c.isalnum() or ord(c) > 127])
    
    if total_meaningful_chars > 0 and english_chars / total_meaningful_chars > 0.4:
        # æ ¹æ®å†…å®¹æ·»åŠ æ›´ç²¾ç¡®çš„å‰ç¼€
        title_lower = title.lower()
        if any(word in title_lower for word in ['launch', 'release', 'announce', 'unveil']):
            chinese_title = f"ğŸš€ æœ€æ–°å‘å¸ƒï¼š{chinese_title}"
        elif any(word in title_lower for word in ['breakthrough', 'innovation', 'revolutionary']):
            chinese_title = f"ğŸ’¡ æŠ€æœ¯çªç ´ï¼š{chinese_title}"
        elif any(word in title_lower for word in ['update', 'improve', 'enhance', 'upgrade']):
            chinese_title = f"ğŸ”„ é‡å¤§æ›´æ–°ï¼š{chinese_title}"
        elif any(word in title_lower for word in ['study', 'research', 'analysis', 'report']):
            chinese_title = f"ğŸ“Š ç ”ç©¶æŠ¥å‘Šï¼š{chinese_title}"
        elif any(word in title_lower for word in ['warn', 'risk', 'danger', 'threat']):
            chinese_title = f"âš ï¸  é£é™©è­¦ç¤ºï¼š{chinese_title}"
        elif any(word in title_lower for word in ['invest', 'funding', 'money', 'billion']):
            chinese_title = f"ğŸ’° æŠ•èµ„åŠ¨æ€ï¼š{chinese_title}"
        else:
            chinese_title = f"ğŸ“° AIèµ„è®¯ï¼š{chinese_title}"
    
    return chinese_title

def get_real_news_and_test():
    """è·å–çœŸå®æ–°é—»å¹¶æµ‹è¯•ç¿»è¯‘"""
    try:
        params = {
            'apikey': GNEWS_API_KEY,
            'q': 'AI OR OpenAI OR "artificial intelligence"',
            'lang': 'en',
            'max': '3'
        }
        
        query_string = urllib.parse.urlencode(params)
        url = f"{GNEWS_BASE_URL}/search?{query_string}"
        
        with urllib.request.urlopen(url, timeout=10) as response:
            result = json.loads(response.read().decode('utf-8'))
        
        if 'articles' in result and len(result['articles']) > 0:
            articles = result['articles']
            
            print("ğŸ“° çœŸå®æ–°é—»ç¿»è¯‘æµ‹è¯•")
            print("=" * 80)
            
            for i, article in enumerate(articles, 1):
                original_title = article.get('title', '')
                chinese_title = improved_translate_title(original_title)
                
                print(f"\n{i}. åŸæ ‡é¢˜:")
                print(f"   {original_title}")
                print(f"   ä¸­æ–‡ç¿»è¯‘:")
                print(f"   {chinese_title}")
                print(f"   æ¥æº: {article.get('source', {}).get('name', 'æœªçŸ¥')}")
            
            return articles[0]  # è¿”å›ç¬¬ä¸€æ¡ç”¨äºæµ‹è¯•æ¨é€
        
    except Exception as e:
        print(f"âŒ è·å–æ–°é—»å¤±è´¥: {str(e)}")
    
    return None

def push_with_improved_translation(article):
    """ä½¿ç”¨æ”¹è¿›ç¿»è¯‘æ¨é€æ–°é—»"""
    token = get_feishu_token()
    if not token:
        return False
    
    chinese_title = improved_translate_title(article.get('title', ''))
    
    # è·å–æœ€å¤§æ—¶é—´æˆ³
    try:
        app_token = "TXkMb0FBwaD52ese70ScPLn5n5b"
        table_id = "tblyPOJ4k9DxJuKc"
        
        # è·å–å½“å‰æœ€å¤§æ—¶é—´æˆ³
        url = f"{FEISHU_BASE_URL}/bitable/v1/apps/{app_token}/tables/{table_id}/records"
        req = urllib.request.Request(url, headers={'Authorization': f'Bearer {token}'})
        
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
        
        max_timestamp = int(time.time() * 1000)
        if result.get('code') == 0:
            records = result.get('data', {}).get('items', [])
            for record in records:
                update_date = record.get('fields', {}).get('æ›´æ–°æ—¥æœŸ', 0)
                if isinstance(update_date, (int, float)) and update_date > max_timestamp:
                    max_timestamp = int(update_date)
        
        # ä½¿ç”¨æ›´æ–°çš„æ—¶é—´æˆ³
        future_timestamp = max_timestamp + 180000  # åŠ 3åˆ†é’Ÿ
        
        # æ¨é€æ•°æ®
        url = f"{FEISHU_BASE_URL}/bitable/v1/apps/{app_token}/tables/{table_id}/records"
        
        record_data = {
            "fields": {
                "æ ‡é¢˜": chinese_title,
                "æ‘˜è¦": (article.get('description', '') or article.get('content', ''))[:200] + "...",
                "AIè§‚ç‚¹": "è¯¥AIæŠ€æœ¯å‘å±•å€¼å¾—è¡Œä¸šå…³æ³¨ï¼Œä½“ç°äº†äººå·¥æ™ºèƒ½é¢†åŸŸçš„æŒç»­åˆ›æ–°å’Œè¿›æ­¥ã€‚",
                "ä¸­å›½å½±å“åˆ†æ": "æŠ€æœ¯å‘å±•ï¼šæ¨åŠ¨å›½å†…AIäº§ä¸šå‡çº§å’ŒæŠ€æœ¯åˆ›æ–°\\nå¸‚åœºæœºé‡ï¼šä¸ºç›¸å…³ä¼ä¸šæä¾›æ–°çš„å‘å±•æœºä¼š\\näººæ‰éœ€æ±‚ï¼šä¿ƒè¿›AIç›¸å…³äººæ‰åŸ¹å…»å’ŒæŠ€æœ¯å‚¨å¤‡",
                "æ›´æ–°æ—¥æœŸ": future_timestamp,
                "æ¥æº": {
                    "link": article.get('url', ''),
                    "text": article.get('source', {}).get('name', 'æ–°é—»æº')
                }
            }
        }
        
        req = urllib.request.Request(
            url,
            data=json.dumps(record_data).encode('utf-8'),
            headers={
                'Authorization': f'Bearer {token}',
                'Content-Type': 'application/json'
            }
        )
        
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
        
        if result.get('code') == 0:
            print(f"\nâœ… æ”¹è¿›ç¿»è¯‘æ¨é€æˆåŠŸï¼")
            print(f"ğŸ“° ä¸­æ–‡æ ‡é¢˜: {chinese_title}")
            return True
        else:
            print(f"âŒ æ¨é€å¤±è´¥: {result}")
            return False
    
    except Exception as e:
        print(f"âŒ æ¨é€å¼‚å¸¸: {str(e)}")
        return False

def main():
    print("ğŸŒ æ”¹è¿›ç‰ˆä¸­æ–‡ç¿»è¯‘æµ‹è¯•")
    print("=" * 60)
    
    # è·å–çœŸå®æ–°é—»å¹¶æµ‹è¯•ç¿»è¯‘
    article = get_real_news_and_test()
    
    if article:
        print(f"\nğŸ“¤ æ¨é€æ”¹è¿›ç¿»è¯‘ç‰ˆæœ¬åˆ°é£ä¹¦...")
        success = push_with_improved_translation(article)
        
        if success:
            print(f"\nğŸ‰ æ”¹è¿›ç‰ˆç¿»è¯‘æµ‹è¯•æˆåŠŸï¼")
            print(f"ğŸ”— æŸ¥çœ‹ç»“æœ: https://jcnew7lc4a8b.feishu.cn/base/TXkMb0FBwaD52ese70ScPLn5n5b")
    else:
        print(f"âŒ æ— æ³•è·å–æ–°é—»è¿›è¡Œæµ‹è¯•")

if __name__ == "__main__":
    main()